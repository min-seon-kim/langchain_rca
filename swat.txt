Anomaly Detection for Industrial Control Systems Using Sequence-to-Sequence Neural Networks Abstract. This study proposes an anomaly detection method for operational data of industrial control systems (ICSs). Sequence-to-sequence neural networks were applied to train and predict ICS operational data and interpret their time-series characteristic. The proposed method requires only a normal dataset to understand ICS’s normal state and detect outliers. This method was evaluated with SWaT (secure water treatment) dataset, and 29 out of 36 attacks were detected. The reported method also detects the attack points, and 25 out of 53 points were detected. This study provides a detailed analysis of false positives and false negatives of the experimental results. Keywords: Anomaly detection · Deep learning · Operational data · Industrial control system. 1 Introduction Since Stuxnet struck a nuclear facility in 2010, threats towards industrial control systems (ICSs) have increased. Unfortunately, as most of ICS attackers are state-sponsored and use zero-day vulnerabilities, signature-based detection (maintaining the blacklist and updating it) is inappropriate. The most common and safe approaches that do not harm the availability of ICSs monitor the network traffic of these systems. ICSs present more periodic behavior than information technology systems. Several studies [5,13,20] applied the statistical characteristics of traffic for ICS-specific security mechanisms. Although this approach is suitable for ICS traffic characteristics, it presents limitations in detecting attacks at the ICS operation level. Other researches focused on the detection of anomalies with physical properties [14]. By using the specification or control logic, the monitoring system rarely emits false alarms [3,15]. However, it is relatively expensive to obtain and specify the specification or control logic. An ICS recognizes the environment with sensors, makes decisions for its purpose, and delivers the right action with actuators. To detect anomalies at the ICS operation level, its normal state must be defined and the control logic that decides actuators’ behaviors must be 2 J. Kim et al. understood. However, understanding the entire set of the control logic is complicated. In fact, the volume of the control logic is enormous, and acquiring it from vendors is not allowed in most cases. Herein, the aim is to monitor the ICS operational data. A feasible alternative is the data-driven approach. Machine-learning-based approaches have been highly studied and especially deep-learning-based anomaly detection methods which have been reported recently using fully-connected networks (FCN) [18], convolutional neural networks (CNN) [10], recurrent neural networks (RNN) [7], and generative adversarial networks (GAN) [12]. We propose a deep learning-based anomaly detection method using a sequenceto-sequence model (seq2seq) [19]. Seq2seq is designed initially for natural language translation. It encodes the words of a given sentence with RNN into a latent vector, then decodes from it to a set of words in the target language. Seq2seq’s encoding-decoding approach presents a significant advantage as it can understand the context of the entire sentence, while vanilla RNN gives the output immediately for every input. Seq2seq is expected to be an effective method for learning the context or semantics of time-series operational data, and obtain a better prediction based on the given data. To date, no abnormal samples have been reported to train machine learning models robustly. Therefore, the reported model is trained with the only normal dataset (training dataset), and it is considered that the training data are clean. In the detection phase, the developed model investigates unseen data with trained neural networks. Using the model after the learning phase, the detection method proceeds in three steps: Step 1, the model predicts the future values of the sensors and actuators, Step 2, the difference between the prediction and actual data is determined, and Step 3, alerts are sent for significant differences. The rest of this paper is organized as follows. Section 2 introduces the anomaly detection method using the seq2seq neural network. Section 3 presents the experimental results after applying the proposed method to the secure water treatment (SWaT) dataset [6]. Section 4 analyzes the experimental results in detail and Section 5 concludes this study. 2 2.1 Proposed Method SWaT Dataset Several studies have recently been reported on dataset generation for ICS research [4,6,11,17]. The most frequently used dataset is the SWaT dataset [6] by Singapore University of Technology and Design (SUTD), which has operational data and attack labels. Herein, the method is developed and evaluated with the SWaT dataset. The SWaT dataset was collected from a testbed water treatment system. Fifty-one tags (25 sensors and 26 actuators) are sampled every second. Some are digital, and others are analog. Tag names define their roles. For example, MV denotes motorized valve, P for pump, FIT for flow meter, and LIT for level transmitter. Anomaly Detection for ICSs Using Seq2Seq Neural Networks 3 Fig. 1. Proposed learning model using seq2seq with attention SWaT consists of six processes. Water flows from process 1 to the process 6. The numbers following the tag names indicate the process ID and the gadget ID. For example, MV-101 is the first motorized valve in process 1. In the SWaT dataset, normal and attack datasets are separated. The normal part has 480,800 samples, and the attack part includes 41 attacks during 449,919 samples. 2.2 Data Preprocessing Multiple machine learning schemes normalize the input into a Gaussian distribution with an average of 0 and a standard deviation of 1. However, to ensure that the distributions of most tags in the normal part of the SWaT dataset were not distorted nor had multiple peaks, min-max normalization was chosen. Long-short term memory (LSTM) [8], which is a RNN cell used in the developed model, has a sigmoid function inside that gives a (0, 1) output. The minimum and maximum for normalization were chosen as 0 and 1. The operational data were time-series. The model used sliding windows of length 100 seconds to understand the temporal context, and each window slides 1 by 1 second. 2.3 Sequence-to-Sequence Neural Networks There are various ways to build a neural network for learning time-series data. We chose the sequence-to-sequence network with attention [2] for training and evaluation. Since RNN is proper for learning a series of data, we expected that RNN is able to encode the current window of data and to anticipate the next values. Figure 1 shows the data flow of the proposed model. The shape of inputs for the encoder is (# of sequences, batch, # of tags). The encoder obtains the first 90 seconds of the window. The encoder’s output is two-fold: 1) the last cell state of the last layer and 2) all hidden states of the last layer. The first 4 J. Kim et al. Fig. 2. Prediction errors for processes 1, 2, 3, 4, and 5 of SWaT (red: attack, purple: prediction error, and blue: anomaly score) one has the context of the given sequences. The second one helps the decoder predict future operational data with the attention mechanism. The decoder part is optional. The reason why we added a decoder with attention is that it gives us more accurate results. The decoder predicts the last second with a 9-second hint. The values of 9th second of the hint is almost the same with those of the last record of the window (we wanted to expect), which helps the model give almost-zero prediction error. The shape of the decoder’s final output is (batch, # of tags). An independent model was applied for each process of SWaT. The model n learns the process n. Figure 2 shows the prediction error of each process. At the early stage of this study, a holistic model1 was tested for six processes. The result was not accurate because each process shows a different prediction error pattern, especially the process 2, as observed in Figure 2. 2.4 Measuring Prediction Error The mean absolute error (MAE) is a typical measuring method. However, pnorm can also be used, with p > 2. The greater the value of p, the greater the value of the vector. ∞-norm returns the maximum value of the vector. Herein, a 4-norm was chosen, while Kaspersky chose a 6-norm [18] for SWaT dataset. 1 [18] used this approach: one model for the whole processes. Anomaly Detection for ICSs Using Seq2Seq Neural Networks The prediction error (distance) D can be extracted as follows: v u n uX 4 D=t d4i where di = Ii − Oi 5 (1) i=1 where n is the number of tags, Ii is the i-th tag values in the dataset, and Oi is the i-th output of the model. 2.5 Anomaly Decision using Prediction Errors The proposed method considers that the system is under attack if the model has never seen the current state. The developed model was trained to perform a precise prediction. When the model detects a never-seen window, it cannot perform an accurate prediction, which leads to more notable 4-norm value. Multiple approaches can be used to determine anomalies such as cumulative sum (CUSUM) and anomaly likelihood [1]. The custom rating method was applied by considering the prediction errors – due to the following factors: 1. A learning model often presents periodic noises, but it is hard to remove noises because of the limited learning data. 2. From a specific time, the distances of process 2, especially AIT-201 in SWaT, are increasing and never recovered (this issue is discussed in Section 4.2). A similar (but not significant) phenomenon occurred in process 5. It is assumed that an insufficient amount of training data and unexpected dynamics can cause growing prediction errors. A sliding window for rating was also applied. First, the top-k outliers were removed. As aforementioned, the developed model presents noise (the impulse of prediction error). The sum of remains except the outliers represents the distance of the window. Fortunately, attacks last at least 2 minutes (the shortest attack is attack 34). For a large summation on a specific window, a high rate can be attributed to that particular region. Second, N summations were collected to compare the current sum with nearby ones. Two hyper-parameters were defined: H and L. L is the 20th percentile, and H is the 90th percentile. H is not the 80th because top-k values (outliers) were already removed to reduce noises. The ratio H L and divided by R, which is another hyper-parameter. Here, R = 20. In short, if the 90th percentile is 20 times greater than the 20th percentile, it is certain that an attack happens. The rate for suspicious region S is derived as follows: H S = min( , 1.0) (2) LR Finally, if S is greater than 0.3 (30%), it is regarded as an attack. All numbers mentioned above (90 for H, 20 for L, 20 for R, and 0.3 for threshold) are hyperparameters which are dataset-dependent. 6 J. Kim et al. Equation 2 determines high rates at the start and end of the attack because it measures the change. We use both sides: start and end. Depending on the attack the high rate can be obtained at the start or at the end. Figure 3 shows D and S of attack 41. Fig. 3. Asymmetric ratings at the start and end of attack 41 (red: attack, purple: prediction error, and blue: anomaly score) As D grows slowly at the start and shrink quickly at the end, S is low at the start but high at the end. 3 Experiment All source codes, pre-processed datasets, trained network parameters, and results are available at https://github.com/jukworks/swat-seq2seq. 3.1 Training Occasionally, a neural network goes bad local minima during training process. A general approach to solve this issue is to train the neural network multiple times independently and choose the best result among the multiple training results. As a neural network is trained with a stochastic gradient descent and mostly initialized with random numbers, different results are obtained every run. Two independent training sessions were run for each model (each process) and the network presenting the lowest training loss was chosen. The model was optimized with Adam [9], amsgrad [16], and without weight decay. Each model trained 150 epochs with a 4,096 batch size. Early stopping was not applied. The hardware consisted of Intel Xeon CPU E5-2960 v4 2.60GHz, 6 NVIDIA Tesla V100, and 512 GB RAM. Table 1 shows that the training time was approximately 2 hours on average. Six models have a different size of input and output, but their internal LSTM architectures were entirely the same. Therefore, the number of trainable parameters is similar, which leads to similar training time. Anomaly Detection for ICSs Using Seq2Seq Neural Networks 7 Table 1. Training time for 150 epochs Trial 1 Trial 2 Process 1 Process 2 Process 3 Process 4 Process 5 Process 6 1h 48m 1h 50m 2h 00m 1h 59m 1h 53m 1h 59m 1h 54m 2h 01m 2h 23m 2h 01m 2h 27m 2h 12m Fig. 4. LIT-101 was not stable after attack 30 happens (from [10]) 3.2 Anomaly Detection The results are compared with Kaspersky’s research [18] because this is the only study providing the list of found attack points. If an alert is received within 15 minutes after the attack range of SWaT, it is considered as a detection. 15 minute is chosen as attacks attacks on cyberphysical systems tend to have a long impact. The shortest attack in SWaT, attack 29, lasts 2 minutes2 . Figure 4 shows LIT-101 on attack 30 [10]. The two black vertical lines represent the start and end of the attack. After the end of the attack, LIT-101 was unstable. As the reported model learns the normal-labeled data only, it may perceive the stabilizing region as an anomaly. Tables 2 and 3 compare the detection results with those of [18]. Attacks 5, 9, 12, 15, and 18 have no physical impact. These attacks were ignored as they cannot be detected with operational data. The first column shows the attack numbers. The second column presents the answer to attack points labeled in the SWaT dataset. The third column represents the detection of the attack: Yes means 100% sure, not sure means 30% - 100% means sure, and No means less than 30% sure. As mentioned in Section 2.5, 30% represents the heuristic threshold. The fourth and fifth column represents the attack points determined by the model and [18], respectively. Bold text indicates correct answers. The 2 The longest attack in SWaT is attack 28, which lasted 9.5 hours. 8 J. Kim et al. Fig. 5. List of detected attacks and comparison with [18]. Red (4, 14, 29) represents attacks that are impossible to detect. Yellow (24) represents attacks that are difficult to detect. parentheses indicate the second-longest distance. N/A indicates that the model failed to detect. [18] reported 25 attacks and 11 attack points (nine with the first predictions and 2 with the second predictions). Herein, the model found 29 attacks and 25 attack points (22 with the first predictions and 3 with the second predictions). 21 attacks were detected by both the developed model and that in [18]. Four attacks were detected only by the model in [18]: attacks 19, 24, 25, and 29. Eight attacks were detected only by the developed model: attacks 1, 3, 17, 20, 27, 32, 33, and 41, which also detected attacks 21 and 31 with 35% and 50% rates, respectively. The SWaT dataset indicates that the attack points of attack 35 is process 1, but it was detected by the developed model for process 3 (20% rate at the model for process 1). Both methods failed to detect three attacks: attacks 4, 13, and 14. The model was not used with process 6 as it has only two tags. The SWaT dataset presents only one attack3 and has an impact on process 6. 4 Analysis of Experimental Results Three pairs of attacks, (10, 11), (19, 20), and (27, 28) were indistinguishable for the developed model because they occur almost continuously4 and have the same attack point. 4.1 Analysis on False Negative (Undetected Attacks) The model failed to detect attacks 4, 13, 14, 19, 24, 25, and 29. 3 4 Attack 23 also has an impact on process 3. The developed model for process 3 detected this attack. Their intervals are 0, 42, and 1 second(s) respectively, while the developed model uses a 100-second sliding windows. Anomaly Detection for ICSs Using Seq2Seq Neural Networks Table 2. Anomaly detection results compared with those of [18] (attacks 1 to 30) Attack # 1 2 Answer (by SWaT) MV-101 P-102 3 LIT-101 4 6 MV-504 AIT-202 7 LIT-301 Yes LIT-301 8 DPIT-301 Yes DPIT-301 10 FIT-401 Yes FIT-401 11 FIT-401 Yes 13 14 16 MV-304 MV-303 LIT-301 No No Yes FIT-401 (FIT-504) MV-304 N/A LIT-301 17 MV-303 Yes 19 AIT-504 No (15%) 20 21 AIT-504 MV-101, LIT-101 UV-401, AIT-502, P-501 P-602, DPIT-301, MV-302 P-203, P-205 LIT-401, P-401 P-101, LIT-301 P-302, LIT-401 P-302 Yes Not sure (35%) Yes AIT-504 LIT-101 FIT-401, FIT-504 AIT-504 (P-501) N/A UV-401 (P-501) DPIT-301 (MV-302) Yes DPIT-301 P-302, P-203 No No (20%) N/A LIT-401 Yes (25% at P3) Yes P-102, LIT-301 LIT-401 LIT-401 P-602, MV-303 LIT-401 (AIT-402) N/A Yes No FIT-401, AIT-504 N/A Yes LIT-101 22 23 24 25 26 27 28 29 30 P-201, P-203, P-205 LIT-101, P-101, MV-201 Detection (our Attack point work) (our work) Yes MV-101 Yes MV-101 (P-102) Not sure MV-101 (65%) (LIT-101) No N/A Yes AIT-202 MV-301 (MV-303) AIT-504 Attack point ([18]) N/A MV-301 (P-102) N/A N/A AIT-202 (P-203) LIT-301 (PIT-502) DPIT-301 (MV-302) FIT-401 (PIT-502) MV-304 (MV-302) N/A N/A MV-301 (MV-303) N/A MV-201, LIT-101 LIT-401, AIT-503 LIT-301 (FIT-301) 9 10 J. Kim et al. Table 3. Anomaly detection results compared with those of [18] (attacks 31 to 41) Attack # 31 Answer (by SWaT) LIT-401 32 33 34 LIT-301 LIT-101 P-101 35 P-101, P-102 36 LIT-101 37 P-501, FIT-502 AIT-402, AIT-502 38 39 Detection (our Attack point work) (our work) Not sure LIT-101 (50%) Yes LIT-301 Yes LIT-101 Yes P-101 Not sure (20% at P1, 45% at P3) Yes Yes Yes (15% at P5) Yes 40 FIT-401, AIT-502 FIT-401 41 LIT-301 Yes Yes P-101 LIT-101 FIT-401, FIT-504 MV-101, AIT-402, AIT-502 FIT-401 FIT-401, FIT-504 LIT-301 Attack point ([18]) P-602, MV-303 N/A N/A MV-201 (P-203) MV-201, MV-303 LIT-101, AIT-503 FIT-504 (FIT-503) AIT-502, AIT-402 FIT-401, P-201 UV-401 (FIT-401) N/A Impossible-to-find attacks It appears that attacks 4, 14, and 29 were impossible to detect (in red in Figure 5). The developed model, the model in [18], and the model in [10] all failed to detect attacks 4, 13, and 14. Attack 4 This attack opens MV-504 that does not exist in the dataset. The description [6] in SWaT’s list of attacks indicates that this attack has no impact. Attack 14 According to SUTD, the attack 14 failed because tank 301 was already full [6]. Attack 29 SUTD said that P-201, P-203, and P-205 did not start because of mechanical interlocks. In the dataset, nothing was changed around 2015/12/31 at 3:32:00 PM. Difficult-to-find attacks According to [6], attacks 13 and 24 have a small impact (represented in yellow in Figure 5). The developed model did not detect these attacks. The model also failed to detect attacks 19 and 25. Attack 13 This attack attempted to close MV-304 but MV-304 was closed later than when this attack occurred. In the SWaT dataset, MV-304 did not change. Anomaly Detection for ICSs Using Seq2Seq Neural Networks 11 Attack 19 This attack attempted to set value of AIT-504 to 16 µs/cm. AIT-504 is below 15 µs/cm in the normal state. In Figure 6, the attack appeared to be detected, but the high rate was derived from attack 20 which set a value of AIT504 to 255 µs/cm. the distances provided by the developed model are too short to detect for attack 19. The rate S was of approximately 20% for attack 19. Fig. 6. Attack 19 in process 5 (red: attack, purple: prediction error, and blue: anomaly score) Attack 24 This attack attempted to turn off P-203 and P-205 (both are pumps are used for injecting chemicals). However, there was only a small impact due to the closure of P-101. Attack 25 This attack attempted to set the value of LIT-401 to 1,000 and open P-402 while P-402 was still operating. LIT-401 presented notable distances but the rate was of approximately 20% (Figure 7). According to [18], attack 25 was detected but wrong attack points were determined. Managed-to-find attack The developed model managed to detect attack 35 with a rate of 45%. Attack 35 According to [6], attack 35 occurred at process 1, but herein, the attack was detected at process 3. Before the attack, P-101 was open, and P-202 was close. The attack opened P-101 and kept P-102 close. Figure 8 shows the attacks 34 and 35. Processes 1, 2, and 3 presented remarkable distances. The distance of process 2 appears to be large, but the scale is small. There are two high peaks of rate in process 1, but they come from the attack 34. Attack 34 closed P-101 (2 → 1) and opened P-102 (1 → 2). Later, P-101 was opened (1 → 2) at 17:14:59 and P-102 was closed (2 → 1). Attack 35 was different from attack 34 as it kept P-102 closed. In the training (normal) dataset, P-102 was closed (of value 1) at all time, which is why the developed model always indicated 1. Because P-102 is a backup pump for P-101, the developed 12 J. Kim et al. Fig. 7. Attack 25 in process 4 (red: attack, purple: prediction error, and blue: anomaly score) Table 4. Number of false positives. OP indicates the number of false positives for attacks on other processes, LT indicates the long-tailed detection (over 15 minutes), and TFP indicates the true false positives. Process False positives (all duplicates) OP LT TFP 1 2 3 4 5 7(11) 5(8) 0 1(1) 0 4 0 1 - 2 0 0 - 1 5 0 - model must understand their connection. However, the model could not learn the connection as the training dataset did not give enough information. 4.2 Analysis on False Positives (False Alarms) This subsection analyzes false positives. The evaluation script is also available at https://github.com/jukworks/swat-seq2seq/tree/master/evaluation. Sixty seven false positives were obtained from all models, and many of them were timely overlapped. After removing the duplicates, twenty false positives were found. The number of false positives is presented in Table 4. Processes 3 and 5 present no false positives. The decision method described in Section 2.5 reacted twice at the start and end of the attack. The second column represents the number of false positives after removing the duplicates. The third column, OP, represents the number of positives caused by the attacks on the other processes. The fourth column, LT, represents the number of long-tailed positives. 15 minutes after the end of the attack as a true-positive, but sometimes the tail was too long and the attack lasted over 15 minutes. The long-tail positives were not counted as true-positives. In summary, there was one true false positive (TFP, the fifth column) in process 1 and five in process 2. Anomaly Detection for ICSs Using Seq2Seq Neural Networks 13 Fig. 8. Attacks 34 and 35 in processes 1, 2, and 3 (red: attack, purple: prediction error, and blue: anomaly score) False positives in process 1 There were eleven false positives in process 1. In Table 5, (2, 3), (4, 5), (7, 8), and (10, 11) are pairs of start-end having the same related attacks. Therefore there were seven independent false positives. One of them was true false positive. Four of them were simultaneous detection for attacks targeting other processes. Two of them were long-tail detection. False positives in process 2 The developed model for process 2 created eight false positives. In Table 6, pairs (1, 2), (4, 5), and (6, 7) have the same related attacks. Therefore, there were five independent false positives, and four of them were true. Most false positives occurred at P-201, P-205, and MV-201. P-201 is the NaCl injection jump; P-205 is the NaOCl injection pump. In the training dataset, P201 never changed. We guess that the model regarded any change of P-201 as an attack. AIT-201, a sensor for NaCl, caused a false positive (No. 8 in Table 6) because P-201 had changed the level of NaCl. After the last false positive, the prediction errors of AIT-201 and AIT-203 went high. AIT-201 and AIT-203 are sensors for NaCl and NaOCl, respectively. We guess that the unexpected behaviors of P-201 and P-205 led to new but normal dataset. False positives in process 4 In Table 7, there was one false positive in process 4, which came from attack 37 hitting process 5. 14 J. Kim et al. Table 5. The analysis of false positives in process 1. OP means the number of false positives for attacks on other processes; LT for long-tailed detection (over 15 minutes); TFP for true false positives. No. Time Related attacks Tags Type of false positive 1 2015-12-28 12:19:05 PM - 2015-12-28 12:20:46 PM 2015-12-29 02:32:36 PM - 2015-12-29 02:36:34 PM 2015-12-29 02:39:42 PM - 2015-12-29 02:43:39 PM 2015-12-30 01:51:41 PM - 2015-12-30 01:55:36 PM 2015-12-30 02:06:12 PM - 2015-12-30 02:09:55 PM 2015-12-30 06:20:01 PM - 2015-12-30 06:21:07 PM 2016-01-01 10:58:18 AM - 2016-01-01 11:02:11 AM 2016-01-01 11:10:06 AM - 2016-01-01 11:13:38 AM 2016-01-01 03:02:23 PM - 2016-01-01 03:04:04 PM 2016-01-02 11:32:16 AM - 2016-01-02 11:36:10 2016-01-02 11:47:29 AM - 2016-01-02 11:51:04 AM 7 P-101 OP 17 MV-101 OP 17 MV-101 OP - MV-101 TFP - MV-101 TFP 26 - LT 32 MV-101 OP 32 MV-101 OP 33 - LT 38 P-101 OP 38 P-101 OP 2 3 4 5 6 7 8 9 10 11 5 Conclusion It is difficult to get internal specification and control logic of ICSs. If routine ICS operational data is the only information available, a data-driven approach is a proper way to develop security products. We proposed an anomaly detection method for industrial control systems using sequence-to-sequence neural networks with attention. Due to the difficulty of defining the abnormal state, the model learns the normal dataset in an unsupervised way. In the detection phase, the model predicts future values based on the previously observed ones. The difference between the model’s prediction and the measured value is the key criterion to detect anomalies. The alarm decision depends on the threshold, and heuristic hyper-parameters were necessary for this experiment. Our proposed method is not dedicated to the dataset. It can be generalized to train any ICS datasets and extract the decision grounds because the specification of operational data and control logic inside was not required. It is also able to detect anomalies with only the dataset from normal operations.
Graph Neural Network-Based Anomaly Detection in Multivariate Time Series Abstract allow them to diagnose and respond to the anomaly as quickly as possible. Due to the inherent lack of labeled anomalies in historical data, and the unpredictable and highly varied nature of anomalies, the anomaly detection problem is typically treated as an unsupervised learning problem. In past years, many classical unsupervised approaches have been developed, including linear model-based approaches (Shyu et al. 2003), distance-based methods (Angiulli and Pizzuti 2002), and one-class methods based on support vector machines (Schölkopf et al. 2001). However, such approaches generally model inter-relationships between sensors in relatively simple ways: for example, capturing only linear relationships, which is insufficient for complex, highly nonlinear relationships in many real-world settings. Recently, deep learning-based techniques have enabled improvements in anomaly detection in high-dimensional datasets. For instance, Autoencoders (AE) (Aggarwal 2015) are a popular approach for anomaly detection which uses reconstruction error as an outlier score. More recently, Generative Adversarial Networks (GANs) (Li et al. 2019) and LSTM-based approaches (Qin et al. 2017) have also reported promising performance for multivariate anomaly detection. However, most methods do not explicitly learn which sensors are related to one another, thus facing difficulties in modelling sensor data with many potential interrelationships. This limits their ability to detect and explain deviations from such relationships when anomalous events occur. How do we take full advantage of the complex relationships between sensors in multivariate time series? Recently, graph neural networks (GNNs) (Defferrard, Bresson, and Vandergheynst 2016) have shown success in modelling graph-structured data. These include graph convolution networks (GCNs) (Kipf and Welling 2016), graph attention networks (GATs) (Veličković et al. 2017) and multi-relational approaches (Schlichtkrull et al. 2018). However, applying them to time series anomaly detection requires overcoming two main challenges. Firstly, different sensors have very different behaviors: e.g. one may measure water pressure, while another measures flow rate. However, typical GNNs use the same model parameters to model the behavior of each node. Secondly, in our setting, the graph edges (i.e. relationships between sensors) are initially unknown, and have Given high-dimensional time series data (e.g., sensor data), how can we detect anomalous events, such as system faults and attacks? More challengingly, how can we do this in a way that captures complex inter-sensor relationships, and detects and explains anomalies which deviate from these relationships? Recently, deep learning approaches have enabled improvements in anomaly detection in high-dimensional datasets; however, existing methods do not explicitly learn the structure of existing relationships between variables, or use them to predict the expected behavior of time series. Our approach combines a structure learning approach with graph neural networks, additionally using attention weights to provide explainability for the detected anomalies. Experiments on two real-world sensor datasets with ground truth anomalies show that our method detects anomalies more accurately than baseline approaches, accurately captures correlations between sensors, and allows users to deduce the root cause of a detected anomaly. 1 Introduction With the rapid growth in interconnected devices and sensors in Cyber-Physical Systems (CPS) such as vehicles, industrial systems and data centres, there is an increasing need to monitor these devices to secure them against attacks. This is particularly the case for critical infrastructures such as power grids, water treatment plants, transportation, and communication networks. Many such real-world systems involve large numbers of interconnected sensors which generate substantial amounts of time series data. For instance, in a water treatment plant, there can be numerous sensors measuring water level, flow rates, water quality, valve status, and so on, in each of their many components. Data from these sensors can be related in complex, nonlinear ways: for example, opening a valve results in changes in pressure and flow rate, leading to further changes as automated mechanisms respond to the change. As the complexity and dimensionality of such sensor data grow, humans are increasingly less able to manually monitor this data. This necessitates automated anomaly detection approaches which can rapidly detect anomalies in highdimensional data, and explain them to human operators to Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. 4027 Multivariate Time Series Modelling These approaches generally model the behavior of a multivariate time series based on its past behavior. A comprehensive summary is given in (Blázquez-Garcı́a et al. 2020). Classical methods include auto-regressive models (Hautamaki, Karkkainen, and Franti 2004) and the auto-regressive integrated moving average (ARIMA) models (Zhang et al. 2012; Zhou et al. 2018), based on a linear model given the past values of the series. However, their linearity makes them unable to model complex nonlinear characteristics in time series, which we are interested in. To learn representations for nonlinear high-dimensional time series and predict time series data, deep learningbased time series methods have attracted interest. These techniques, such as Convolutional Neural Network (CNN) based models (Munir et al. 2018), Long Short Term Memory (LSTM) (Filonov, Lavrentyev, and Vorontsov 2016; Hundman et al. 2018a; Park, Hoshi, and Kemp 2018) and Generative Adversarial Networks (GAN) models (Zhou et al. 2019; Li et al. 2019), have found success in practical time series tasks. However, they do not explicitly learn the relationships between different time series, which are meaningful for anomaly detection: for example, they can be used to diagnose anomalies by identifying deviations from these relationships. Graph-based methods provide a way to model the relationships between sensors by representing the interdependencies with edges. Such methods include probabilistic graphical models, which encode joint probability distributions, as described in (Bach and Jordan 2004; Tank, Foti, and Fox 2015). However, most existing methods are designed to handle stationary time series, and have difficulty modelling more complex and highly non-stationary time series arising from sensor settings. to be learned along with our model, while GNNs typically treat the graph as an input. Hence, in this work, we propose our novel Graph Deviation Network (GDN) approach, which learns a graph of relationships between sensors, and detects deviations from these patterns1 . Our method involves four main components: 1) Sensor Embedding, which uses embedding vectors to flexibly capture the unique characteristics of each sensor; 2) Graph Structure Learning learns the relationships between pairs of sensors, and encodes them as edges in a graph; 3) Graph Attention-Based Forecasting learns to predict the future behavior of a sensor based on an attention function over its neighboring sensors in the graph; 4) Graph Deviation Scoring identifies and explains deviations from the learned sensor relationships in the graph. To summarize, the main contributions of our work are: • We propose GDN, a novel attention-based graph neural network approach which learns a graph of the dependence relationships between sensors, and identifies and explains deviations from these relationships. • We conduct experiments on two water treatment plant datasets with ground truth anomalies. Our results demonstrate that GDN detects anomalies more accurately than baseline approaches. • We show using case studies that GDN provides an explainable model through its embeddings and its learned graph. We show that it helps to explain an anomaly, based on the subgraph over which a deviation is detected, attention weights, and by comparing the predicted and actual behavior on these sensors. 2 Related Work We first review methods for anomaly detection, and methods for multivariate time series data, including graph-based approaches. Since our approach relies on graph neural networks, we summarize related work in this topic as well. Graph Neural Networks In recent years, graph neural networks (GNNs) have emerged as successful approaches for modelling complex patterns in graph-structured data. In general, GNNs assume that the state of a node is influenced by the states of its neighbors. Graph Convolution Networks (GCNs) (Kipf and Welling 2016) model a node’s feature representation by aggregating the representations of its one-step neighbors. Building on this approach, graph attention networks (GATs) (Veličković et al. 2017) use an attention function to compute different weights for different neighbors during this aggregation. Related variants have shown success in time-dependent problems: for example, GNN-based models can perform well in traffic prediction tasks (Yu, Yin, and Zhu 2017; Chen et al. 2019). Applications in recommendation systems (Lim et al. 2020; Schlichtkrull et al. 2018) and relative applications (Wang et al. 2020) verify the effectiveness of GNN to model large-scale multi-relational data. However, these approaches use the same model parameters to model the behavior of each node, and hence face limitations in representing very different behaviors of different sensors. Moreover, GNNs typically require the graph structure as an input, whereas the graph structure is initially unknown in our setting, and needs to be learned from data. Anomaly Detection Anomaly detection aims to detect unusual samples which deviate from the majority of the data. Classical methods include density-based approaches (Breunig et al. 2000), linear-model based approaches (Shyu et al. 2003), distance-based methods (Angiulli and Pizzuti 2002), classification models (Schölkopf et al. 2001), detector ensembles (Lazarevic and Kumar 2005) and many others. More recently, deep learning methods have achieved improvements in anomaly detection in high-dimensional datasets. These include approaches such as autoencoders (AE) (Aggarwal 2015), which use reconstruction error as an anomaly score, and related variants such as variational autoencoders (VAEs) (Kingma and Welling 2013), which develop a probabilistic approach, and autoencoders combining with Gaussian mixture modelling (Zong et al. 2018). However, our goal is to develop specific approaches for multivariate time series data, explicitly capturing the graph of relationships between sensors. 1 The code is available at https://github.com/d-ailin/GDN 4028 1. Sensor Embedding Input: vi .. . … N sensors 3.3 N sensors Time 2. Graph Structure Learning X3 Learned Relations … X1 3. Graph Attention-Based Forecasting X2 Attention-Based Features Z1 Forecast ... Z2 4. Graph Deviation Scoring Observation Z3 Prediction Figure 1: Overview of our proposed framework. 3 3.1 Proposed Framework Problem Statement In this paper, our training data consists of sensor (i.e. multivariate time series) data from N sensors i h over Ttrain time (T ) (1) ticks: the sensor data is denoted strain = strain , · · · , straintrain , which is used to train our approach. In each time tick t, the (t) sensor values strain ∈ RN form an N dimensional vector representing the values of our N sensors. Following the usual unsupervised anomaly detection formulation, the training data is assumed to consist of only normal data. Our goal is to detect anomalies in testing data, which comes from the same N sensors but over a separate hset of Ttest timei ticks: the test data is denoted stest = (T ) (1) stest , · · · , stesttest . The output of our algorithm is a set of Ttest binary labels indicating whether each test time tick is an anomaly or not, i.e. a(t) ∈ {0, 1}, where a(t) = 1 indicates that time t is anomalous. 3.2 Sensor Embedding In many sensor data settings, different sensors can have very different characteristics, and these characteristics can be related in complex ways. For example, imagine we have two water tanks, each containing a sensor measuring the water level in the tank, and a sensor measuring the water quality in the tank. Then, it is plausible that the two water level sensors would behave similarly, and the two water quality sensors would behave similarly. However, it is equally plausible that sensors within the same tank would exhibit strong correlations. Hence, ideally, we would want to represent each sensor in a flexible way that captures the different ‘factors’ underlying its behavior in a multidimensional way. Hence, we do this by introducing an embedding vector for each sensor, representing its characteristics: vi ∈ Rd , for i ∈ {1, 2, · · · , N } These embeddings are initialized randomly and then trained along with the rest of the model. Similarity between these embeddings vi indicates similarity of behaviors: hence, sensors with similar embedding values should have a high tendency to be related to one another. In our model, these embeddings will be used in two ways: 1) for structure learning, to determine which sensors are related to one another, and 2) in our attention mechanism, to perform attention over neighbors in a way that allows heterogeneous effects for different types of sensors. 3.4 Graph Structure Learning A major goal of our framework is to learn the relationships between sensors in the form of a graph structure. To do this, we will use a directed graph, whose nodes represent sensors, and whose edges represent dependency relationships between them. An edge from one sensor to another indicates that the first sensor is used for modelling the behavior of the second sensor. We use a directed graph because the dependency patterns between sensors need not be symmetric. We use an adjacency matrix A to represent this directed graph, where Aij represents the presence of a directed edge from node i to node j. We design a flexible framework which can be applied either to 1) the usual case where we have no prior information about the graph structure, or 2) the case where we have some prior information about which edges are plausible (e.g. the sensor system may be divided into parts, where sensors in different parts have minimal interaction). This prior information can be flexibly represented as a set of candidate relations Ci for each sensor i, i.e. the sensors it could be dependent on: Ci ⊆ {1, 2, · · · , N } \ {i} (1) In the case without prior information, the candidate relations of sensor i is simply all sensors, other than itself. To select the dependencies of sensor i among these candidates, we compute the similarity between node i’s embedding vector, and the embeddings of its candidates j ∈ Ci : vi > vj eji = for j ∈ Ci (2) kvi k · kvj k Aji = 1{j ∈ TopK({eki : k ∈ Ci })} (3) Overview Our GDN method aims to learn relationships between sensors as a graph, and then identifies and explains deviations from the learned patterns. It involves four main components: 1. Sensor Embedding: uses embedding vectors to capture the unique characteristics of each sensor; 2. Graph Structure Learning: learns a graph structure representing dependence relationships between sensors; 3. Graph Attention-Based Forecasting: forecasts future values of each sensor based on a graph attention function over its neighbors; 4. Graph Deviation Scoring: identifies deviations from the learned relationships, and localizes and explains these deviations. Figure 1 provides an overview of our framework. 4029 (t) That is, we first compute eji , the normalized dot product between the embedding vectors of sensor i, and the candidate relation j ∈ Ci . Then, we select the top k such normalized dot products: here TopK denotes the indices of top-k values among its input (i.e. the normalized dot products). The value of k can be chosen by the user according to the desired sparsity level. Next, we will define our graph attention-based model which makes use of this learned adjacency matrix A. 3.5 feature Wxi , and a is a vector of learned coefficients for the attention mechanism. We use LeakyReLU as the nonlinear activation to compute the attention coefficient, and normalize the attention coefficents using the softmax function in Eq. (8). Output Layer From the above feature extractor, we obtain (t) (t) representations for all N nodes, namely {z1 , · · · , zN }. (t) For each zi , we element-wise multiply (denoted ◦) it with the corresponding time series embedding vi , and use the results across all nodes as the input of stacked fully-connected layers with output dimensionality N , to predict the vector of sensor values at time step t, i.e. s(t) : h i (t) (t) ŝ(t) = fθ v1 ◦ z1 , · · · , vN ◦ zN (9) Graph Attention-Based Forecasting In order to provide useful explanations for anomalies, we would like our model to tell us: • Which sensors are deviating from normal behavior? • In what ways are they deviating from normal behavior? To achieve these goals, we use a forecasting-based approach, where we forecast the expected behavior of each sensor at each time based on the past. This allows the user to easily identify the sensors which deviate greatly from their expected behavior. Moreover, the user can compare the expected and observed behavior of each sensor, to understand why the model regards a sensor as anomalous. Thus, at time t, we define our model input x(t) ∈ RN ×w based on a sliding window of size w over the historical time series data (whether training or testing data): h i x(t) := s(t−w) , s(t−w+1) , · · · , s(t−1) (4) The model’s predicted output is denoted as ŝ(t) . We use the Mean Squared Error between the predicted output ŝ(t) and the observed data, s(t) , as the loss function for minimization: LMSE = 3.6 Feature Extractor To capture the relationships between sensors, we introduce a graph attention-based feature extractor to fuse a node’s information with its neighbors based on the learned graph structure. Unlike existing graph attention mechanisms, our feature extractor incorporates the sensor embedding vectors vi , which characterize the different behaviors of different types of sensors. To do this, we compute node i’s aggregated representation zi as follows:   X (t) (t) (t) zi = ReLU αi,i Wxi + αi,j Wxj  , (5) (t) (t) (t) π (i, j) = LeakyReLU a> gi ⊕ gj αi,j = P exp (π (i, j)) , k∈N (i)∪{i} exp (π (i, k))  (11) (8) A (t) = max ai (t) (6)  (t) (7) the learned adjacency matrix A, W ∈ R is a trainable weight matrix which applies a shared linear transformation to every node, and the attention coefficients αi,j are computed as:  (10) As different sensors can have very different characteristics, their deviation values may also have very different scales. To prevent the deviations arising from any one sensor from being overly dominant over the other sensors, we perform a robust normalization of the error values of each sensor: Erri (t) − µ ei ai (t) = , (12) σ ei where µ ei and σ ei are the median and inter-quartile range (IQR2 ) across time ticks of the Erri (t) values respectively. We use median and IQR instead of mean and standard deviation as they are more robust against anomalies. Then, to compute the overall anomalousness at time tick t, we aggregate over sensors using the max function (we use max as it is plausible for anomalies to affect only a small subset of sensors, or even a single sensor) : j∈N (i) (t) 2 Graph Deviation Scoring Erri (t) = |si − ŝi | (t) where xi ∈ Rw is node i’s input feature, N (i) = {j | Aji > 0} is the set of neighbors of node i obtained from d×w (t) 2 Given the learned relationships, we want to detect and explain anomalies which deviate from these relationships. To do this, our model computes individual anomalousness scores for each sensor, and also combines them into a single anomalousness score for each time tick, thus allowing the user to localize which sensors are anomalous, as we will show in our experiments. The anomalousness score compares the expected behavior at time t to the observed behavior, computing an error value Err at time t and sensor i: The target output that our model needs to predict is the sensor data at the current time tick, i.e. s(t) . gi = vi ⊕ Wxi Ttrain X 1 ŝ(t) − s(t) Ttrain − w t=w+1 i 2 (13) IQR is defined as the difference between the 1st and 3rd quartiles of a distribution or set of values, and is a robust measure of the distribution’s spread. (t) where ⊕ denotes concatenation; thus gi concatenates the sensor embedding vi and the corresponding transformed 4030 To dampen abrupt changes in values are often not perfectly predicted and result in sharp spikes in error values even when this behavior is normal, similar with (Hundman et al. 2018b), we use a simple moving average(SMA) to generate the smoothed scores As (t). Finally, a time tick t is labelled as an anomaly if As (t) exceeds a fixed threshold. While different approaches could be employed to set the threshold such as extreme value theory (Siffer et al. 2017), to avoid introducing additional hyperparameters, we use in our experiments a simple approach of setting the threshold as the max of As (t) over the validation data. 4 #Features #Train #Test Anomalies SWaT WADI 51 127 47515 118795 44986 17275 11.97% 5.99% Table 1: Statistics of the two datasets used in experiments 4.2 Baselines We compare the performance of our proposed method with five popular anomaly detection methods, including: • PCA: Principal Component Analysis (Shyu et al. 2003) finds a low-dimensional projection that captures most of the variance in the data. The anomaly score is the reconstruction error of this projection. Experiments In this section, we conduct experiments to answer the following research questions: • RQ1 (Accuracy): Does our method outperform baseline methods in accuracy of anomaly detection in multivariate time series, based on ground truth labelled anomalies? • RQ2 (Ablation): How do the various components of the method contribute to its performance? • RQ3 (Interpretability of Model): How can we understand our model based on its embeddings and its learned graph structure? • RQ4 (Localizing Anomalies): Can our method localize anomalies and help users to identify the affected sensors, as well as to understand how the anomaly deviates from the expected behavior? 4.1 Datasets • KNN: K Nearest Neighbors uses each point’s distance to its kth nearest neighbor as an anomaly score (Angiulli and Pizzuti 2002). • FB: A Feature Bagging detector is a meta-estimator that fits a number of detectors on various sub-samples of the dataset, then aggregates their scores (Lazarevic and Kumar 2005). • AE: Autoencoders consist of an encoder and decoder which reconstruct data samples (Aggarwal 2015). It uses the reconstruction error as the anomaly score. • DAGMM: Deep Autoencoding Gaussian Model joints deep Autoencoders and Gaussian Mixture Model to generate a low-dimensional representation and reconstruction error for each observation (Zong et al. 2018). Datasets As real-world datasets with labeled ground-truth anomalies are scarce, especially for large-scale plants and factories, we use two sensor datasets based on water treatment physical test-bed systems: SWaT and WADI, where operators have simulated attack scenarios of real-world water treatment plants, recording these as the ground truth anomalies. The Secure Water Treatment (SWaT) dataset comes from a water treatment test-bed coordinated by Singapore’s Public Utility Board (Mathur and Tippenhauer 2016). It represents a small-scale version of a realistic modern Cyber-Physical system, integrating digital and physical elements to control and monitor system behaviors. As an extension of SWaT, Water Distribution (WADI) is a distribution system comprising a larger number of water distribution pipelines (Ahmed, Palleti, and Mathur 2017). Thus WADI forms a more complete and realistic water treatment, storage and distribution network. The datasets contain two weeks of data from normal operations, which are used as training data for the respective models. A number of controlled, physical attacks are conducted at different intervals in the following days, which correspond to the anomalies in the test set. Table 1 summarises the statistics of the two datasets. In order to speed up training, the original data samples are downsampled to one measurement every 10 seconds by taking the median values. The resulting label is the most common label during the 10 seconds. Since the systems took 5-6 hours to reach stabilization when first turned on (Goh et al. 2016), we eliminate the first 2160 samples for both datasets. • LSTM-VAE: LSTM-VAE (Park, Hoshi, and Kemp 2018) replaces the feed-forward network in a VAE with LSTM to combine LSTM and VAE. It can measure reconstruction error with the anomaly score. • MAD-GAN: A GAN model is trained on normal data, and the LSTM-RNN discriminator along with a reconstruction-based approach is used to compute anomaly scores for each sample (Li et al. 2019). 4.3 Evaluation Metrics We use precision (Prec), recall (Rec) and F1-Score (F1) over the test dataset and its ground truth values to evaluate the performance of our method and baseline models: TP TP F1 = 2×Prec×Rec Prec+Rec , where Prec = TP+FP and Rec = TP+FN , and TP, TN, FP, FN are the numbers of true positives, true negatives, false positives, and false negatives. Note that our datasets are unbalanced, which justifies the choice of these metrics, which are suitable for unbalanced data. To detect anomalies, we use the maximum anomaly score over the validation dataset to set the threshold. At test time, any time step with an anomaly score over the threshold will be regarded as an anomaly. 4.4 Experimental Setup We implement our method and its variants in PyTorch (Paszke et al. 2017) version 1.5.1 with CUDA 10.2 and PyTorch Geometric Library (Fey and Lenssen 2019) 4031 SWaT SWaT WADI Method Prec Rec F1 Prec Rec F1 PCA KNN FB AE DAGMM LSTM-VAE MAD-GAN 24.92 7.83 10.17 72.63 27.46 96.24 98.97 21.63 7.83 10.17 52.63 69.52 59.91 63.74 0.23 0.08 0.10 0.61 0.39 0.74 0.77 39.53 7.76 8.60 34.35 54.44 87.79 41.44 5.63 7.75 8.60 34.35 26.99 14.45 33.92 0.10 0.08 0.09 0.34 0.36 0.25 0.37 GDN 99.35 68.12 0.81 97.50 40.19 0.57 Method Prec Rec WADI F1 Prec Rec F1 GDN 99.35 68.12 0.81 97.50 40.19 0.57 - T OP K - E MB - ATT 97.41 92.31 71.05 64.70 61.25 65.06 0.78 0.76 0.68 92.21 91.86 61.33 35.12 33.49 38.85 0.51 0.49 0.48 Table 3: Anomaly detection accuracy in term of percision(%), recall(%), and F1-score of GDN and its variants. Table 2: Anomaly detection accuracy in terms of precision(%), recall(%), and F1-score, on two datasets with ground-truth labelled anomalies. Part of the results are from (Li et al. 2019). 2_FIC_101_C 2_FIC_101_CO O 2_FIC_201_CO version 1.5.0, and train them on a server with Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz and 4 NVIDIA RTX 2080Ti graphics cards. The models are trained using the Adam optimizer with learning rate 1 × 10−3 and (β1 , β2 ) = (0.9, 0.99). We train models for up to 50 epochs and use early stopping with patience of 10. We use embedding vectors with length of 128(64), k with 30(15) and hidden layers of 128(64) neurons for the WADI (SWaT) dataset, corresponding to their difference in input dimensionality. We set the sliding window size w as 5 for both datasets. 4.5 2_FIC_201_C 2_FIC_301_CO ... ... 2_FIC_301_C O O Figure 2: A t-SNE plot of the sensor embeddings of our trained model on the WADI dataset. Node colors denote classes. Specifically, the dashed circled region shows localized clustering of 2 FIC x01 CO sensors. These sensors are measuring similar indicators in WADI. RQ1. Accuracy In Table 2, we show the anomaly detection accuracy in terms of precision, recall and F1-score, of our GDN method and the baselines, on the SWaT and WADI datasets. The results show that GDN outperforms the baselines in both datasets, with high precision in both datasets of 0.99 on SWaT and 0.98 on WADI. In terms of F-measure, GDN outperforms the baselines on SWaT; on WADI, it has 54% higher F-measure than the next best baseline. WADI is more unbalanced than SWaT and has higher dimensionality than SWaT as shown in Table 1. Thus, our method shows effectiveness even in unbalanced and high-dimensional attack scenarios, which are of high importance in real-world applications. 4.6 the graph structure learner enhances performance, especially for large-scale datasets. • The variant which removes the sensor embedding from the attention mechanism underperforms the original model in both datasets. This implies that the embedding feature improves the learning of weight coefficients in the graph attention mechanism. • Removing the attention mechanism degrades the model’s performance most in our experiments. Since sensors have very different behaviors, treating all neighbors equally introduces noise and misleads the model. This verifies the importance of the graph attention mechanism. RQ2. Ablation To study the necessity of each component of our method, we gradually exclude the components to observe how the model performance degrades. First, we study the importance of the learned graph by substituting it with a static complete graph, where each node is linked to all the other nodes. Second, to study the importance of the sensor embeddings, we use an attention mechanism without sensor embeddings: that is, gi = Wxi in Eq. (6). Finally, we disable the attention mechanism, instead aggregating using equal weights assigned to all neighbors. The results are summarized in Table 3 and provide the following findings: These findings suggest that GDN’s use of a learned graph structure, sensor embedding, and attention mechanisms all contribute to its accuracy, which provides an explanation for its better performance over the baseline methods. 4.7 RQ3. Interpretability of Model Interpretability via Sensor Embeddings To explain the learned model, we can visualize its sensor embedding vectors, e.g. using t-SNE(Maaten and Hinton 2008), shown on the WADI dataset in Figure 2. Similarity in this embedding space indicate similarity between the sensors’ behaviors, so inspecting this plot allows the user to deduce groups of sensors which behave in similar ways. • Replacing the learned graph structure with a complete graph degrades performance in both datasets. The effect on the WADI dataset is more obvious. This indicates that 4032 1_AIT_005_PV 1_FIT_001_PV 1_MV_001_STATUS 1_LT_001_PV 1_FIT_001_PV 1_MV_001_STATUS Figure 3: Left: Force-directed graph layout with attention weights as edge weights, showing an attack in WADI. The red triangle denotes the central sensor identified by our approach, with highest anomaly score. Red circles indicate nodes with edge weights larger than 0.1 to the central node. Right: Comparing expected and observed data helps to explain the anomaly. The attack period is shaded in red. To validate this, we color the nodes using 7 colors corresponding to 7 classes of sensors in WADI systems. The representation exhibits localized clustering in the projected 2D space, which verifies the effectiveness of the learned feature representations to reflect the localized sensors’ behavior similarity. Moreover, we observe a group of sensors forming a localized cluster, shown in the dashed circled region. Inspecting the data, we find that these sensors measure similar indicators in water tanks that perform similar functions in the WADI water distribution network, explaining the similarity between these sensors. Figure 3 (left). The large deviation at this sensor indicates that 1 MV 001 STATUS could be the attacked sensor, or closely related to the attacked sensor. GDN indicates (in red circles) the sensors with highest attention weights to the deviating sensor. Indeed, these neighbors are closely related sensors: the 1 FIT 001 PV neighbor is normally highly correlated with 1 MV 001 STATUS, as the latter shows the valve status for a valve which controls the flow measured by the former. However, the attack caused a deviation from this relationship, as the attack gave false readings only to 1 FIT 001 PV. GDN further allows understanding of this anomaly by comparing the predicted and observed sensor values in Figure 3 (right): for 1 MV 001 STATUS, our model predicted an increase (as 1 FIT 001 PV increased, and our model has learned that the sensors increase together). Due to the attack, however, no change was observed in 1 MV 001 STATUS, leading to a large error which was detected as an anomaly by GDN. In summary: 1) our model’s individual anomaly scores help to localize anomalies; 2) its attention weights help to find closely related sensors; 3) its predictions of expected behavior of each sensor allows us to understand how anomalies deviate from expectations. Interpretability via Graph Edges and Attention Weights Edges in our learned graph provide interpretability by indicating which sensors are related to one another. Moreover, the attention weights further indicate the importance of each of a node’s neighbors in modelling the node’s behavior. Figure 3 (left) shows an example of this learned graph on the WADI dataset. The following subsection further shows a case study of using this graph to localize and understand an anomaly. 4.8 RQ4. Localizing Anomalies How well can our model help users to localize and understand an anomaly? Figure 3 (left) shows the learned graph of sensors, with edges weighted by their attention weights, and plotted using a force-directed layout(Kobourov 2012). We conduct a case study involving an anomaly with a known cause: as recorded in the documentation of the WADI dataset, this anomaly arises from a flow sensor, 1 FIT 001 PV, being attacked via false readings. These false readings are within the normal range of this sensor, so detecting this anomaly is nontrivial. During this attack period, GDN identifies 1 MV 001 STATUS as the deviating sensor with the highest anomaly score, as indicated by the red triangle in 5 Conclusion In this work, we proposed our Graph Deviation Network (GDN) approach, which learns a graph of relationships between sensors, and detects deviations from these patterns, while incorporating sensor embeddings. Experiments on two real-world sensor datasets showed that GDN outperformed baselines in accuracy, provides an interpretable model, and helps users to localize and understand anomalies. Future work can consider additional architectures and online training methods, to further improve the practicality of the approach.
Information Hiding in Cyber Physical Systems: Challenges for Embedding, Retrieval and Detection using Sensor Data of the SWAT Dataset ABSTRACT CCS CONCEPTS In this paper, we present an Information Hiding approach that would be suitable for exfiltrating sensible information of Industrial Control Systems (ICS) by leveraging the long-term storage of process data in historian databases. We show how hidden messages can be embedded in sensor measurements as well as retrieved asynchronously by accessing the historian. We evaluate this approach at the example of water-flow and water-level sensors of the Secure Water Treatment (SWAT) dataset from iTrust. To generalize from specific cover channels (sensors and their transmitted data), we reflect upon general challenges that arise in such Information Hiding scenarios creating network covert channels and discuss aspects of cover channel selection and and sender receiver synchronisation as well as temporal aspects such as the potential persistence of hidden messages in Cyber Physical Systems (CPS). For an empirical evaluation we design and implement a covert channel that makes use of different embedding strategies to perform an adaptive approach in regards to the noise in sensor measurements, resulting in dynamic capacity and bandwidth selection to reduce detection probability. The results of this evaluation show that, using such methods, the exfiltration of sensible information in long-term scaled attacks would indeed be possible. Additionally, we present two detection approaches for the introduced hidden channel and carry out an extensive evaluation of our detectors with multiple test data sets and different parameters. We determine a detection accuracy of up to 87.8% on test data at a false positive rate (FPR) of 0%. • Security and privacy → Network security; Systems security; Intrusion detection systems; Security in hardware; Firewalls; Systems security; Intrusion detection systems; • Applied computing → Industry and manufacturing; • Social and professional topics → Computer crime; Automation; Computer crime; • Theory of computation → Cryptographic protocols. KEYWORDS Information Hiding; Steganography; Covert Channels; Network Covert Channels; Cyber Physical Systems; Industrial Control Systems; Sensors; Steganalysis; Detection; Warden ACM Reference Format: Kevin Lamshöft, Christian Krätzer, Jana Dittmann, Tom Neubert, and Claus Vielhauer. 2021. Information Hiding in Cyber Physical Systems: Challenges for Embedding, Retrieval and Detection using Sensor Data of the SWAT Dataset. In Proceedings of the 2021 ACM Workshop on Information Hiding and Multimedia Security (IHMMSec ’21), June 22–25, 2021, Virtual Event, Belgium. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3437880.3460413 1 INTRODUCTION Information Hiding in the field of network steganography has recently attract more attention, as targeted attacks have begun to use stealth mechanisms to avoid early detection, especially in the context of so called Supply Chain Attacks like the recent SolarWinds attacks [1]. As recent publications show, Information Hiding acts as a novel threat for Industrial Control Systems (ICS) and Cyber Physical Systems (CPS) in general, as they enable attackers to infiltrate systems, exfiltrate valuable information and establish command and control channels in such a stealthy way that common intrusion detection and prevention systems are likely to fail (i.e. do not reliably detect such attacks [14]). Another application of (Network-) Information Hiding is to avoid detection of lateral movement in an attacked domain after the first initial intrusion, and can especially be used to circumvent firewalls and other means of network segregation (incl. air gapping). To establish stealthy covert channels, one common way in Network Information Hiding is to identify fields in network protocols which usually contain high entropy content and then modify these to embed hidden messages [10]. In this paper, we evaluate the feasibility of four selected embedding methods to hide information in the transmission of sensor readings ∗ Kevin Lamshöft provided the idea, concept and realisation of the presented covert channel and contributed to the paper in a whole. Christian Krätzer contributed to Section 1 and 2 and gave the initial idea for the proposed synchronisation method. Jana Dittmann contributed to the overall structure by improvements in the systematical structuring of the findings and contributions, in the formalization of the approach, the discussion of embedding and retrieval keys and Figure 1. † Tom Neubert contributed the idea, concept and evaluation of detection approaches in Sections 5 and 6. Claus Vielhauer contributed to the overall structure of the paper, Figure 1 and the general design of detection and evaluation in Sections 5 and 6. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. Thisallwork licensed underthe a Creative Commons Attribution-NonCommercialFor otheris uses, contact owner/author(s). NoDerivs’21, International 4.02021, License. IHMMSec June 22–25, Virtual Event, Belgium ©IH&MMSec 2021 Copyright held by the owner/author(s). ’21, June 22–25, 2021, Virtual Event, Belgium. ACM ISBN 978-1-4503-8295-3/21/06. © 2021 Copyright held by the owner/author(s). https://doi.org/10.1145/3437880.3460413 ACM ISBN 978-1-4503-8295-3/21/06. https://doi.org/10.1145/3437880.3460413 113 IH&MMSec ’21, June 22–25, 2021, Virtual Event, Belgium Session 5: Steganography I IHMMSec ’21, June 22–25, 2021, Virtual Event, Belgium Lamshöft and Neubert, et al. relates to the paradigm of performing pooled steganalysis on batch steganography. This concept, introduced in 2007 in [11] focuses on the problems of hiding information securely when spreading it across a batch of covers as well as corresponding considerations on the detection of such embedding. In his seminal work, Andrew D. Ker illustrated the paradigm with a case study using LSB replacement in large batches of images. While large bursts of media objects might create some suspicion, such an occurrence in network traffic is in many cases considered normal. Therefore, it is an obvious choice to investigate into such methods for network steganography. Based on this realisation and driven by increasing numbers of Malware relying on steganographic methods (for purposes of hidden infiltration, command and control communication or data exfiltration) since 2011, the field of research in network steganography and steganalysis has received a huge boost as well as a shift in focus. While early approaches have been looking into generic network protocols such as TCP/IP or HTTP for cover channels, more recent publications have started looking into protocols that would be much more relevant in the industrial espionage or sabotage scenarios targeted by modern Malware families. As a result network protocols used for automation networks, found in Industrial Control Systems or automation systems in general are of special interest. In [25] Wendzel et al. use an analogy from nature to describe Information Hiding in Cyber Physical Systems. The authors of that paper use hoarding and caching tactics found in the behaviour of animals to describe how attackers potentially could use Information Hiding to establish secret steganographic data storage in smart buildings. Their focus lies on actuators and unused registers of automation systems in smart buildings which are used as secret storage to hide information. This idea of distributing a hidden message in multiple covers is referred to as scattered hoarding. In their work they focus on steganographic data storage in Cyber Physical Systems by using a smart buildings automation system as a secret storage. This is framed by a scenario in which two spies want to secretly exchange information in an asynchronous way by using a dead drop, which in this case is the smart building. The main issue with that approach is that the hidden data might be overwritten by control processes or user interaction. Since ICS usually deploy long-term storage of historic process data, we propose to leverage this fact by encoding hidden messages by manipulating sensor or actuator values and retrieve those by accessing the long-term storage. In [9] and [4] Herzberg and Ahmed manipulate the noise levels in senor data to establish a covert timing channel between sensors and actuators. Other work evaluates covert channels found in common automation protocols, e.g. Modbus/TCP [13] [15], OPC/UA [10] [5] and MQTT [24]. Additional work modulating sensor values to perform attacks on Industrial Control Systems include the works of Krotofil [12] and Ahmed [4] [6] [3]. However, certain publications regarding covert channels in common IT networks might be applicable as well in industrial networks. at the example of water-flow and water-level sensors in an ICS environment. We leverage the circumstance that such systems are commonly designed similar to the Purdue Reference Architecture [26], which employs the transmission of process data to a centralized database (often referenced to as process- or data historian) for long-term storage. Additionally, we evaluate how such communication flows can be used to establish protocol-agnostic covert channels for information exfiltration and generate data sets for evaluations based on the introduced embedding methods. Furthermore, we introduce novel detection approaches to detect such attacks. These detection approaches are extensively evaluated in regards to their performance on data sets generated with different embedding methods and bandwidth. The contributions of our paper can be summarized as follows: • Proposal for establishing covert channels for data exfiltration using sensor data collected in ICS historians (long-term storage of process data) • Design of a protocol-agnostic covert channel that is asynchronous and long-term persistent • Discussion on temporal persistence of hidden messages • Discussion on selection of appropriate embedding strategies • A practical evaluation of hiding information in the noise of sensor values of water-flow and water-level sensors in the Secure Water Treatment (SWAT) dataset [6] • Generation of evaluation data for testing & detection approaches • Design and implementation of novel detection approaches for the introduced covert channels • An extensive evaluation of the introduced detection approaches to determine their performance • Analysis of detection approaches for integration in ICS The work is structured as follows: In Section 2 we discuss the state of the art regarding network steganography and corresponding covert channels related to our work. In Section 3 we describe the threat model, attack scenario and attacker model which represents the basis for our exfiltration strategy, which we discuss in detail in Section 4. Section 5 introduces our novel detection approaches based on [10] and how it could be used in a real world ICS. In Section 6 the evaluation of our detection approaches is summarised, including evaluation goals, data sets and results. Section 7 concludes our work and presents a perspective on potential future work. 2 STATE OF THE ART Compared to research on steganographic methods for media objects (esp. digital images), network steganography has received much less attention in the past decades. It has always been around since the digital domain started to gain pace, with first noticeable publications in the 1980s (see e.g. [18]), 1990s ([8]), early 2000s ([17]), but those have been small in numbers and mostly focusing on more or less trivial storage channels (like e.g. the embedding into unused TCP/IP header fields discussed in [17]). With the advent of covert timing channels in network steganography around 2005 (see e.g. [22] or [21]) the field gathered some noticeable increase in research interest. If it comes to the task of performing steganalysis on a hidden channel created by network steganography, then this task 3 THREAT MODEL As described in the previous section, in contrast to [25] we use an attack scenario, in which we leverage the long-term storage of process data as as a cover channel for exfiltrating data out of 114 IH&MMSec ’21, June 22–25, 2021, Virtual Event, Belgium Session 5: Steganography I Information Hiding in Cyber Physical Systems IHMMSec ’21, June 22–25, 2021, Virtual Event, Belgium Figure 1: Our approach for embedding and retrieval in sensor measurements. an Industrial Control Systems (ICS) network. In the following sections, we describe our attack scenario as well as the corresponding attacker model. 3.1 the tactics of Data Historian-, Engineering Workstation- and Supply Chain- Compromise. The previously described scenario of the inside threat, developing the malware at the workplace is currently not reflected in the Att&icks framework. Attack Scenario 3.2 In order to describe our attack scenario we use the MITRE Att&CKics framework [16], which is a comprehensive knowledge base and allows for modelling realistic attack scenarios and attack procedure descriptions for ICS. In our attack scenario we assume that the attacker wants to exfiltrate sensible information from the production network, like firmware versions, IP-addresses or details on the process itself or its logic. While the focus is set on the exfiltration part here for simplicity, the proposed covert channel is geared to be used as part of a more complex Command & Control (C&C) channel as well (when paired with a covert infiltration channel). To be able to exfiltrate such information, we assume that on the embedder side a device is compromised which takes part in the communication flow between sensors gathering data about a physical process which is collected and processed by Programmable Logic Controllers (PLCs) and are (with potential inter-stops) aggregated and stored in a process database, or historian. Depending on the network architecture, those components could be PLCs, network elements (e.g. firewalls), Human-Machine-Interfaces (HMIs) or other components, like data aggregators or protocol converter. On the receiver side, each device which in some way has (potential) access to the historical data, like the database server itself or engineering workstations, are potential receiving/retrieving devices, which need to be compromised in a way that the hidden message can be extracted from the historian. For example, an engineer who has access to the historical data can act as inside threat, by e.g. infecting her computer with a malware which is capable of retrieving the hidden information or writing such code directly at her workplace. In the Att&ckics framework this scenario is part of the Initial Access phase and is reflected in Attacker Model For our scenario the knowledge level of the attacker only plays a minor role, as the aim of the data exfiltration strategy is to gain more insight and might be used as part of the reconnaissance for further attacks. Nevertheless, in order to establish the covert channel, prior infections are needed, which require a certain set of a priori information. For our attacker model, we assume that the attacker has the capabilities to deploy the tactics as described before, namely supply chain attacks and engaging inside threats. As those tactics require high efforts, they are deployed by actors with sufficient resources, like nation state actors or advanced persistent threats (APT). Therefore, our attack scenario and attacker model is based on the assumption of a highly targeted attack with nearly unlimited resources regarding time, money and personnel. On the technical side though, we encounter limited resources and capabilities as limitations occur regarding computational power and data storage, when the embedding and retrieval takes place in a stealthy way on components with limited resources, like PLCs or firewalls. 3.3 Experimental Setup For the experimental evaluation we use the Secure Water Treatment (SWAT) dataset from iTrust [6] as it provides a large amount of real process data, which allows for a realistic simulation of our attack scenario. We are using a subset from the A1 and A2 collection from December 2015 and focus on two sensors, water flow (FIT101 in the original dataset, here 𝑆 1 ) and water level (LIT101 in the original dataset, here 𝑆 2 ). These sensors are selected as they represent two 115 IH&MMSec ’21, June 22–25, 2021, Virtual Event, Belgium Session 5: Steganography I IHMMSec ’21, June 22–25, 2021, Virtual Event, Belgium Lamshöft and Neubert, et al. common but distinctive types found in such systems. For this evaluation, the process data directly from the sensors is used in order to simulate a scenario, in which PLC would modulate the received values. Figure 1 illustrates this attack scenario. The focus here is to evaluate the performance of four different embedding strategies (see Section 4) for each sensor (𝑆 1, 𝑆 2 ) and the resulting effect on the detection. For the data generation, a subset of 24855 datapoints is selected from the SWAT dataset, which reflects around 6 hours of the physical process. The first two hours (8285 values) are used to build the cover model (see Section 4.1) for each sensor (and can be used as a non-stego set), the other 4 hours (16570 values) are used for embedding. 4 EMBEDDING & RETRIEVAL As shown in Figure 1, our approach for embedding and retrieval is based on six Process Steps 𝑃𝑖 , which can be summarized as follows: 𝑃1 : Cover Model Generation, 𝑃2 : Cover Channel Selection, 𝑃 3 : Cover Model Application, 𝑃4 : Cover Object Selection, 𝑃5 : Embedding, 𝑃6 : Retrieval. In the following we use these as a guideline and describe each phase in more detail. 4.1 Figure 2: Cover Model 𝐶𝑀1, 𝐶𝑀2 , Synchronisation Method 𝑆𝑦𝑛𝑐 1, 𝑆𝑦𝑛𝑐 2 and Embedding Strategies 𝐸𝑆 1, 𝐸𝑆 2, 𝐸𝑆 3, 𝐸𝑆 4 for Sensors 𝑆 1, 𝑆 2 ) (Water Flow, Water Level). Cover Model Generation (𝑃 1 ) (static/linear/exponential/logarithmic increase/decrease) and the estimated noise for that state. As shown in Figure 2 for both Sensors 𝑆 1 and 𝑆 2 two methods 𝑆𝑦𝑛𝑐 1, 𝑆𝑦𝑛𝑐 2 are used for synchronisation. In case of the water level sensor 𝑆 2 , we are using the steady state above a water level of 812 centimeters for synchronisation and the linear transient state (which look to be steady, but are linear increasing) around the value of 500 centimeters for embedding the actual message (𝑆𝑦𝑛𝑐 2 ). The synchronisation method 𝑆𝑦𝑛𝑐 1 for the water flow sensor 𝑆 1 is quite different in comparison, as there are two steady states, in which either water is currently flowing or not. If no water is flowing through the sensor, the value is zero and therefore not suitable for embedding. Therefore, embedding is only possible, when water is flowing through the sensor. For synchronisation, we use the transition between not flowing and flowing. The first 128 values after the sensor started to read a flow are used for syncing and the rest for embedding the actual message. In order to get comparable results, we are using the same hidden message for both sensors, as well as the same parameters for the embedding strategies. In addition to that, the states model is helpful as well when employing a a dynamic capacity strategy by calculating the noise per state to use different capacities (hidden bits per cover object) in correlation to the noise, which ultimately might make detection more difficult. In the following the estimation of sensor and process noise is described. As shown in [12] sensors of Cyber Physical Systems can show different types of noise, depending on the measured physical property and type of sensor. The physical process and the sensor itself induce two types of noise [4]: (1) sensor noise which is inherited by the (in-)accuracy of a sensor measuring a physical property and (2) process noise which are fluctuations of the physical process, e.g. a moving liquid. A sensor measurement 𝑦𝑆𝑖 𝑡 can be described as the combination of the physical value 𝑣𝑡 and the noise 𝑛𝑡 , which is the sum of the process noise 𝑛𝑝𝑡 and the sensor noise 𝑛𝑆𝑖 𝑡 at a given point in time 𝑡: Sensor measurements can have very different characteristics depending on the type of sensor, the physical process that is monitored and the current state of that process. For example, in the case of the used water flow sensor 𝑆 1 , a constant 0.00 is returned when no water is passing the sensor. Obviously, it is not possible to plausibly embed in such values. Therefore, to be able to decide whether a measurement is suitable for plausible embedding or not, a (cover) model for each sensor is developed by observing measurements over a given period of time, e.g. over the course of day. The resulting cover model 𝐶𝑀𝑖 defines constraints which indicate whether the current measurement is suitable for plausible embedding. To derive such constraints, we combine two methods: (1) we use a simple states model to describe the current state of the physical process and (2) we estimate the noise of the sensor for this state. Another important factor is that sensors measurements can show recognizable patterns over time (e.g. reaching a peak level, after filling a water tank). In our approach, we explicitly seek such recognizable patterns to use them for synchronisation between covert sender and receiver. These recognizable patterns are used to enhance the cover model and to define constraints, when values are used for synchronisation or embedding the actual message. Figure 2 illustrates the cover models at the example of the aforementioned sensors 𝑆 1, 𝑆 2 . As described in the threat model, the attacker might have unlimited resources from an organisational standpoint, but when targeting automation devices like PLCs or HMIs, the attacker only has limited computational resources on that specific target system. Nevertheless, to be able to develop a representative cover model, we leverage the fact, that in general physical processes can be simplified in a states model with two states: steady states and transient states. In steady states values are either constant or fluctuate around a specific value, whereas transient states describe the transition between steady states. By identifying the current state, a simplified model of the physical process is developed by noting the average duration of each phase, its mathematical description 𝑦𝑡 = 𝑣𝑡 + 𝑛𝑡 = 𝑣𝑡 + 𝑛𝑝𝑡 + 𝑛𝑆𝑖 𝑡 116 IH&MMSec ’21, June 22–25, 2021, Virtual Event, Belgium Session 5: Steganography I Information Hiding in Cyber Physical Systems IHMMSec ’21, June 22–25, 2021, Virtual Event, Belgium To embed a hidden message into the measurement of the sensor, the attacker introduces a 𝛿𝑡 (which might be positive or negative) to the measured value of the sensor (see Figure 1). The modified value which is transferred and stored in the historian can therefore be described as: about the system and the warden, his capabilities, his position in the system and therefore access to cover objects and cover channels. In nature, rodents like squirrels recache their food (move it to another cache) in order to prevent pilferage. In the context of Information Hiding, pilferage can be seen as detection and suppression of a covert channel by an active warden. Taking this concept to Information Hiding, two interesting aspects arise: The first aspect we can take from nature, is that hidden elements (in this case a hidden message) may have different lifetimes. A hidden message might be - depending on the on the covert channel - only receivable in real-time, whereas when using a different covert channel a hidden message might be retrievable even years later. This is what we describe as the temporal aspect in regards to persistence of a covert channel or hidden message. The second aspect we can take from nature is the general concept of recaching which is resembled in Information Hiding as changing the embedding position or cover selection. Here we can define four major types of recaching, with multiple options for each type: 𝑦¯𝑡 = 𝑦𝑡 + 𝛿𝑡 = 𝑣𝑡 + 𝑛𝑡 + 𝛿𝑡 In order to stay undetected the aim is to keep modifications so small, that a) values are still within the limits and distribution of usual noise and b) still a receiver is able to retrieve the hidden information. In a dynamic capacity scenario the information hider has to solve the optimization problem of finding the highest possible capacity at a given point in time while staying within the limits and distribution of the usual noise. Assuming the usual distribution of the combined noise of sensor and process noise is 𝑛𝑡 ∈ 𝑃 the distribution of the sensor reading with the embedded message should be within this usual noise distribution 𝑛𝑡 + 𝛿𝑡 ∈ 𝑃 to avoid detection. To calculate the noise, we follow a modified approach inspired by [2] and calculate local noise by using the standard deviation on fixed window sizes. In addition to that, we use the distribution of the last digits as a second feature for noise calculation. The window size is selected individually for each sensor, as transient and steady states of the underlying control process might vary in length. To get the potential steganographic capacity per sensor value in bit, we use the doubled standard deviation of the values for a given window 𝑋 to the logarithmic base of 2 to receive the deviation in bits: 𝑐𝑎𝑝𝑚𝑎𝑥 (𝑋 ) = 𝑙𝑜𝑔2 (2𝜎 (𝑋 )). This gives us the maximum amount of bits which can potentially be modified while staying within the usual fluctuations of the values. 4.2 (1) Cover Channel Selection (change cover channel) (2) Covert Channel Hopping (change covert channel) (3) Embedding Position Change (change embedding position within a cover object) (4) Cover Object Selection (select different set of cover objects) For each type multiple options of operation are possible: (1) recache-by-default: constant change (covert protocol) (2) triggered-recache: triggered (e.g. by control message) (3) conditional-recache: triggered when a pre-defined condition is met e.g. bandwidth below threshold Cover Channel Selection (𝑃 2 ) One of the main concepts in this exfiltration strategy is the fact, that in CPS it is common to store process data for longer periods of time in an historian database. This circumstance is leveraged to establish an asynchronous covert channel, where the hidden information is retrieved independently from the point of time when it got embedded. Therefore, such asynchronous covert channels can only be established, if the cover objects are persistent. Such persistence can be further differentiated. For Cyber Physical Systems we use here three levels of persistence (which vary depending on the actual system): The amount of potential cover channels is given by the amount of I/Os the covert sender has access to. For example, if the covert sender is a PLC, the list of potential cover channels is given by the sensors and actuators that are connected to the PLC. In case of a compromised network element, like a protocol converter or firewall, the available cover channels are given by the amount of transferred I/O values in the network flow. Therefore, in this paper the number of potential cover channels is two, namely 𝑆 1 and 𝑆 2 . As described in Section 2, in [25] the authors propose to use a scatter hoarding strategy to hide a message across multiple unused registers of sensors in a smart building. This concept is driven by the idea to achieve a potentially high bandwidth while staying stealthy as the message is distributed on a large set of cover objects. This discussion of whether to hide a given message in a small number of cover objects (resembles larder hoarding) or to scatter this message across a larger set of cover objects (scatter hoarding) can be found in the concept of batch steganography and steganalysis by Ker in 2007 [11]. In this work it is shown to be the best strategy to embed only in a small number of cover objects - at least if the warden is using a detection method explicitly designed for such pooled steganalysis. This on the other hand leads to the conclusion, that in order to choose a proper strategy for an information hider, he has to keep the warden in mind, which lefts him in a game theoretic problem, as described by Schöttle and Böhme in 2013 [20]. Therefore, the potentially best strategy for the hider is specific to his knowledge (1) long-term persistence, similar to dead drops, e.g. historians (months to years) (2) mid-term persistence, e.g. log files (days to weeks) (3) short-term persistence (minutes to hours) In contrast to that a synchronous covert channel makes use of an ephemeral cover channel, e.g. direct TCP/IP communication between an HMI and PLC (under the premise, that communication does not get recorded). In case of the proposed data exfiltration strategy, we are using the long-term persistent storage of process data as a cover channel. But as this differentiation shows, there are potentially a large amount of other similar attack scenarios leveraging different levels of persistence. Another application of this differentiation is in the design phase of a warden, as it is important to place wardens in the right positions to be able to detect such covert channels. 117 IH&MMSec ’21, June 22–25, 2021, Virtual Event, Belgium Session 5: Steganography I IHMMSec ’21, June 22–25, 2021, Virtual Event, Belgium 4.3 Lamshöft and Neubert, et al. Cover Model Application (𝑃 3 ) As stated before, the idea of the embedding strategies is to modulate the bandwidth in the hope to render a detection less likely. The embedding strategy ratio 𝐸𝑆𝑟𝑖 indicates how many of the sensor values, that are within the constraints of the cover model 𝐶𝑀𝑖 , are actually used for embedding. When also taking into values into account, which were not used for embedding due to the fact that there not apt for plausible embedding (e.g. due low noise), the The main objective here is to decide for each Cover Channel 𝐶𝑖 whether the current cover object (= measurement value 𝑦𝑆𝑖 𝑡 ) which is transferred on that channel is used to embed a hidden message, used to synchronise or not used at all (e.g. because the noise is too low). This decision is driven by the selected synchronisation method 𝑆𝑦𝑛𝑐𝑖 and the cover model 𝐶𝑀𝑖 (both described in 4.1), which defines constraints, whether a cover object is suitable to embed a message, and whether it is part of a synchronisation or embedding. 4.4 | 𝑦¯𝑆 | embedding ratio 𝑟 is used: 𝑟 = | 𝑦ˆ |+𝑖| 𝑦¯ | . 𝑆𝑖 𝑆𝑖 The embedding ratio 𝑟 indicates how many values were modi¯ to embed a message in relation to all values (non-modified fied (𝑦) ¯ As the strategy ratio 𝐸𝑆𝑟𝑖 de𝑦ˆ due to 𝐶𝑀𝑖 and 𝐸𝑆𝑖 and modified 𝑦). fines how many values are actually used for embedding the hidden message, it is a direct parameter for the resulting embedding ratio 𝑟 and bandwidth. One of the major features of the pseudo-random method is that the strategy ratio 𝐸𝑆𝑟𝑖 can be arbitrarily set by giving the function a probability with which is decided, whether a value is used or not. This method allows for fine-granular tuning of the embedding ratio 𝑟 and therefore is especially of interest in regards to make detection and suppression more difficult. This is even more embraced as the embedding seems to be random for an outside viewer. The embedding strategies are applied to both synchronisation sequences as well as sequences used for embedding the actual message. Figure 2 illustrates this at the example of the two sensors and embedding strategies. The results of the application of these embedding strategies and their effect on the bandwidth are discussed in Section 4.7. Cover Object Selection (𝑃 4 ) In nature, animals are searching and using different sized caches and amounts of food per cache to prevent or minimize losses in case of pilferage. While the terminology might vary across different publications, in (Network-) Information Hiding usually two types of (steganographic) payload variation are common: • Capacity Modulation, which is steganographic payload per cover object. • Bandwidth Modulation, which is steganographic payload over time. These two options are especially relevant for CPS, as they allow for different strategies in regards to the avoidance of detection. Capacity modulation can be helpful in scenarios where the characteristics of the cover channel vary. For example in physical processes the noise of sensor values might be different in transient states from steady states. On the other hand bandwidth modulation can be helpful to adjust the payload over time in regards to the physical process to avoid detection by a warden. Both strategies and especially in combination can help an attacker to optimize steganographic payload against detection probability. 4.5 In order to modulate the bandwidth in our approach, four embedding strategies 𝐸𝑆𝑖 are applied to drive the Cover Object Selection (𝑃 4 ). For evaluation of this approach, we are using four different strategies, which employ different Embedding Strategy Ratios 𝐸𝑆𝑟𝑖 , as shown in Table 1. Table 1: Embedding Strategies 𝐸𝑆𝑖 and correlating Embedding Strategy Ratios 𝐸𝑆𝑟𝑖 Strategy 𝐸𝑆 1 𝐸𝑆 2 𝐸𝑆 3 𝐸𝑆 4 Description every suitable value every second suitable every third suitable value pseudo-random method Embedding (𝑃 5 ) In 𝑃5 the actual embedding of hidden bits for a given value takes place, whereas the Cover Model 𝐶𝑀𝑖 of Process Step 𝑃1 dictates if these are part of the synchronisation sequence or taken from the actual message (see Section 4.1). Either way, both the synchronisation sequences as well as the secret message get encrypted, encoded and split into embedding blocks and embedded in the target value (see Figure 3). In accordance to our attack scenario, where we assume an attacker wants to exfiltrate sensible information, we are generating a realistic hidden message with detailed information about the hardware and firmware of the target system. We are using the common Linux command lshw to generate a detailed hardware list and strip unnecessary symbols and line breaks. For our testing environment, this message is about 13.5 kilobytes in size. AES-ECB is currently used out of simplicity and can be exchanged by other modes, as our synchronisation methods are especially designed for this use case. As shown in Figure 3 the process of embedding can be divided in to five steps. In the first step the value, which is going to be modified in order to embed a part of the hidden message, is split in two parts: head and tail. The size of the parts is given by the capacity 𝑐𝑎𝑝𝑖 . The capacity is either calculated (and by that dynamically chosen) by using the cover model 𝐶𝑀𝑖 , in order to set a capacity in relation to the current noise, or a static capacity 𝑐𝑎𝑝𝑖 is used which then is part of the stego key 𝐾𝑆 For the two sensors 𝑆 1, 𝑆 2 , we tested capacities between 1 and 12 bit. Therefore, the algorithm splits the last four digits (tail) from the rest of the value (head). Those last four digits (tail) are then treated as an 16-bit integer. In the next step the tail gets transcoded to a binary string. From the encrypted Strategy Ratio 𝐸𝑆𝑟𝑖 1.0 0.5 0.33 variable 𝐸𝑆 1 is the trivial case, when every suitable value (in the means of the cover model) is actually used for embedding or synchronisation data. In 𝐸𝑆 2 we reduce the used values by 50% and only every second suitable value is going to be used. 𝐸𝑆 3 uses every third suitable, therefore the strategy ratio is only 33% in relation to all suitable values. 𝐸𝑆 4 is using a special method which uses a pseudo-random function to decide, whether a value is used or not. In order to be able to synchronise such pseudo-randomly inserted messages we are using a seed that is part of the stego key 𝐾𝑆 . 118 IH&MMSec ’21, June 22–25, 2021, Virtual Event, Belgium Session 5: Steganography I Information Hiding in Cyber Physical Systems IHMMSec ’21, June 22–25, 2021, Virtual Event, Belgium message queue the next block in the size of the chosen capacity 𝑐𝑎𝑝𝑖 is retrieved, which will then replace the last bits of the tail. In the third step this bit-block replaces the corresponding last bits of the original. After that, the new binary string gets encoded back to an integer and in the last step joined with the original. the effect on the resulting bandwidth per sensor. In order to get comparable, yet realistic data, we are using a static capacity per cover object of 8 bit (𝑐𝑎𝑝 1,2 = 8). As shown in Table 2 the results illustrate that the water flow sensor 𝑆 1 does not embark the same amount of potential bandwidth. From the water level sensor 𝑆 2 53% of the measurements are supposed to be suitable (noise above 8 bit) in the context of the cover model, which is reflected in the maximum embedding ratio 𝑟𝑚𝑎𝑥 which describes how many of all measurements can be used for plausible embedding. In contrast to that, only 35% of the values of the water flow sensor 𝑆 1 are supposedly suitable for embedding (𝑟𝑚𝑎𝑥 = 0.35). This directly effects the maximum achievable bandwidth per sensor. Within the constraints of the cover model the maximum achievable bandwidth for the water level sensor 𝑆 2 is about 4.2 bit per second and 2.84 bit for the water flow sensor 𝑆 1 when using every suitable value for embedding (𝐸𝑆 1 ). To put this in perspective, the resulting bandwidth is set around 370kb (water level) and 245kb (water flow) per day. This might not seem to be a high bandwidth on a first glance, but in the context of the exfiltration attack scenario (which assumes a long-term projected attack) the bandwidth is comparable high ([10], [13]). For example, the hidden message we are using (which contains detailed hardware and firmware information about the target system) is only 13.5kb in size and therefore could be transmitted between 18 and 27 times depending on the sensor per day. Even when using an (embedding) strategy ratio of only 0.33 (𝐸𝑆𝑟 3 = 0.33) on the lower performing water flow sensor 𝑆 1 , in the course of a day the message could be transmitted six times (81kb). As the static 8 bit capacity is a conservative estimation, even more bandwidth might be achievable while also improving the stealthiness when using a dynamic capacity based on the local noise of the sensor. Figure 3: The five-step process for embedding secret messages in the last digits of sensor values. 4.6 Retrieval (𝑃 6 ) As described in our attack scenario in Section 3, the retrieval is done by a receiver who has access to the historian database. A common example would be an engineer accessing the database for monitoring or maintenance on the physical process. To be able to retrieve the message, the retriever has to have knowledge on (1) the algorithm, (2) which cover channels (sensors) the covert sender has access to and (3) the stego key 𝐾𝑆 . As shown in Figure 1 the Stego Key 𝐾𝑆 is made out of six components: (1) Cover Channels (Selection Method) {𝐶𝑖 }, (2) Embedding Strategy 𝐸𝑆𝑖 , (3) (Embedding) Strategy Ratio 𝐸𝑆𝑟𝑖 , (4) Synchronisation Method 𝑆𝑦𝑛𝑐𝑖 , (5) Capacity 𝐶𝑎𝑝𝑖 and (6) the Encryption Key 𝐾𝑒 . In the context of our attack scenario we can assume the stego key to be static, e.g. as part of a supply chain attack. On a first glimpse the retrieval seems like the search for a needle in an haystack. However, the stego key 𝐾𝑆 is constructed in a way, to make this search successful: With the knowledge of the retriever which cover channels the covert sender has access to and which strategy is used to select cover channels {𝐶𝑖 }, the retriever knows where to search for hidden messages. With the knowledge of the algorithm and the synchronisation method 𝑆𝑦𝑛𝑐𝑖 the receiver can create a cover model. With that model and the knowledge on the used embedding strategy and its correlating strategy ratio 𝐸𝑆𝑖 , 𝐸𝑆𝑟𝑖 , the receiver can identify the synchronisation sequences, which contain information where the hidden messages are stored. In order to decode and decrypt these, the receiver needs to know the capacity 𝑐𝑎𝑝𝑖 and the encryption key 𝐾𝑒 . 4.7 5 DETECTION In this section the concepts of our novel detection approaches are introduced. Furthermore, we will discuss how the approaches can be integrated in a real world ICS. 5.1 Detection Approaches In order to detect the covert channel described in Section 4, we elaborate a novel detection approach based on [10]. The detection approach is based on the assumption that non-modified sensor data (𝑦ˆ𝑆𝑖 ) follows a rather uniform distribution on its last digits of sensor values on sequences with a supposedly short length (< 50 values) than steganographic sensor data (𝑦¯𝑆𝑖 ) as such aim for a uniform distribution during embedding in order to stay undetected. We assume that this steganographic embedding feature could result in data that is more uniformly distributed than unaltered data and leads to an detectable anomaly. Our detection approach is based on statistical pattern recognition and uses two classes of data for training and classification (non-modified sensor data (𝑦ˆ𝑆𝑖 ) and modified sensor data (𝑦¯𝑆𝑖 )). Due to the fact, that a detection of an anomaly in a single sensor value is basically not possible because the steganographic embedding is hidden and is totally unobtrusive, the detector analyzes sequences of sensor values as introduced in [10]. The sensor value sequence |𝑆𝑒𝑞| indicates how many values (𝑦𝑆𝑖 ) the detector analyzes for feature extraction and to create a sample (feature vector) for training or classification. The optimal Comparison of the Embedding Strategies For the practical evaluation we are using the four embedding strategies 𝐸𝑆𝑖 described in Section 4.4 for both sensors 𝑆 1, 𝑆 2 to evaluate 119 IH&MMSec ’21, June 22–25, 2021, Virtual Event, Belgium Session 5: Steganography I IHMMSec ’21, June 22–25, 2021, Virtual Event, Belgium Lamshöft and Neubert, et al. Table 2: Embedding Strategy Comparison (sorted by Strategy Ration 𝐸𝑆𝑟𝑖 ) Strategy Strategy Description Strategy Ratio 𝐸𝑆𝑟𝑖 Sensor 𝐸𝑆 1 𝐸𝑆 1 𝐸𝑆 4 𝐸𝑆 4 𝐸𝑆 2 𝐸𝑆 2 𝐸𝑆 3 𝐸𝑆 3 all all random random alternating alternating thirds thirds 1.00 1.00 0.75 0.75 0.50 0.50 0.33 0.33 𝑆1 𝑆2 𝑆1 𝑆2 𝑆1 𝑆2 𝑆1 𝑆2 Sensor Maximum Embedding Ratio 𝑟𝑚𝑎𝑥 0.35 0.53 0.35 0.53 0.35 0.53 0.35 0.53 size for the sensor value sequence |𝑆𝑒𝑞| has to be determined during evaluation by exploratory analyzing different length of |𝑆𝑒𝑞|. We assume that the detector delivers the best performance with a sequence length between |𝑆𝑒𝑞| ≥ 15 and |𝑆𝑒𝑞| ≤ 50. The detector analyzes the last three digits (because of the 8-bit embedding) of multiple sensor values in a sequence (how many values depends on |𝑆𝑒𝑞| as mentioned before). In formalized terms it means that, the detector looks at the last three digits 𝑥 1 , 𝑥 2 and 𝑥 3 of a sensor value 𝑦𝑆𝑖 where: 𝑥 1 = 𝑦𝑆𝑖 [𝑙𝑒𝑛𝑔𝑡ℎ(𝑦𝑆𝑖 ) − 3], 𝑥 2 = 𝑦𝑆𝑖 [𝑙𝑒𝑛𝑔𝑡ℎ(𝑦𝑆𝑖 ) − 2] and 𝑥 3 = 𝑦𝑆𝑖 [𝑙𝑒𝑛𝑔𝑡ℎ(𝑦𝑆𝑖 ) − 1]. The approach stores all 𝑥 1 ,𝑥 2 and 𝑥 3 for value sequence in three corresponding vectors 𝑉 𝑒𝑐{𝑥 1 }, 𝑉 𝑒𝑐{𝑥 2 } and 𝑉 𝑒𝑐{𝑥 3 }. For example: If |𝑆𝑒𝑞| = 3, the detector analyses three sensor values 𝑦𝑆𝑖 in a sequence, e.g.: 𝑦𝑆𝑖1 = 2.456358, 𝑦𝑆𝑖2 = 421.2452514 and 𝑦𝑆𝑖3 = 234.23521. Thus, the resulting vectors for analysis are 𝑉 𝑒𝑐 𝑥1 = {3, 5, 5}, 𝑉 𝑒𝑐 𝑥2 = {5, 1, 2} and 𝑉 𝑒𝑐 𝑥3 = {8, 4, 1} and have the length of |𝑆𝑒𝑞|. This is only a short example to understand the basis of our approach, because the features of the approach are calculated based on these three vectors. As mentioned before, we assume a significant longer sequence size |𝑆𝑒𝑞| somewhere between ≥ 15 and ≤ 50 for an expedient detection. However, these three created vectors are analyzed by the approach hereafter. Initially, the percentage probability of occurrence for digits 0 to 9 is determined for every vector which results in ten percentage values for each vector. These 10 values for each of the three vectors are the basis for our feature extraction as in [10]. The standard deviation is calculated for every vector based on the ten calculated percentage values for the occurrence of a digit. It results in three extracted features 𝑆𝑡𝑑𝑥1 , 𝑆𝑡𝑑𝑥2 and 𝑆𝑡𝑑𝑥3 . We determine these features based on our assumption, a more uniform distribution (as assumed for steganographic samples) of the values should result in a lower standard deviation. Additionally, we determine the variance 𝑉 𝑎𝑟 𝑆𝑡𝑑 and the average 𝐴𝑣𝑔𝑆𝑡𝑑 of 𝑆𝑡𝑑𝑥1 , 𝑆𝑡𝑑𝑥2 and 𝑆𝑡𝑑𝑥3 because these values should be significantly differ for uniform and rather uniform distributions of 𝑥 1 , 𝑥 2 and 𝑥 3 . Furthermore, we extract the percentage maximum of the percentage values for the occurrence of a digit for every vector 𝑀𝑎𝑥𝑥1 , 𝑀𝑎𝑥𝑥2 and 𝑀𝑎𝑥𝑥3 . We suppose that these values should be higher for non-steganographic samples because of the rather uniform distribution of the digits. This completes the feature extraction of our approach. All feature vectors are labeled for our statistical pattern recognition based detection approach. Thus our feature vector is 8-dimensional (𝑆𝑡𝑑𝑥1 , 𝑆𝑡𝑑𝑥2 , 𝑆𝑡𝑑𝑥3 , 𝑉 𝑎𝑟 𝑆𝑡𝑑 , 𝐴𝑣𝑔𝑆𝑡𝑑 , 𝑀𝑎𝑥𝑥1 , 𝑀𝑎𝑥𝑥2 and 𝑀𝑎𝑥𝑥3 ) with a label. The resulting feature vector represents a sample for training or Results Embedding Ratio 𝑟 0.35 0.53 0.27 0.40 0.18 0.27 0.12 0.18 Bandwidth bit/sec kb/day 2.84 4.28 2.12 3.21 1.41 2.14 0.94 1.42 244.94 369.75 183.54 276.98 122.14 184.88 81.43 122.81 classification. Based on the described 8-dimensional feature space, a two-class (non- steganographic data class and steganographic data class) J48 decision tree [19] is trained with WEKA3.9 [7]. We evaluated three other classifiers: logistic model tree (LMT), support vector machine (SVM) and multilayer perceptron (MLP). We use J48 decision tree because it performs with best accuracy and fastest runtime among the tested classifiers. The detector is in the following called 𝐷 1 . Furthermore, we use WEKA to carry out a feature selection to see if the a subset of features may result in a better detection performance. Therefore, we use the InfoGainAttributeEval with its Ranker method with default parametrization to determine the information gain of a feature with respect to its class. The selection shows that 𝑆𝑡𝑑𝑥3 is the feature with the clearly best separation precision. Due to this, we additionally train a second detector only with 𝑆𝑡𝑑𝑥3 feature to train a J48 decision tree 𝐷 2 . The J48 classifier is used in WEKA’s default parametrization. Both approaches are trained with the same non-steganographic data (non-modified) and steganographic (modified) data, presented in Section 6.2.1. In our evaluation we will evaluate both detectors with same test data sets (presented in Section 6.2.2). We will determine and compare their performance in Section 6.3. 5.2 Integration of the detection approaches in ICS The introduced detection approaches can be used as online or offline approaches. This means they can be integrated into a system to work live or be used with recorded data. If they are integrated in an live environment, the approach can practically make a classification in nearly real time. If the approaches work offline on recorded data, the detection can be slightly delayed in comparison to an online integration of the approaches. However, we see several options for both online and offline application at different positions in the reference architecture, e.g. to use online detectors in the network communication of PLCs and offline detectors directly on the historian. In order to assure that the detection has no influence on the real time capabilities and integrity of the system a decentralized integration of online-detectors seem reasonable. Here one scenario would be to place online detectors for each function unit or to use detectors for each PLC. Offline detectors might be especially of use when regularly crawling the historian database for potential hidden messages. The combination of both is especially interesting when 120 IH&MMSec ’21, June 22–25, 2021, Virtual Event, Belgium Session 5: Steganography I Information Hiding in Cyber Physical Systems IHMMSec ’21, June 22–25, 2021, Virtual Event, Belgium using them to correlate events, thus making a detection more likely and easier to pinpoint infected devices. 6 used sequence sizes for detection are determined by exploratory analyzing different sequence sizes. In the exploratory analysis, we evaluated our detectors with different |𝑆𝑒𝑞| in a 10-fold cross validation. We start with |𝑆𝑒𝑞| = 10 and increase it step-wise by 10. Around |𝑆𝑒𝑞| = 20 we determined the highest performance, we extend our exploratory analysis with small adjustments in this area of |𝑆𝑒𝑞| to find |𝑆𝑒𝑞| with the optimal performance. The analysis revealed that the optimal value sequence length for our detection approaches is |𝑆𝑒𝑞| = 22. As a result we considered the following value sequences |𝑆𝑒𝑞| = {10, 18, 19, 20, 21, 22, 23, 24, 30, 40, 50, 100} in our evaluation. EVALUATION OF DETECTION APPROACHES In this section, we present our extensive evaluation of our previously introduced detection approaches. We describe evaluation goals, data and results in the following subsections. 6.1 Evaluation Goals For our evaluation we define 3 goals to evaluate and compare our presented detection approaches 𝐷 1 and 𝐷 2 . The evaluation goals can be summarized as follows: Table 3: Number of Samples for 𝐷𝑆𝑡𝑟𝑎𝑖𝑛𝑖𝑛𝑔 for used sequence sizes |𝑆𝑒𝑞| (|𝑆𝑒𝑞| determined by exploratory analysis) • Goal 1: Determination of detection performance of 𝐷 1 & 𝐷 2 on different test data sets 𝑇 𝐷𝑆 with different embedding strategies and ratios 𝑟 . • Goal 2: Comparison of their performance. • Goal 3: Investigation of correlation between embedding ratio 𝑟 and detection performance. |𝑆𝑒𝑞 | 10 18 19, 20 21, 22 23, 24 30 40 50 100 The performance of the detection approaches is measured with well-known metrics. We use the True Positive Rate (TPR) for correct classified steganographic samples in a test data set and the True Negative Rate (TNR) for correct classified non-modified samples in test data. Additionally, we use the False Positive Rate (FPR) as complementary rate to TNR to describe triggered false alarms by the approach. 6.2 Number of Samples based on non-modified Values 𝑦ˆ𝑆𝑖 1905 1058 952 865 793 634 475 380 189 Number of Samples based on modified Values 𝑦¯𝑆𝑖 1497 831 748 680 623 498 373 298 148 Overall 3402 1889 1700 1545 1416 1132 848 678 337 Evaluation Data 6.2.1 Training Data. To train our pattern recognition based detection approaches, we create a training data set 𝐷𝑆𝑇 𝑟𝑎𝑖𝑛𝑖𝑛𝑔 . Therefore, we use recorded authentic (non-modified) data (𝑦ˆ𝑆𝑖 ) and (modified) data with steganographic embedding (𝑦¯𝑆𝑖 ) from the two previously introduced sensors (𝑆 1 and 𝑆 2 ). We use data from both sensors for training due to the expectation that a single detector will be able to detect anomalies for both sensors if it is trained with sensor data from both sensors. The steganographic training data includes only values with steganographic embedding. Thus, the training data has an embedding ratio 𝑟 = 1.0. As mentioned before, 𝑟 indicates the ratio of modified values to all values in | 𝑦¯𝑆 | a data set (𝑟 = | 𝑦ˆ |+𝑖| 𝑦¯ | ) and the resulting sample. 𝐷𝑆𝑇 𝑟𝑎𝑖𝑛𝑖𝑛𝑔 𝑆𝑖 𝑆𝑖 contains 9529 values of non-modified sensor data 𝑦ˆ𝑆𝑖 (4005 water flow samples 𝑦ˆ𝑆 1 , 5524 water level samples 𝑦ˆ𝑆 2 ) and 7494 values with steganographic embedding 𝑦¯𝑆 (1688 flow samples 𝑦¯𝑆 1 , 5804 level samples 𝑦¯𝑆 2 ). Thus, we have a small bias in training because we have slightly more non-steganographic values in 𝐷𝑆𝑇 𝑟𝑎𝑖𝑛𝑖𝑛𝑔 because not every value is suitable for embedding, as mentioned before. However, this results in a different number of samples (remember: samples are not values, samples (or feature vectors) are calculated based on sensor values 𝑌𝑆𝑖 ) for 𝐷𝑆𝑇 𝑟𝑎𝑖𝑛𝑖𝑛𝑔 , depending on the sequence size |𝑆𝑒𝑞| (see Section 5.1) which is used from the detection approach. Furthermore, we use a sliding window to analyze a data set with an overlapping of 50% to analyze the data more detailed than without a sliding window and to create more samples. This leads to a varying number of samples for a detector based on the sliding window (always 50% in this work) and the sequence size |𝑆𝑒𝑞| (visualized in Table 3). As mentioned before, the 6.2.2 Test Data. To evaluate the performance of our elaborated detection approaches (presented in 5.1), we create 12 test data sets 𝑇 𝐷𝑆, six for each sensor (𝑆 1 and 𝑆 2 ). We summarize the test data sets in Table 4. We separate the sensor data for our evaluation to see if detectors, trained with water flow (𝑆 1 ) and water level (𝑆 2 ) samples, are able to detect anomalies for both sensors. We use the four different embedding strategies (introduced in 4.4) for both sensors which result in different embedding ratios 𝑟 to evaluate the detection performance in relation to the steganographic embedding ratio. Additionally, we use two test data sets with non-steganographic data only (one for each sensor) to see if the detector triggers false alarms (false positives). For 𝑇 𝐷𝑆𝑆 1 𝑟 1.00 and 𝑇 𝐷𝑆𝑆 2 𝑟 1.00 we refer to no embedding strategy because we simply exclude every sample in their initial data sets (𝑇 𝐷𝑆𝑆 1 𝑟 0.50 and 𝑇 𝐷𝑆𝑆 2 𝑟 0.95 ) with no steganopgrahic embedding, which corresponds to a embedding ratio 𝑟 of 1.0. As mentioned before embedding ratio indicates how many values in a data set include steganographic embedding in a data set. For example: If the embedding ratio is 0.3 and the sequence size |𝑆𝑒𝑞| = 20, six values in the analyzed sequence (to create a sample) include steganographic embedding (𝑦¯𝑆𝑖 ) and 14 values are non-modified (𝑦ˆ𝑆𝑖 ). Thus, a sample (feature vector) is a steganographic one as soon as one value contains steganographic embedding (𝑟 > 0) in the sequence. This means all steganographic test data sets with 𝑟 < 1.0 (𝑇 𝐷𝑆𝑆𝑖 𝑟 0.𝑥𝑥 ) contain sensor modified values with steganographic embedding (𝑦¯𝑆𝑖 ) as well as non-modified sensor values (𝑦ˆ𝑆𝑖 ). The embedding ratios varies for test data sets with steganographic embedding (𝑇 𝐷𝑆𝑆𝑖 𝑟𝑥 ) in comparison to descriptions in Table 2, because they are pre-processed for our evaluation. The pre-processing 121 IH&MMSec ’21, June 22–25, 2021, Virtual Event, Belgium Session 5: Steganography I IHMMSec ’21, June 22–25, 2021, Virtual Event, Belgium Lamshöft and Neubert, et al. |𝑆𝑒𝑞| > 250 by initial tests). We evaluate the performance of detectors only for |𝑆𝑒𝑞| < 100 because we can observe a dropping detection performance and a less accurate classification of nonmodified samples for |𝑆𝑒𝑞| ≥ 50. Detector 𝐷 2 is able to detect 87.8% (TPR) of steganographic samples (for 𝑇 𝐷𝑆𝑆 1 𝑟 1.00 ) at a FPR of 0% (TNR = 100% for both test datasets with non-modified data). 𝐷 1 delivers a comparable detection rate with up to 81.8% of correct classified steganographic samples but with a TPR of 93.9% for 𝑇 𝐷𝑆𝑆 1 and 94.8% for 𝑇 𝐷𝑆𝑆 2 . The detection performance of both detectors drops significantly when the embedding ratio 𝑟 decreases (e.g. 28.7% correct classified samples for 𝐷 2 and 30.3% 𝐷 1 when the embedding ratio 𝑟 = 0.17). We will compare the detection performance of 𝐷 1 and 𝐷 2 in 7.3.2. All in all, both detectors deliver promising results, but with a significant variance between different |𝑆𝑒𝑞|. Furthermore, we can observe comparable detection results between 𝑆 1 and 𝑆 2 test data sets. We conclude that the detection has a similar performance for both types of data with a slightly better detection in 𝑆 1 data sets because both detectors have slightly better TPR on water flow (𝑆 2 ) data sets. We assume, that this is caused by the training data. Furthermore, where we previously assumed that the embedding strategy is rather relevant for our detection, we can now see that the more significant parameter for detection is the embedding ratio 𝑟 . We analyze the detection performance in context of the embedding ratio in detail in 7.3.3. excludes long sequences (|𝑆𝑒𝑞| > 10) with non-modified values (values that are not suitable for embedding) to avoid samples with no steganographic embedding in a steganographic data set because this would result in false labeled samples and biased evaluation results. With these different data sets (which include different embedding strategies and embedding ratios), we evaluate the impact of different steganographic embedding ratios induced by the different embedding strategies on the performance of detection. All in all, we have 2 𝑇 𝐷𝑆 with modified values only (𝑟 = 1.0; detection performance determined with TPR), 8 𝑇 𝐷𝑆 with mixed modified and non-modified values based on different embedding strategies (0.0 > 𝑟 < 1.0; detection performance also determined with TPR, because we make sure that every calculated sample contains at least one modified value) and 2 𝑇 𝐷𝑆 with non-modified values only (𝑟 = 0.0, performance determined with TNR). The test data sets are analyzed by the detectors analogous to the training data set with the same sliding window of 50% and the same sequence sizes |𝑆𝑒𝑞|. With the number of values of a data set the number of samples can be calculated based on used sequence size in consideration of the sliding window (50%). Table 4: Test data sets (independent from training) for the evaluation of detection approach 𝑇 𝐷𝑆𝑆 1 𝑟 1.00 𝑇 𝐷𝑆𝑆 1 𝑟 0.50 𝑇 𝐷𝑆𝑆 1 𝑟 0.37 𝑇 𝐷𝑆𝑆 1 𝑟 0.25 𝑇 𝐷𝑆𝑆 1 𝑟 0.17 𝑇 𝐷𝑆𝑆 1 Number of values 𝑦𝑆𝑖 1279 5924 5924 11785 11584 2004 Embedding Ratio 𝑟 1.00 0.50 0.37 0.25 0.17 0.00 Embedding Strategy manual 𝐸𝑆 1 𝐸𝑆 4 𝐸𝑆 2 𝐸𝑆 3 - 𝑦¯𝑆 1 𝑦¯𝑆 1 , 𝑦ˆ𝑆 1 𝑦¯𝑆 1 , 𝑦ˆ𝑆 1 𝑦¯𝑆 1 , 𝑦ˆ𝑆 1 𝑦¯𝑆 1 , 𝑦ˆ𝑆 1 𝑦ˆ𝑆 1 𝑇 𝐷𝑆𝑆 2 𝑟 1.00 𝑇 𝐷𝑆𝑆 2 𝑟 0.95 𝑇 𝐷𝑆𝑆 2 𝑟 0.70 𝑇 𝐷𝑆𝑆 2 𝑟 0.50 𝑇 𝐷𝑆𝑆 2 𝑟 0.33 𝑇 𝐷𝑆𝑆 2 3038 9294 5924 8954 9067 2761 1.00 0.95 0.70 0.50 0.33 0.00 manual 𝐸𝑆 1 𝐸𝑆 4 𝐸𝑆 2 𝐸𝑆 3 - 𝑦¯𝑆 2 𝑦¯𝑆 2 , 𝑦ˆ𝑆 2 𝑦¯𝑆 2 , 𝑦ˆ𝑆 2 𝑦¯𝑆 2 , 𝑦ˆ𝑆 2 𝑦¯𝑆 2 , 𝑦ˆ𝑆 2 𝑦ˆ𝑆 2 Name 6.3 Type 6.3.2 Detector 𝐷 1 vs 𝐷 2 (Goal 2). For the comparison of 𝐷 1 and 𝐷 2 , we visualize the performance of the detectors for each test data set with |𝑆𝑒𝑞| = 22 in Figure 4. We can state that the performance of 𝐷 2 for non-modified samples is perfect (with |𝑆𝑒𝑞| = {19, 20, 21, 22, 23, 40}) in our evaluation, not a single non-modified sample is classified as a steganographic-one, which means no false alarms are triggered by 𝐷 2 (FPR = 0%). The performance of 𝐷 1 for non-modified test data sets is significant lower, it delivers a false positive rate (FPR) of 6.1% (93.9% TNR) for 𝑇 𝐷𝑆𝑆 1 and a FPR of 5.2% (94.8% TNR) for 𝑇 𝐷𝑆𝑆 2 for |𝑆𝑒𝑞| = 22. Thus, the performance on non-modified data is significantly better with our single-feature detector 𝐷 2 . In terms of detection performance both detectors deliver their best performance with a |𝑆𝑒𝑞| = 22. The results are comparable except for 𝑇 𝐷𝑆𝑆 1 𝑟 1.00 . For 𝑇 𝐷𝑆𝑆 1 𝑟 1.00 detector 𝐷 2 delivers a significant higher performance than 𝐷 1 with a 87.8% vs. 81.7%. For other test data sets with steganographic data and a embedding ratio 𝑟 ≥ 0.35, 𝐷 2 performs slightly better than 𝐷 1 . For a embedding ratio 𝑟 < 0.35 𝐷 1 delivers a better TPR than 𝐷 2 . Overall, we postulate that the single feature detector 𝐷 2 delivers better performances in our evaluation but for a real world application, we recommend to use 𝐷 1 first, because we assume a more robust detection with 𝐷 1 on real world application with more diverse training and testing. The optimal value sequence length |𝑆𝑒𝑞| has to be re-determine for every field of application and its training and test sensor data. Additionally, |𝑆𝑒𝑞| can significantly vary because of different embedding strategies and other resulting anomalies. Evaluation Results In this section we discuss the evaluation results for our detectors 𝐷 1 and 𝐷 2 trained with presented data in 6.2.1 and tested with data presented in 6.2.2. This section is structured according to the evaluation goals 1, 2 and 3 presented in Section 6.1. 6.3.1 Performance of Detector 𝐷 1 and 𝐷 2 (Goal 1). The detection performance results for 𝐷 1 and 𝐷 2 are presented in Table 5. Both Detector 𝐷 1 and 𝐷 2 can reach their best performance results with a value sequence length of |𝑆𝑒𝑞| = 22. The detection performance varies strongly for different |𝑆𝑒𝑞|, even for small variations of |𝑆𝑒𝑞| (see results for |𝑆𝑒𝑞| = 23 or |𝑆𝑒𝑞| = 21). We have not found a comprehensive reason for this, yet. However, for |𝑆𝑒𝑞| = 22 the feature spaces 𝐷 1 and 𝐷 2 deliver the best separation precision between the two classes of data. As assumed before, the optimal size or length for |𝑆𝑒𝑞| has to be quite low that the features have a separation precision because the steganographic embedding is warden compliant (see [13]) for longer value sequences (we assume 6.3.3 Embedding Ratio 𝑟 vs. Detection Performance (Goal 3). During our evaluation, we observe an correlation of the steganographic embedding ratio 𝑟 and the detection performance. Obviously, we can state that higher embedding ratios result in a better detection performances (high TPR) and a decreasing performance when the 122 IH&MMSec ’21, June 22–25, 2021, Virtual Event, Belgium Session 5: Steganography I Information Hiding in Cyber Physical Systems IHMMSec ’21, June 22–25, 2021, Virtual Event, Belgium Table 5: TNR and TPR for Detector 𝐷 2 and 𝐷 1 for different |𝑆𝑒𝑞| on test data sets (FPR complementary to TNR for 𝑇 𝐷𝑆𝑆 1 and 𝑇 𝐷𝑆𝑆 2 ). |𝑆𝑒𝑞 | 10 18 19 20 21 22 23 24 30 40 50 100 |𝑆𝑒𝑞 | 10 18 19 20 21 22 23 24 30 40 50 100 𝑇 𝐷𝑆𝑆 1 TNR(𝐷 2 ) TNR(𝐷 1 ) 99.1 95.2 99.5 91.9 100 85.4 100 93.5 100 84.5 100 93.9 100 85.5 99.4 70.3 82.6 70.5 100 64.6 74.7 68.4 28.2 82.1 𝑇 𝐷𝑆𝑆 1 𝑟 1.00 TPR(𝐷 2 ) TPR(𝐷 1 ) 41.7 46.1 68.8 70.1 54.0 43.7 78.6 78.6 61.7 59.1 87.8 81.7 68.6 64.8 67.6 48.6 61.9 50.0 79.0 62.9 46.0 52.0 87.5 62.5 𝑇 𝐷𝑆𝑆 1 𝑟 0.50 TPR(𝐷 2 ) TPR(𝐷 1 ) 28.9 31.2 49.8 54.0 38.7 30.5 57.2 56.7 51.2 50.3 61.6 61.6 27.4 36.6 53.4 40.2 47.1 43.8 59.3 45.8 29.8 43.0 81.2 45.3 𝑇 𝐷𝑆𝑆 1 𝑟 0.37 TPR(𝐷 2 ) TPR(𝐷 1 ) 28.1 31.7 48.3 50.5 43.3 34.2 53.8 55.3 48.8 49.9 56.4 55.9 18.7 30.9 53.9 44.9 48.6 42.7 54.2 47.5 34.0 43.4 81.2 35.9 𝑇 𝐷𝑆𝑆 1 𝑟 0.25 TPR(𝐷 2 ) TPR(𝐷 1 ) 19.1 22.1 33.9 38.1 30.8 28.5 39.1 39.6 35.4 39.9 39.3 40.1 10.4 25.7 39.8 41.7 39.3 39.4 39.1 42.2 33.2 42.3 77.4 29.9 𝑇 𝐷𝑆𝑆 1 𝑟 0.17 TPR(𝐷 2 ) TPR(𝐷 1 ) 13.9 18.0 24.3 28.8 21.1 21.6 26.7 28.3 25.0 31.9 28.7 30.3 6.4 21.4 28.9 36.1 34.5 36.4 28.5 40.8 32.5 36.4 75.1 32.6 𝑇 𝐷𝑆𝑆 2 TNR(𝐷 2 ) TNR(𝐷 1 ) 99.5 93.5 100 94.4 100 89.1 100 96.0 100 85.6 100 94.8 100 87.3 100 77.7 86.3 71.6 100 75.2 86.2 77.1 48.1 92.6 𝑇 𝐷𝑆𝑆 2 𝑟 1.00 TPR(𝐷 2 ) TPR(𝐷 1 ) 42.7 45,7 62.2 66.1 54.3 43.7 77.5 79.5 62.9 65.8 82.5 81.8 62.7 67.5 64.3 57.9 59.7 54.2 66.7 62.0 43.0 56.0 86.4 67.0 𝑇 𝐷𝑆𝑆 2 𝑟 0.95 TPR(𝐷 2 ) TPR(𝐷 1 ) 43.0 45.7 62.2 68.9 51.9 41.5 73.7 74.7 59.3 65.8 83.9 81.6 62.6 63.0 59.9 55.4 51.6 52.6 62.2 59.0 35.4 56.8 77.2 62.0 𝑇 𝐷𝑆𝑆 2 𝑟 0.70 TPR(𝐷 2 ) TPR(𝐷 1 ) 36.2 38.7 58.5 59.8 47.0 39.5 66.9 65.7 54.5 56.5 71.9 70.1 46.3 47.5 57.6 46.4 46.7 47.5 55.6 50.1 27.4 47.6 70.9 46.6 𝑇 𝐷𝑆𝑆 2 𝑟 0.50 TPR(𝐷 2 ) TPR(𝐷 1 ) 31.2 33.4 51.5 54. 40.8 29.6 55.6 55.6 47.0 49.0 56.9 55.5 29.7 36.5 48.5 42.1 37.6 39.3 43.9 42.4 22.4 37.5 60.7 32.0 𝑇 𝐷𝑆𝑆 2 𝑟 0.33 TPR(𝐷 2 ) TPR(𝐷 1 ) 21.1 23.1 35.6 38.8 29.5 20.7 39.3 39.4 34.1 38.8 40.6 42.3 15.5 25.9 36.2 34.7 29.2 37.1 32.5 38.3 16.9 34.9 51.7 31.7 embedding ratio falls down. We achieve a detection performance of up to 87.8% when every value in a data set contains steganographic embedding (𝑟 =1.0) with a value sequence length |𝑆𝑒𝑞 = 22|. But, the detection performance is more robust than expected, it decreases not as significant as the embedding ratio 𝑟 . If the embedding ratio drops for example to 25% (𝑇 𝐷𝑆𝑆 1 𝑟 0.25 ) the detection performance is still around 40% TPR with 𝐷 1 and |𝑆𝑒𝑞| = 22. It is interesting, that the detector 𝐷 2 is able to detect up to 28.7% of steganographic samples with |𝑆𝑒𝑞| = 22 on the water-flow data set 𝑇 𝐷𝑆𝑆 1 𝑟 0.17 with a, embedding ratio of only 𝑟 = 0.17 and a FPR = 0%. This means the detectors are able to detect (with |𝑆𝑒𝑞| = 22) nearly one out of three samples correct, even if only 3 or 4 (in average 3.74) out of 22 values analyzed in a sample are modified with steganographic embedding. With sacrificing a high TNR (results in higher FPR), also higher detection performances of up to 40.8% for 𝐷 1 with |𝑆𝑒𝑞| = 40 can be achieved for data sets with low embedding ratio 𝑟 = 0.17 (𝑇 𝐷𝑆𝑆 1 𝑟 0.17 ). 7 Figure 4: Performance of detectors 𝐷 2 and 𝐷 1 with |𝑆𝑒𝑞| = 22 for all test data sets sorted by embedding ratio to render detection by a warden less likely. Our experimental evaluation shows the feasibility of this approach for the selected attack scenario. In this first evaluation, using the proposed embedding strategies a bandwidth between 80kb and 370kb per day (depending on the sensor) could be achieved. Given a targeted long-term scaled attack scenario this covert channel seems to be a viable option for data exfiltration over a longer period of time. In the process of designing covert channels for CPS several challenges arise, especially in regards to cover channel selection, sender receiver synchronisation and retrieval. Our approach addresses these by proposing different methods. In the context of this specific covert channel we describe the general concepts of recaching, the difference of asynchronous, synchronous and ephemeral channels as well as the temporal aspect in from of levels of persistence. These concepts apply CONCLUSION & FUTURE WORK At the example of two types of sensors commonly found in Cyber Physical Systems (CPS), we present a network covert channel aiming at exfiltrating sensible information of Industrial Control Systems (ICS). Leveraging the circumstance that in such environments process data is usually stored persistently in historian databases, this channel is based on a protocol-agnostic approach, using longterm persistent asynchronous communication. By using different embedding strategies this approach is bandwidth adaptive, aimed 123 IH&MMSec ’21, June 22–25, 2021, Virtual Event, Belgium Session 5: Steganography I IHMMSec ’21, June 22–25, 2021, Virtual Event, Belgium Lamshöft and Neubert, et al. to covert channels in Cyber Physical Systems but might be applicable as well to other domains of Information Hiding. Additionally, we introduce two novel detection approaches 𝐷 1 and 𝐷 2 based on [10]. These detection approaches work with value sequences |𝑆𝑒𝑞| which are used to create a sample for training or classification. The optimal size or length for |𝑆𝑒𝑞| has to be determined by an exploratory analysis. 𝐷 2 achieves a TPR of 87.8% by a FPR of 0.0% for value sequence |𝑆𝑒𝑞| = 22 for an embedding ratio of 100%. The performance of the approaches varies strongly for different |𝑆𝑒𝑞| (even for small adjustments) and decreases for |𝑆𝑒𝑞| > 50. If the embedding ratio decreases the detection performance decreases significantly. With an embedding ratio of 𝑟 = 0.17 𝐷 2 is able to detect still 28.9% of steganographic samples (TPR) with 0% FPR and |𝑆𝑒𝑞| = 24. In comparison, our single feature detector 𝐷 2 delivers better results in our evaluation than 𝐷 1 for embedding ratios < 32% with |𝑆𝑒𝑞| = 22, 𝐷 1 has a slightly better TPR for embedding ratios ≥ 32%. The detection delivers slightly better results for waterflow sensor data sets than for water-level data sets, we assume this is caused by training. While the results for the proposed covert channel look promising, the presented methods shall be further analysed and investigated in the future. One major aspect for further investigation is the robustness of the presented covert channel in regards to its communication flow along several intermediate nodes, especially ones which employ protocol (or data-) conversions. Further improvements are planned for the cover model and noise calculation as well as testing a dynamic capacity selection based on the current noise of the sensor and process. The idea here is to fully automate the processes 𝑃1 to 𝑃4 Cover Model Generation, Cover Channel Selection, Cover Model Application and Cover Object Selection. Furthermore, the applicability of the presented approach on other types of sensors is investigated in the future as well. Another aspect to be tested in the context of this approach is tactical deception (e.g. [23]), which can be seen as a technique of anti-forensics in IT-Security.
SWaT: A Water Treatment Testbed for Research and Training on ICS Security Abstract—This paper presents the SWaT testbed, a modern industrial control system (ICS) for security research and training. SWaT is currently in use to (a) understand the impact of cyber and physical attacks on a water treatment system, (b) assess the effectiveness of attack detection algorithms, (c) assess the effectiveness of defense mechanisms when the system is under attack, and (d) understand the cascading effects of failures in one ICS on another dependent ICS. SWaT consists of a 6-stage water treatment process, each stage is autonomously controlled by a local PLC. The local fieldbus communications between sensors, actuators, and PLCs is realized through alternative wired and wireless channels. While the experience with the testbed indicates its value in conducting research in an active and realistic environment, it also points to design limitations that make it difficult for system identification and attack detection in some experiments. Keywords: Cyber Physical Systems, Industrial Control Systems, Cyber Attacks, Cyber Defense, Water Testbed I. INTRODUCTION In recent years, cyber-security threats to Industrial Control Systems (ICS) have received increased attention from the industry and research communities. ICS are built from, and depend upon, the integration of computational algorithms and physical components. ICS have evolved as a natural consequence of increasingly interconnected physical processes. They interact with the physical world, i.e., by sensing and actuating physical processes, and also with users, e.g., via human-machine-interfaces (HMIs), engineering work stations, corporate work stations, smart phones, etc. ICS are found in diverse areas such as critical infrastructure systems (electricity, water, gas distribution, communication and transportation networks), industrial applications (such as process plants, automotive industries), and small scale systems (such as robotics, health care systems, and home automation). The inclusion of networking within an ICS, and in some cases its connectivity to the Internet, introduces the threat of cyber attacks. Such attacks could come from inside the system perimeter such as by an employee, or through the network from an outside attacker. In either case, researchers have proposed algorithms for the prevention and detection of attacks. Mechanisms for defending an ICS against attacks have also been proposed. However, many of the published 978-1-5090-1161-2/16/$31.00 ©2016 IEEE algorithms are assessed for their effectiveness using simulation or numerically [2], [4], [6], [15], [16] This paper describes an operational ICS, the Secure Water Treatment (SWaT) testbed. SWaT was designed and built to enable experimental research in the design of secure ICS, and is one of the core components of a larger research effort in iTrust, all focusing on the design of secure cyber-physical systems. In addition to the testbed, work is also underway on complementary tools such as simulation environments [1], attack, and defense modeling tools. The long term objective of SWaT, and other testbeds that would be operational alongside SWaT, is to transform the process of ICS design. The current state-of-the-art in ICS design focuses on functionality and safety. Testbeds, and the associated research projects under the iTrust research center, are aimed at bringing cyber security into the design stage of ICS. However, doing so requires extensive experimentation to validate software and hardware based methods and tools aimed at improving ICS resilience. Testbeds such as SWaT are essential for such validation. All testbeds under iTrust are available for collaborative projects that allow the broader ICS community to contribute to realizing the longterm goal of transforming ICS design process. Contributions: (a) Design of a testbed for research in cyber security of Industrial Control Systems. (b) Use of a testbed in assessing the effectiveness of methods for cyber attacks and and defense against. Organization: The remainder of this paper offers an introduction into the architecture of SWaT, its utility, and lessons learned. The overall physical and cyber architecture of SWaT is in Section II. A set of sample experiments conducted so far using SWaT, and the outcome, are in Section III. Similar testbeds and a brief comparison with SWaT are in Section IV. Strengths and shortcomings of SWaT are in Section V. The conclusion and future plans for the use of SWaT and collaboration with other researchers are provided in Section VI. II. A RCHITECTURE OF SWAT SWaT is an operational testbed for water treatment producing 5 US gallons/hr of filtered water. In a small footprint of approximately 90 square meters (Figure 1), the testbed represents a small-scale version of a large modern water UV dechlorinator Ultrafiltration Unit Chemical dosing station Reverse Osmosis Unit Cabinet with PLCs Fig. 1. A pictorial view of SWaT. The Reverse Osmosis unit is seen in the front, while the view on Ultrafiltration unit, tanks, and several other components is obstructed. treatment plant found in large cities. The overall testbed design was coordinated with Singapore’s Public Utility Board, the nation-wide water utility company, and constructed by a third party vendor. That collaboration ensured that the overall physical process and control system closely resemble real systems in the field, so that the results can be applied to real systems as well. We use SWaT to investigate cyber-attacks and respective systems responses, and to conduct experiments with novel countermeasure designs (e.g., physics-based). As shown in Figure 2, SWaT consists of six stages labeled P1 through P6. Each stage is controlled by its own set of dual PLCs, one serving as a primary and the other as a backup in case of any failure of the primary. Overall, the testbed leverages a distributed control approach in normal operations, where each process stage is individually controlled by the local PLCs. For some of the process stages, the local control requires state information from other process, to obtain this information, the PLCs are networked and in constant communication. In addition to this automated distributed control mode, the operator can also manually control all actuators of the testbed through the HMI, and the SCADA system. Communications: We provide a general overview of the communication structure in Figure 3. Within each process stage, the main PLC obtains data from local sensors and controls actuators such as pumps and valves. For example, turning the pumps ON, or opening a valve, causes water to flow either into or out of a tank. In addition to the actuators, sensors such as level sensors in each tank enable the PLCs to monitor the status of the system, and to decide when to turn a pump ON or OFF. Several other sensors are available to check the physical and chemical properties of water flowing through the six stages. The local communications between a PLC and its direct sensors and actuators is using an Ethernetbased ring topology, using Allan-Bradley’s Device Level Ring (DLR) protocol. The ring ensures that loss of a single link can be tolerated, and no data or control functionality is impacted. Between the different process stages, PLCs communicate with each other through a separate network, which we call L1 network. That network is based on a conventional Ethernet star topology, with an industrial switch connecting all 6 process stages, the HMI, SCADA system and historian. All network communication by PLCs, sensors and actuators in SWaT is using the industrial EtherNet/IP (ENIP) and Common Industrial Protocol (CIP) stack [8]. In ENIP, sensor values or actuator settings are mapped to tags. Each tag can be addressed either via a string descriptor defined by the system designer (e.g., MV101 for motorized valve 1 in process 1), or a more direct mapping to bank number and pin number or similar (directly referring to digital/analog pins of a unit’s IO panel). Communications among sensors, actuators, and PLCs can be via either wired Ethernet or Wi-Fi links; manual switches allow to change the configuration between the wired and wireless communication. Stages in SWaT: Stage P1 controls the inflow of water to be treated by opening or closing a valve (not shown) that connects the inlet pipe to the raw water tank. Water from the raw water tank is pumped via a chemical dosing (stage P2,chlorination) station to another UF (Ultra Filtration) Feed water tank in the stage P3. In stage P3, a UF feed pump sends the water via UF membrane to RO (Reverse Osmosis) feed water tank in stage P4. Here an RO feed pump sends the water through an ultraviolet de-chlorination unit controlled by a PLC in stage P4. This step is necessary to remove any free chlorine from the water prior to passing it through the reverse osmosis unit in stage P5. Sodium bisulphate (NaHSO3) can be added in stage P4 to control the ORP (Oxidation Reduction Potential). In stage P5, the de-chlorinated water is passed through a 3stage RO filtration unit. The filtered water from the RO unit is stored in the permeate tank and the reject in the UF backwash tank. Stage P6 controls the cleaning of the membranes in the UF unit by turning on or off the UF backwash pump. The backwash cycle is initiated automatically once every 30 minutes and takes less than a minute to complete. Differential pressure sensors in stage P3 measure the pressure drop across the UF unit. A backwash cycle is also initiated if the pressure drop exceeds 0.4 bar, indicating that the membranes need immediate cleaning. A differential pressure meter installed in stage P3 is used by PLC-3 to obtain the pressure drop. Each PLC has memory locations, known as tags, to save sensor data. There is one tag for each sensor connected to a PLC. These tags are accessible across the entire SWaT. Thus, for example, the level of tank T301 in stage P3, can be obtained by PLC 1 to decide whether to start pump P101. Tag values are also sent to SCADA on demand. All sensor data, at every time instant, can be sent to the historian and saved for future analysis. Note that the historian resides in a separate computer connected via the Level 1 network to the PLCs and SCADA system. The availability of tag values at different points in SWaT was found useful in implementing attack detection algorithms. For example, PLC 3 can look into tags in PLC 1 to check if a process invariant—a physical condition—that uses sensors connected to both PLC 1 and Raw water MV101 x Chemical tanks and dosing pumps P1 LIT101 Raw Water Tank T101 HCL P101 Pump x NaOCl NaCl P203 P201 FIT201, AIT201 P205 P2 Static Mixer MV201 AIT202, AIT 203 Chemical dosing station P3 P4 Ultraviolet (UV) Dechlorinator AIT402 x x FIT401 P401 RO Feed Pump LIT401 RO Feed Tank T401 DPIT301 x LIT301 Ultrafiltration Unit (UF) x NaHSO3 P5 Cartridge Filter x AIT503 RO Boost Pump P501 Reverse Osmosis (RO) Unit x AIT504 Re UF backwash Tank T502 Raw Permeate Pr Tank T501 UF Feed Tank T301 P301 UF Feed Pump P6 UF backwash Pump P602 Water return to T101 Pr: Permeate Re: Reject Fig. 2. Physical water treatment process in SWaT and attack points used in the case study. P1 though P6 indicate the six stages in the treatment process. Solid arrows indicate flow of water or chemicals in the dosing station. Dashed arrows indicate potential cyber attack points. LIT: Level Indicator and Transmitter; Pxxx: Pump; AITxxx: Property indicator and Transmitter; DPIT: Differential Pressure Indicator and Transmitter. outlined experiments are just the first steps, and more detailed results will follow soon. SCADA, HMI, Engineering Workstation, Historian etc. Level 1 P1 Control Program P2 Control Program Level 0 Level 0 Sensors Actuators Sensors Actuators Pn Control Program Level 0 Sensors Actuators Fig. 3. Architecture of the control portion of a CPS. P1, P2,. . . ,Pn denote PLCs. Each PLC communicates with its sensors and actuators through a local network at Level 0. PLCs communicate among themselves via another network at Level 1. Communication with SCADA and other computers is via a Level 3 network not shown here. Note that the actuators, e.g., a pump, also have sensors to indicate their condition. PLC 3, is true. III. E XPERIMENTS WITH SWAT SWaT is serving as a fertile playground for faculty and researchers at SUTD, external academic collaborators, and commercial organizations. We believe that academic security research on ICS suffers from the general problem that it is difficult to access live ICS, in particular any active (securityrelated) tests in such systems are typically impossible. As a result, realistic examples of detailed ICS are rare, and theoretical assumptions made by researchers can be misleading. To mitigate that problem, we started a range of experiments on SWaT, which are supposed to give other researchers a better insight into the setup of an ICS such as SWaT. We hope that such information facilitates research activities, in particular assessment of academic and commercial prototypes, and experimental techniques. As SWaT is available for collaborative projects with our international partners, we expect that the A. Attacker Model Initial system reconnaissance and first attacks on the system were launched soon after SWaT became operational. In particular, we focused on several attacker settings: a) an attacker A who has access to the local plant communication network, b) an attacker B who is in physical proximity, but not directly on site, and c) an attacker C who is on site and has physical access to the devices. In all cases, the goal of the attacker is to manipulate the normal operations of the plant. In an exemplary attack, the goal was to overflow the raw water tank in SWaT. It is argued that that this goal, while not threatening high damage, is representative for an attack that requires attackers to fully control sensor and actuators in an ICS. At the same time, it is safe enough to achieve in the lab without damaging equipment. For the first attack scenarios in Section III-B, we assume that the attacker has general knowledge about the technology used, but does not know details of the system under attack yet. In that setting the attacker tries to obtain more information on the system under attack, and find additional attack vectors to manipulate the system. In particular, the attacker has tools to interact with the industrial devices using the specific industrial protocols, such as EtherNet/IP and CIP [8]. B. System Reconnaissance The experimental reconnaissance attack assumed the presence of an attacker A, that has access to the L1 plant network. We used a standard laptop with wired and wireless network interfaces, with open source networking tools such as Wireshark and Zenmap. With that setup, we were able to quickly map the local networking setup, and determine the available services on the hosts. We discovered a range of web interfaces on the local PLCs and networking devices. In particular, devices such as PLCs provide an informative web interface with a summary of their configuration and setup. In addition, the local HMI device (AB PanelView Plus Terminal) is running an embedded Windows OS, an FTP server that allows anonymous login, and a remote desktop protocol (RDP) server. Anonymous FTP login enabled the discovery of hidden files that appear to contain the complete HMI configuration in a proprietary format (Composite Document File V2). As all PLCs, the HMI and the SCADA system are within the same Link-layer broadcast domain, it was possible to launch ARP spoofing attacks using Ettercap [3]. For more details on that attack, refer to [1]. As a result of the attack, the attacker is able to arbitrarily re-direct local traffic through his machine, and eavesdrop or manipulate the content. We found that the industrial protocol used, ENIP, does not feature any authentication or encryption in our testbed. Protocol analyzers such as Wireshark are able to decode ENIP to some degree, so that exchanged data can be extracted. We are currently also working on extensions for the Scapy tool, to enable automated processing and generation of ENIP traffic. In addition to sensor data and actuator commands, it was also possible to capture actions such as remote firmware and logic updates, from the SCADA to individual PLCs. The new programming seems to be sent around in cleartext (as binary file), so it would be possible for attacker A to obtain detailed information on the used logic on the PLCs, and also to reprogram the PLCs with manipulated logic. C. Compromise through Wireless Network Following the first set of experiments on reconnaissance, further investigation was carried out on potential compromise by attacker B, an attacker within WiFi range of the plan control system. In particular, the SWaT testbed has the option to replace the wired Ethernet-based L1 network with a WiFi-based wireless solution. The alternate wireless network uses industrial access points (the MOXA AWK-5222-EU) to connect the devices, and employs the WPA2 security scheme with pre-shared keys. Assuming that the pre-shared key is strong enough to not be guessed outright, there are several options for the attacker: a) the attacker can try to perform a (cloud-based) brute force attack, b) the attacker can perform a well-known evil twin attack[11] to impersonate the legitimate AP, and trick the PLCs to connect to it instead. Suitable tools for both attacks exist, for example the Aircrack-Ng tool. The feasibility of the brute-force approach depends greatly on the strength of the chosen password. In our case, we left the choice of the password to the system integrator, and we found that the chosen password would easily be guessable with a dictionary. In addition, it was noted during the wired reconnaissance of attacker A, that the AP provides a web interface for configuration, and that its default user account for that web interface had the default password. That password enabled cleartext password for the wireless network of that AP in the HTML source code (the rendered HTML replaced it with bullet points). As a result, attacker A would be able to obtain the WiFi password quickly, and be able to use it later to remotely connect to the WiFi network to launch attacks from a safe distance. D. Compromise through Direct Physical Access Attacker C, who has direct physical access to the network, has a range of additional options to attack the SWaT testbed. In particular, the attacker could arbitrarily re-wire networking cables, insert passive taps (such as [9]), or manipulate sensors [14]. It was also found that the PLC model (1756 ControlLogix) used in SWaT features SD card slots that can be used to update the coded control logic in the PLC. While this is yet to be tested in practice, this seems like a promising attack vector for attacker C. E. Conclusion on Attacker Model Several ways were identified as to how attackers A,B, and C can fully manipulate the communication in the L0 ring or L1 networks. As a result, the outlined attacker will be able to insert itself as man-in-the-middle between any two parties (e.g. two PLCs), and will be able to eavesdrop on all exchanged sensor and command data. In addition, the attacker can use the Ettercap rules we designed to re-write sensor or command values on-the-fly. While the outlined attacks are well known in traditional computer networks, and several countermeasures are available, the initial configuration of the SWaT system did not provide any means to detect or prevent the ARP spoofing based attack. As a result, the attacker must be assumed to be able to obtain full knowledge of the topology, technology, and operational parameters of the attacked system. F. System Response to Attacks It is important to know how a CPS will respond to cyber and physical attacks. This information is useful in designing detection and defense mechanisms. While one could obtain this information based on modeling and simulation of the design using tools such as LabView [5] or Simulink [13], the assumptions made to create a working model might taint the results; recent comprehensive experimental work with a robot [12] serves to emphasize this point. Example 1: The purpose of this attack is to degrade the performance of SWaT from the nominal 5 gallons/minute to a lower value. To understand how this could be done, consider the fact that the UF unit contains micrometer sized membranes to remove small particles from the water to be filtered. PLC 6 (stage P6 in Figure 2) is programmed to clean the UF every 30 minutes by using a backwash process. However, depending on the quality of the incoming water, UF may need to be cleaned sooner. PLC 3 (stage P3 in Figure 2) is responsible for checking whether or not UF should be cleaned. This is determined by an examination of the data received from the differential pressure sensor, DPIT 301. This sensor checks the pressure difference across the UF, i.e., across the incoming and outgoing streams of water. A differential pressure higher than 0.40kpa indicates that the UF ought to be cleaned soon. A simple attack is to compromise the link from DPIT301 to PLC 3 and send false data to the PLC. This attack requires continuous reconnaissance of the DPIT data link and compromising it at an appropriate instant which could be any time before the programmed backwash cycle is to begin. This attack was launched by changing the DPIT301 value sent to PLC 3 from 20Kpa to 42kPa. Consequently PLC 3 initiated a backwash process as the pressure drop, as assumed by PLC 3, was more than the maximum acceptable, i.e., 40kpa. In a similar attack, sensor LIT401 was compromised. The impact of attacking sensor LIT401 was measured on the flow rate of water at the output of the RO unit. According to system specifications, this flow rate must remain at about 1.2cm/hr which leads to nearly 5 gallons/minute of treated water. The single point attack on LIT401 changed the level of the RO feed water tank, as known to the PLC in stage 5, from 800mm to 200mm. This caused the PLC to stop pump P401.Doing so reduced the amount of water produced to 113 gallons from the expected 155 gallons during the observation period. Example 2: A number of experiments were performed to investigate the effectiveness of process invariant(physics) based approaches in the detection of cyber attacks. One outcome of these experiments is a list of emerging design parameters that ought to be considered while designing a secure ICS. These parameters include the number of data points to be used by the PLC control logic to decide on what control action to take, and the number of data points to be used by the detection algorithm before it announces an attack or no attack. Several parameters that define an attack have also emerged. For example, in intermittent attacks, an attacker may control the width of the attack pulse to thwart the detection algorithm. Perhaps the most interesting outcome of these experiments was the realization that an attack launched on a sensor immediately prior to power outage, or immediately following power outage, is the most difficult to detect using invariant based approaches. IV. S IMILAR T ESTBEDS There exist a number of testbeds in the areas of power and water. Some of these allow simulation of large systems and do not actually produce power or water. Other testbeds are operational in the sense that they actually generate a usable product though in smaller quantities than their real counterparts. Both types have their pros and cons. Simulationbased testbeds allow large scale attack analysis, e.g., a large number of buses in a transmission system. Operational testbeds allow the conduct of experiments that input data from actual sensors and command actuators thus enabling more realistic validations than their simulation counterparts. In [7], the authors present a set of small scale physical processes and control systems from the domain of gas pipelines, water distribution, and manufacturing at the Mississippi State University. The individual process stages involve few sensors and RTU units, and industrial control software. In contrast to SWaT, the underlying physical processes are of much smaller scale. In particular, the SWaT testbed involves the full cycle of water treatment with several filtration stages, with a significant throughput of 5 US gallons per minute. In addition, the distributed control implemented in SWaT is significantly more complex than the controls implemented in that system. A miniwater testbed is available at the University of Lancaster [10]. It allows communications with field emulated sites using multiple communications media such as telephone or leased line, and satellite. The key advantage of having small tanks that fit in a bookcase, is that the impact of attacks can be observed quickly in contract to SWaT where the tanks are much larger that requires significant wait time before the impact of an undetected attack can be observed visually or via sensors. V. L ESSONS L EARNED FROM SWAT We now summarize a number of lessons learned from the process of designing and implementing the SWaT testbed, related to the industrial networking protocols, industrial software used, physical layout of the testbed, and the raw water used for filtration. A. Physical Layout of the Testbed The availability of a real physical testbed complete with process and controls continues to be a great benefit for our researchers. In addition, the testbed also developed to be a major attraction for guests visiting our campus. While we planned the testbed to be easily supervisable through a window from the neighboring room housing the SCADA system, it turns out that the physical layout of the testbed is not well suited towards groups of more than 5 visitors. In particular, larger groups of visitors have to spread out more in the lab, and have problems to understanding the guide. As a result, we are designing our future testbeds with such use cases in mind: larger open spaces allow visitors to both have an unobstructed view on the process, and stay in contact with the guide. In addition, we plan to have simple barriers to discourage guests from manipulating devices without consent. B. Industrial Protocols At the time of designing SWaT specifications for the system vendor, no specification was given for any particular industrial protocol to be used (e.g., Modbus/TCP); only Ethernet-based communication was a requirement. Consequently, the vendor proposed the use of EtherNet/IP and CIP, which was accepted by the tender evaluation team. That decision has turned out to be both advantageous and disadvantageous, as there is little existing open-source tool support to interact with EtherNet/IP protocols. That requires us to extend existing tools, and contribute to the community. If we had chosen to use Modbus/TCP instead, that effort (and contribution) would not have been required. C. Industrial Software Perhaps unsurprisingly, the industrial software used on the SCADA and Historian system is not very open towards integration with other tools or libraries. In particular, exporting collected data from the Historian to a comma separated value file format currently requires manual intervention for each tag value. While it might be possible to write own connectors to the used database in the future, the effort to obtain the measured data from the DB is exceeding our expectations. We would recommend others to address similar problems already in the specification stage of future testbeds. D. Sensor Availability Several limitations of SWaT have been observed during the course of experimentation to assess the effectiveness of methods to detect cyber attacks. While SWaT consist of a rich set of sensors, not all stages are equipped adequately. For example, there is no pH sensor at the output of the UF unit (see Figure 2). The lack of this sensor requires the use of a pH sensor immediately following the UV dechlorinator. Thus, the impact of UF on water pH cannot be measured directly. This might impact system identification studies where a linear dynamical model of only stages P1 through P3 is to be constructed. For future testbeds, it is thus advisable to “over-instrument” the testbed to allow for more flexibility in experimentation and re-configuration. We note that there are several trade-offs to consider in that context, in particular, physical limitations to the number of sensors that can be used without the sensors themselves influencing the process. As a result, sensors such as flow meters cannot just be inserted every 30 cm of pipe section. In the context of water systems, many sensors must also be placed at specific locations to obtain representative values. For example, sensors should have a certain distance to pipe bends, or other sensors or actuators. In addition, industrial sensors have non-negligible hardware cost, and require wiring, IO slots on the PLCs/RIOs, and appropriate programming of the PLCs. E. Raw Water The current design takes in raw water (stage P1) from the campus water line. This water is pure in the sense that it is drinkable. To conduct experiments that detect attacks aimed at impacting water quality, it would be helpful to add water of quality similar to what is input to the treatment system in a selected city, e.g., Singapore. Doing so is not possible in SWaT as the overall system is designed for certain minimal quality of the water in tank T101. The design is currently being modified to make it possible to add significantly impure water to T101 without any damage to the remaining sub-processes. VI. C ONCLUSION AND F UTURE W ORK A number of ICS security related projects in iTrust are currently using SWaT. In addition collaborators from organizations within and outside of Singapore have begun using SWaT. To make collaboration easier, it is proposed that access to SWaT be online thus allowing authorized researchers to access it from anywhere. Obviously, doing so comes with its own challenges such as secure access, visibility into every system component, 24/7 availability, etc. Currently, the treated water in SWaT is recycled within the treatment process itself. In the future, the product water of SWaT will also be used as input water for a second testbed, which is currently under construction. That second testbed will focus on a water distribution testbed. That interconnection will allow the assessment of impact of attacks propagation multiple testbeds. Cascading effects of cyber attacks across multiple ICS is a challenging research problem. It is planned that the electric power testbed under design in iTrust will be linked to SWaT. Doing so will allow experimentation to assess the impact of cyber attacks on the power grid on the operation of SWaT. The ICS interconnection will also make it feasible to study the impact of multiple simultaneous attacks on two ICS. ACKNOWLEDGEMENTS This work was supported in part by a grant from the Ministry of Defense, Singapore. Thanks to Sridhar Adepu and Kaung Aung for collecting and sharing some of the data and SWaT related information included in this paper, and Nicolas Iooss for experimental work on the attacks.
1. Introduction 1.1 The Critical Infrastructure Security Showdown– Online 2020 (CISS2020-OL), conducted over two weeks from July 27 - Aug 7, 2020 at the Singapore University of Technology and Design (SUTD), was the fourth run of iTrust’s technology assessment exercise. Owing to the pandemic, CISS was moved to an entirely online platform. Doing so allowed participants – red and blue teams – to still enjoy the same level of access and experience to the exercise platform as if they were physically onsite. 1.2 CISS2020-OL was sponsored by Singapore Government agencies, the Ministry of Defence and the National Research Foundation. 2. Objectives 2.1 CISS2020-OL’s key objectives are to: (a) validate and assess the effectiveness of technologies developed by researchers associated with iTrust; (b) develop capabilities for defending critical infrastructure under emergency situations such as cyber-attacks; and (c) understand composite Tactics, Techniques and Procedures (TTPs) for enhanced Operation Security (OpSec). 2.2 From the perspective of participating red teams, CISS2020-OL provided hard-to-get insight and hands-on experience in understanding the approaches required for compromising critical infrastructure. 3. Phases in CISS2020-OL CISS2020-OL consisted of the following time-sequenced phases: Phase I [May 4 - 29, 2020] : Participant selection (red & blue teams, observers) Phase II [June 22 - July 3, 2020] : Participant familiarisation (red & blue teams) Phase II-A [June 22] Blue team briefing Phase II-B [June 29] Red team briefing Phase II-C Judge briefing Phase III [July 6 - 16, 2020] : Target system selection (red teams) Phase IV [July 27 - Aug 7, 2020] : CyberFire (red & blue teams, observers) UNRESTRICTED 6 Phase V [Q3 – Q4, 2020] : Data analysis and reporting Throughout the document there will be several mentions of the tools deployed by iTrust to manage the entire exercise. Readers are encouraged to familiarise themselves with these terms by referring to paragraph 10 of this report. 3.1. Phase I: Participant selection 3.1.1. Participation in CISS2020-OL was by invitation only. Participants were classified into: a) Red teams (up to 6 members per team): o 18 local and international teams from government organisations, private sectors and academia, including two from iTrust. o Participating teams were from Finland, France Netherlands, Poland, Singapore, South Korea and United States of America. b) Blue teams (no limit on the number of members): o 12 teams from private sector and academia, including 6 teams from iTrust c) 3.2. Remote observers: Singapore Government agencies and their invitees. Phase II: Participant familiarisation 3.2.1. All red and blue teams were given an online tour of the Secure Water Treatment (SWaT) testbed. Briefing and Q&A sessions were also organised for red and blue teams. 3.2.2. In addition, the red and blue teams were provided documented information on SWaT, the digital twin, digital twin player, and various anomaly detection and plant safety technologies that would be deployed during the exercise. 3.2.3. Blue teams that needed to install their hardware and learn the normal behaviour of SWaT were given sufficient time to do so. They were required to adhere the following: o The installations (hardware and software) do not disturb the regular plant operation and interfere with existing iTrust technologies; UNRESTRICTED 7 o o o o Make its own arrangements for the data generated by its hardware to be piped to their computers outside of the SWaT during the exercise; The installations respond as if in a real-time environment; The installations be completely removed post-exercise and restore SWaT to its original condition. The blue team would bear any cost for damages arising from the installation and/or teardown of the upgrades; and Disallowed to prevent, halt or thwart any attacks launched by the red teams. 3.2.4. Blue teams’ systems were connected to iTrust’s TAP switch to receive pcap data from Zycron Cyber City and SWaT (see Figure 4). For details on attack detection and reporting by blue teams, refer to paragraph 3.4.4.2. 3.3. Phase III: Target system selection 3.3.1. During this Phase III, each red team was provided with 7 instances of data collected from SWaT and its digital twin, referred to as Target 1, Target 2…Target 7. A higher score was given if the red team successfully selected SWaT as the target (see paragraph 3.4.4 for details on scoring.) 3.3.2. Red teams could choose to analyse the dataset in one of the following options: a) Option 1: Use the 2-hour slot to connect to Cloud VM to view the datasets and “play” the datasets view a player; or b) Option 2: Download the datasets 48 hours prior to their 2-hour slots and analyse them. 3.3.3. Details of both options are as follows: Option 1: Use 2-hour slot to connect to Cloud VM 3.3.4. Red teams were provided unique credentials to connect to Cloud VM 30 minutes before their target selection timeslot. OT data captured by the historian by each target system i.e., Target 1, Target 2…Target 7 from SWaT and the digital twin historians were available on the Cloud VM and could be viewed through PEPPR-PV and PEPPR-PP. Figure 1 on the next page captures the interactions between a red team and the targets. Note that ZCC (see para 3.4.1) was not available during this phase. UNRESTRICTED 8 Figure 1: Interactions between red team & CISS2020-OL system & tools in target selection 3.3.5. Red teams were provided unique credentials to connect to Cloud VM 30 minutes before their target selection timeslot. OT data captured by the historian by each target system i.e., Target 1, Target 2…Target 7 from SWaT and the digital twin historians were available on the Cloud VM and could be viewed through PEPPR-PV and PEPPR-PP. 3.3.6. Each red team was asked to make known their target system selection to iTrust within 2 hours from the end of their target selection slot. Option 2: Download the datasets 48 hours prior to their 2-hour slots 3.3.7. If the red team selected this option, the datasets were available for download by the red team 48 hours before its target selection slot (e.g. if the slot it chose was Wednesday, 4pm (GMT+8) then the link to download the dataset would be sent to it on Monday, 4pm (GMT+8). The red team was given 48 hours to make known its selection to iTrust. 3.3.8. Regardless of its selection (whether it chose SWaT or digital twin) during this phase, all red teams were given the full four hours to launch attacks on SWaT. UNRESTRICTED 9 3.4. Phase IV: CyberFire activities The CyberFire activities were spread over 16 CFM (Table 1). The duration of each CFM slot was 4 hours, from 9am to 1pm or from 2pm to 6pm, GMT+8, with a one-hour break in between for system reset. Table 1: CISS2020-OL Schedule for red teams Date Mon July 27 Tue July 28 Wed July 29 Thu July 30 Week 1 CFM slot 1 (AM) SR 2 (PM) 3 (AM) SR 4 (PM) 5 (AM) SR 6 (PM) 7 (AM) SR 8 (PM) Fri July 31 Date Mon Aug 3 Tue Aug 4 Wed Aug 5 Thu Aug 6 Fri Aug 7 No activity; Public holiday Week 2 CFM slot 9 (AM) SR 10 (PM) 11 (AM) SR 12 (PM) 13 (AM) SR 14 (PM) 15 (AM) SR 16 (PM) 17 (AM) SR 18 (PM) CFM: CyberFire Module; red teams attack a target system; SR: System reset (1 hour) AM slot: 0900 – 1300; PM slot: 1400 – 1800, GMT +8 3.4.1. Attack platform For added realism, all red teams were required to attack SWaT by first entering the network via the ZyCron Cyber City (ZCC; Figure 2); they would land in ZCC’s corporate network through a VPN connection. ZCC is a full-fledged virtual organisation comprising Information Technology (e.g., e-mail server, file server, printer server, CCTV, honeypot and intranet) and Operational Technology (processes similar to those in SWaT). To make these entities “alive,” various types of network traffic were also crafted and included in ZCC. As an IT environment, ZCC was not set up with best practices i.e., it was intentionally built with minimum security features and contained vulnerabilities for red teams to explore and exploit. There was no internet access within the ZCC. UNRESTRICTED 10 Figure 2: High-level Architecture of ZyCron Cyber City 3.4.2. Launching attacks 3.4.2.1. Active stage During a CFM the active red team was asked to demonstrate its attacks and achieve the pre-determined goals (see para 3.4.4 for details on scoring). The CFM duration included, but was not limited to: reconnaissance, designing and launching attacks, interactions with judges (e.g., for Attack Logging; see Figure 3) and taking breaks. 3.4.2.2. Hunting stage All red teams had to enter SWaT via the ZCC to launch attacks. Failure to do so and to identify the pre-selected target system led to a lower score. If, during its CFM slot, attempts to penetrate into SWaT network through ZCC corporate network were unsuccessful after 30 mins, the red team could request to extend to up to 60 mins. If the attempt was still unsuccessful, iTrust assisted to port the red team over to SWaT. ZCC is built with typical enterprise vulnerabilities that exist in many organisations. The red team had to “hunt” for these vulnerabilities and compromise them before using them to “hop” deeper into the network and eventually locate SWaT/digital twin in the OT network. UNRESTRICTED 11 3.4.2.3. Attack launch stage Active teams had four hours to design and launch attacks on SWaT (see Figure 3). Figure 3: Interactions between red/blue teams & CISS2020-OL systems & tools in CyberFire Prior to launching attacks, the active red team were required to do the following throughout its CFM: a. Share with iTrust the “live” screen of the computer that is used to launch the attack via an online communication tool (e.g. Skype)1; b. Allow iTrust to video record the screen; and c. Inform judges (1) the intention of the attack; (2) the targeted component(s); and (3) the launch procedure. The duration of an attack was determined in real time by iTrust’s cyber security technology engineers stationed physically at SWaT. Attacks that took a long time, e.g., 30 minutes, to have a noticeable impact on the plant could be halted by the judges before the impact was visible. 3.4.3. Attack monitoring Any anomaly resulting from the attack, or otherwise (i.e., a false alarm), and reported by one or more iTrust detectors, was visible only to the organisers, observers and judges and not to the red or blue teams. 1 For iTrust’s post-event analysis and report writing purposes; recordings are not shared with anyone or made public without written permission by the red team UNRESTRICTED 12 3.4.4. Scoring of red teams The performance of each red team was assessed in real time by a team of judges comprising cyber security experts and engineers working in the critical infrastructure domain. Only single attacks, in series (one starts only after the previous one has ended), were allowed. Judges scored each red team based on criteria such as complexity of the attacks launched and success of the attack in resulting in an anomaly in at least one of the plant state variables. The total score, S, for each attack launched is computed based on five factors t, p, at, asd and b. These are described in detail below. Total score, S = t + p * (at1asd1 + at2 asd1 … atn asdn) + b where: • t = target selection modifier o Selected SWaT (t = 150) or one of the digital twins (t = 0) during target selection • p = point of entry modifier o All red teams must attack SWaT by first entering the network via the ZCC (para 3.4.2.); p = 1 o If attempts to enter ZCC are unsuccessful after 30 mins (request to extend to up to 60 will be considered), the team may proceed to attack SWaT or the digital twin (whichever was selected as the target in the selection phase) directly; p = 0.75 • at = an attack target is a physical component or parameter in the plant on which the red team wants to launch the attack. An attack target differs from the attack intention which is defined as the intended impact as a result of the attack on the target. For example, to cause a water tank to overflow (attack intention), an attacker may choose to launch an attack on a valve (attack target) by setting it to the CLOSED condition long enough, without getting detected, so that a continuous flow of water into the tank is maintained. • The 12 attack targets2, and their corresponding points in parentheses, if an attack 2 Activities or actions that would interfere, obstruct or disturb Participants, iTrust and running of the Exercise were strictly prohibited. In addition, the following were unavailable for attack: o Hypervisors o 10.10.0.0/16 UNRESTRICTED 13 is successful, in SWaT are: o o o o o o o o o o o Conductivity meter (300) Flowmeter (200) Historian4 (100) Water level meter (200) Oxidation Reduction Potential Meter (300) o pH meter (300) PLCs (100) Pressure meter (200) Pumps (200) SCADA (100) Network switches (100) Valves (200) • asd = attack success and detection modifier: whether an attack results in an anomaly, and whether the anomaly/attack is detected by any of the installed detectors. o asd = s * d o If the attack is successful, s = 1; else s = 0 o d is calculated as: ↓d s→ Attack results in an anomaly Attack does not result in an anomaly 0.7 -0.2 1 0 Anomaly/attack is observed* Anomaly/attack is not observed* *through physical observations of the plant and SCADA screen by plant operator and judges • b = bonus points for novel attacks (such as the ability to disrupt the anomaly detectors), at the discretion of the judges 3.4.4.1. Attack detection Throughout the event the blue teams monitored their systems remotely (Figure 4 next page). Post-event, blue teams were given pcap and OT data captured for analysis. o o o o o 1.2.222.0/24 9.9.0.0/16 Server rack: The server rack should not be attacked through physical layer Historian: Comprising historian not allowed General electric supply, fire alarm systems etc. UNRESTRICTED 14 Figure 4: Blue teams remotely monitoring their systems’ GUI 3.4.4.2. Reporting of alerts The above assumption implies that any alert generated by the security system deployed by a blue team was reported immediately to the plant operator automatically, not manually. While each blue team was provided event data at the end of the event, they were not expected to conduct an analysis of an alert generated during the event. Blue teams were requested to report each alert immediately as if it were occurring in a live plant and being reported to the plant operator. Reporting of alerts to iTrust by blue teams was done in one of the following two ways: a) PEPPR-PV: this required the blue team to work with iTrust’s developer to integrate with it, so that its detections/alerts could be sent to PEPPR-PV for automatic logging and visual alerts; or b) Alert logger: a simple password-protected interface to manually log a timestamped alert each time the blue team detected an attack. 3.5. Phase V: Data analysis and reporting 3.5.1 Data from each red team session were recorded and saved in the iTrust data library. These consisted of measurements from all sensors in SWaT as well as network packets saved into pcap files. Note that the recorded data contains data mutated by the red teams. 3.5.2 In the following sections, details regarding the types of attacks launched by red teams, description of the blue teams’ mechanisms and the analysis of detections made by the blue teams are reported. The analysis will result in metrics such as the number and UNRESTRICTED 15 types of attacks launched, success rate, detection rate (and false positives), and time taken to detect. 4. Description of Attacks Launched by Red Teams (selected) 4.1. Team KopiTiam (Singapore) 4.1.1 Manipulation of conductivity using chemical dosing pumps Objective Increase the conductivity value by controlling chemical dosing pumps P201 and P202 (refer to Figure 5) Attack Method Direct control of PLC using Python script Tools Pycomm Description Instead of the routine procedure whereby PLC turns on one dosing pump, attacker forcefully turned on two pumps concurrently, namely P201 and P202, for chemical salt (sodium chloride). With the additional dosage of salt into the water, the sensor, AIT201, reading for conductivity increases. Figure 5: Screenshot of an attacker’s script UNRESTRICTED 16 4.1.2 Manipulation of pH value by pumps Objective Decrease pH value by controlling chemical dosing pumps P203 and P204 (refer to Figure 6) Attack Method Direct control of PLC using Python script Tools Pycomm Description The attacker decreases the pH value of the water by turning on both the dosing pumps concurrently, namely P203 and P204, of the chemical hydrochloric acid, instead of the regular single pump. The sensor, AIT202, reflects a drop in the pH. Figure 6: Screenshot of an attacker’s script 4.1.3 Manipulation of ORP value by pumps Objective Increase ORP value by controlling chemical dosing pumps P205 and P206 (refer to Figure 7) Attack Method Direct control of PLC using Python script Tools Pycomm Description The attacker increases the ORP value of the water by turning on both the dosing pumps concurrently, namely P205 and P206, of the chemical UNRESTRICTED 17 sodium hypochlorite, instead of the regular single pump. The sensor, AIT203, reflects an increase in the ORP value. Figure 7: Screenshot of an attacker’s script 4.1.4 Manipulation of PLC routine and attack the pumps Objective To deceive the SCADA HMI of the incorrect conductivity value (refer to Figures 8 and 9) Attack Method Direct control of PLC using Python script and insert a malicious logic into the PLC routine Tools Pycomm and RSLogix 5000 Description The attacker inserted a malicious contact named RU_BY (Normally Closed) into the PLC routine using Allen Bradley’s proprietary software RSLogix 5000 to perform a Man-in-the-Middle attack between the remote IO (RIO) and SCADA HMI. This contact helps to block particular routines from execution and hence resulting in values from RIO not been transferred to the HMI tags. The attacker used pycomm script to set “ON” for RIO tags, meant for layer-0 network, of two chemical dosing pumps of sodium chloride and set “4000” of conductivity sensor reading through this layer-1 attack. As SCADA extracts the information from the HMI tags, sensor AIT201 for conductivity reading displays a spoofed value set by the attacker. UNRESTRICTED 18 Figure 8: Screenshot of the Malicious logic in the PLC Routine Figure 9: Screenshot of an attacker’s script 4.1.5 Manipulation of PLC routine to disrupt historian Objective To disrupt Historian from receiving updates from PLC 2 (refer to Figure 10) UNRESTRICTED 19 Attack Method Direct control of PLC using Python script and insert a malicious logic into the PLC routine Tools Pycomm and RSLogix 5000 Description The attacker inserted a malicious contact named RU_BY (Normally Closed) into the PLC routine using Allen Bradley’s proprietary software RSLogix 5000. In this situation, attacker inserted RU_BY to almost all the rungs before each routine and this resulted in RIO values from PLC 2 being not transferred to the HMI tags that are needed for the accurate intercommunication among the PLCs. As HMI tags do not contain valid values, accurate readings are not updated in the Historian. Figure 10: Screenshot of an attacker’s script 4.2. Team KPMG (Singapore) 4.2.1 Control of SWaT HMI Workstation Objective Take over the control of SWaT HMI Attack Method Exploit the host using Metasploit framework Tools Metasploit, mimikatz UNRESTRICTED 20 Description The attackers identified the HMI IP address through their enumeration and exploited the Windows 7 workstation with EternalBlue. With the meterpreter session, the attacker used mimikatz to retrieve the administrator’s credentials. The attacker connected to SCADA using Remote Desktop Protocol (RDP) and was able to control SWaT through the Graphical User Interface (GUI). 4.2.2 Control of motorised valve Objective Turn on MV101 to flood the water tank (refer to Figure 11) Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers identified all the PLCs IP addresses through their enumeration and executed the pycomm script to turn on motorised valve, MV101, with the intention to flood the water tank. a) Set AUTO mode to FALSE b) Set motorized valve MV101 to OPEN Figure 11: Screenshot of an attacker’s script 4.2.3 Control of pump Objective Turn on P101 to burst the pump (refer to Figure 12) Attack Method Direct control of PLC using Python script Tools Pycomm UNRESTRICTED 21 Description The attackers executed the pycomm script to turn on the pump, P101, while the subsequent motorised valve, MV201, was closed with the intention to burst the pipe. a) Set AUTO mode to FALSE b) Set pump P101 to OPEN Figure 12: Screenshot of an attacker’s script 4.2.4 Manipulation of wireless access point (AP) Objective Disrupt the wireless operation (refer to Figure 13) Attack Method Not applicable Tools MOXA software Description The attackers identified MOXA service and login with default “nil” credential. From the GUI, the attacker exploited a CLI, command-based input, used for pinging devices in the network to issue a UNIX command and dump the password file with the intention to extract possible password hashes. UNRESTRICTED 22 Figure 13: Screenshot of MOXA 4.2.5 Control of level indication transmitter (LIT) Objective Spoof LIT101 reading to cause flooding (refer to Figure 14) Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers executed the pycomm script to spoof the LIT101 sensor reading to be “low” even though the actual reading is “high”, which will trigger motorised valve, MV101, to turn on for refilling the water tank and caused the water level to increase. a) Check the current LIT101 value b) Set LIT101 simulation mode to TRUE c) Set LIT101 simulation value to 45 Figure 14: Screenshot of an attacker’s script UNRESTRICTED 23 4.2.6 Control of flow indication transmitter (FIT) Objective Spoof FIT101 reading to close MV101 Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers executed the pycomm script to spoof the actual sensor reading of FIT101 while the subsequent motorised valve, MV101, was closed. This attack deceived the control room operator as if there was water leakage or pipe burst. 4.2.7 Control of analyser indication transmitter (AIT) Objective Manipulate the conductivity value of AIT201 (refer to Figure 15) Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers executed the pycomm script to spoof the conductivity sensor, AIT201, reading without actually changing any chemical dosage to the water. a) Check the current AIT201 value b) Set AIT201 simulation mode to TRUE c) Set AIT201 simulation value to 45 Figure 15: Screenshot of an attacker’s script UNRESTRICTED 24 4.2.8 Control of analyser indication transmitter (AIT) Objective Manipulate the pH value of AIT202 Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers executed the pycomm script to spoof the pH sensor, AIT202, reading without actually changing any chemical dosage to the water. 4.2.9 Control of differential pressure indication transmitter (DPIT) Objective To manipulate the value of DPIT301 Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers executed the pycomm script to spoof the differential pressure indication transmitter, DPIT301, reading without actually manipulating any pressure before and after the ultra-filtration system. 4.3 Team JYVSECTEC (Finland) 4.3.1 Access to SWaT SCADA HMI Workstation Objective Gain access to SCADA HMI while locking out legitimate users Attack Method Exploited the workstation through host operation system vulnerability Tools Metasploit framework Description The attackers identified the workstation IP address through their enumeration and exploited the Windows 7 operating system vulnerability, EternalBlue. With the meterpreter session, they exfiltrated files from the workstation and changed the administrator credential concurrently using Windows “net user” command. Subsequently, the attacker login to the workstation using Windows RDP and the previously changed administrative password. 4.3.2 Control the state of the pumps UNRESTRICTED 25 Objective Turned off P101 and P102 for 3 seconds (refer to Figure 28) Attack Method Direct control of PLC using Python script Tools Pylogic and Direct control via SCADA HMI Description The attackers attempted to turn off pumps P101 and P102 by setting “0” value to HMI_P101_Cmd and HMI_P102_Cmd. However, due to wrong value used, the pumps remained operational. Figure 16: Screenshot of script used to stop pump P101 4.3.3 Control SWaT operation using SCADA HMI Workstation Objective Demonstrate the attackers’ ability to use the SCADA HMI to control various sensors and actuators disrupting the water treatment process (refer to Figure 29) Attack Method Direct control via SCADA HMI Tools SCADA Graphical User Interface (GUI) Description 2 Demonstrations - (a) Turned on motorised valve MV101, which causes the raw water tank T101 to be refilled continuously. (2) Set the alarm set points, Low and Low-Low, of level indication transmitter LIT101 to “0” while turning on pumps P101 and P102 to drain the Raw Water Tank (T101). UNRESTRICTED 26 Figure 17: Screenshot of LIT-101 LO and LoLo Alarm Setpoints reset to 0mm 4.3.4 Control the water level of the raw water tank (T101) Objective Control the inflow of water to the raw water tank T101 Attack Method Direct control of PLC using Python script Tools Pycomm Description Closed the motorised valve MV101 using Python script. This valve directly controls the water inflow to the Raw Water Tank (T101). 4.3.5 Manipulation of wireless access point (AP) Objective To disrupt the wireless connection of SWaT (refer to Figures 30 and 31) Attack Method N.A. Tools MOXA software Description The attackers identified the MOXA service through wired connection and enumeration and were able to login using default credential. By disabling the wireless function of MOXA, the attackers were able to disconnect all wireless devices that were connected to it. Therefore, all connected devices lost its connection. UNRESTRICTED 27 Additionally, attackers proposed to change password, settings and inject commands using the field in the “ping” section to execute other attacks. Figure 18: Screenshot of Disabling Wireless Access Point in MOXA Figure 19: Screenshot of Command Injection in the Ping Input 4.3.6 Damage the Reverse Osmosis (RO) membrane Objective Damage the RO membrane using chlorine (refer to Figure 32) UNRESTRICTED 28 Attack Method Direct control via SWaT SCADA workstation Tools SCADA HMI Description The attacker attempted to disrupt Ultraviolet (UV) actuator meant for removing free chlorine residue in the water. Prolonged exposure of free chlorine in the water damages the RO membrane. Attackers disabled the UV light by triggering the setpoint alarms of flow indication transmitter (FIT401) and UV401. They changed the Low and Low-Low setpoints of UV401 to 1.5 and 1.4, and the Low and Low-Low setpoints of FIT401 to 1.8 and 1.5 respectively. Once the alarms were raised for six seconds, PLC shut down UV401 automatically. Without removing free chlorine, RO membrane became eroded gradually. Figure 20: Screenshot of FIT-401’s Alarm Set Points being altered 4.3.7 Shutdown SWaT treatment process Objective Shut-down all the PLC in SWaT Attack Method Direct control via SWaT SCADA HMI Tools SCADA HMI UNRESTRICTED 29 Description 4.4 Attackers terminated the water treatment process by shutting down all the PLC using SWaT SCADA graphical user interface (GUI) Team CTF.SG (Singapore) 4.4.1 Control of the pumps Objective Turned off pumps P401 and P101 (refer to Figure 33) Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers identified all the PLC IP addresses through their enumeration and executed a Python script to turn off pumps P401 and subsequently P101. Figure 21: Screenshot of an attacker’s script 4.4.2 Control of the Level Indication Transmitter (LIT) Objective Changed the alarm setpoint of LIT101 Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers executed a Python script to change the “High” setpoint from 800 to 876 for level indication transmitter LIT101. 4.4.3 Alternating state of the pump UNRESTRICTED 30 Objective Alternating state of pump P301 to cause pump damage (refer to Figure 34) Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers executed a Python script alternating the state of pump P301 (“Open” and “Closed”) using a “for loop” command with the intention to trip the power circuit breaker and damage the pump. Figure 22: Screenshot of an attacker’s script 4.4.4 Attack the pump and spoof the Flow Indication Transmitter (FIT) value Objective Turn off pump P101 and spoof FIT201 value to zero on SCADA HMI Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers executed a Python script to turn off pump P101 and set the value of FIT201 to zero deceiving SCADA operator through SCADA workstation display. UNRESTRICTED 31 4.5 Team NSHC (South Korea) 4.5.1 Manipulation of SWaT wireless access point (AP) Objective To disrupt SWaT wireless operation (refer to Figures 35 and 36) Attack Method Not applicable Tools MOXA software Description The attackers identified MOXA device through reconnaissance and access it using default credential. In the GUI, attackers changed the WIFI password of the SSID “PCN_AP” and injected command, “halt”, in the “ping” CLI field to terminate services in the device. Figure 23: Screenshot of Password Changing in MOXA Figure 24: Screenshot of Commands being used in “Ping” session UNRESTRICTED 32 4.5.2 Control of the Differential Pressure Indication Transmitter (DPIT) Objective Manipulate the value of DPIT301 Attack Method Direct control of PLC using Python script Tools Pylogic Description The attackers executed the Python script to spoof the DPIT301 reading to be “14.01.” Figure 25: Screenshot of an attacker’s script 4.5.3 Control of SWaT SCADA HMI Workstation Objective Obtained a reverse shell from a Windows 7 host Attack Method Exploited the host using Metasploit framework Tools Metasploit Description The attackers identified the IP address of the Windows 7 host through reconnaissance and exploited it using RCE vulnerability (exploit windows/rdp/cve_2019_0708_bluekeep_rce). After successful exploitation, attackers obtained a Windows command shell from the host. UNRESTRICTED 33 Figure 26: Screenshot of Metasploit session 4.6 Institute of Higher Learning (IHL) Student Team (Singapore) 4.6.1 Control of Level Indication Transmitter (LIT) Objective Control of LIT101 value (refer to Figures 39 and 40) Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers identified all the PLCs IP addresses through their enumeration and executed a Python script changing the value of level indication transmitter LIT101 to 800. UNRESTRICTED 34 Figure 28: Screenshot of results Figure 27: Screenshot of the Attacker’s script 4.6.2 Control of Motorised Valve (MV) Objective Control of MV101 status (refer to Figure 41 and 42) Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers identified all the PLCs IP addresses through their enumeration and executed a Python script changing the motorised valve MV101 from “Closed” to “Open.” UNRESTRICTED 35 Figure 30: Screenshot of results Figure 29: Screenshot of an attacker’s script 4.7 Team Crimson Crusaders; ST Engineering (Singapore) 4.7.1 Control of the SWaT SCADA HMI Objective Control of SWaT SCADA HMI (refer to Figures 43 and 44) Attack Method Exploited the host using Metasploit framework Tools Metasploit Description The attackers identified the SCADA IP address through their enumeration and exploited the Windows 7 vulnerability, EternalBlue. With the meterpreter session, they exfiltrated files, using “download” command, from the SCADA workstation and added a new privilege user account (“net user username password /ADD”) through its previously obtained Windows “shell” session. Subsequently, the attackers gained access to the SCADA through Windows RDP using its newly created account. Then, it changed the existing SCADA Administrator’s password using Windows “Change Password” function to prevent authentic users from logging in. UNRESTRICTED 36 Figure 31: Screenshot of File Exfiltration Figure 32: Screenshot of Password Changed 4.7.2 Control of the chemical dosing pump Objective Control of chemical pump P205 status (refer to Figure 45) UNRESTRICTED 37 Attack Method Direct control of PLC using Python script Tools Pycomm Description The attackers found an attack script from the exfiltrated files and executed the Python script with the intention to shut down the chemical (sodium hypochlorite) dosing pump P205. This attack was not successful. Figure 33: Screenshot of an attacker’s script 4.8 Team REDTEAM.PL (Poland) 4.8.1 Shut down SWaT Objective Shut down SWaT (refer to Figures 46 and 47) Attack Method Altering pcap from SWaT Touch Panel to the PLC Tools OWASP ZAP Description The attackers used ZAP (web application security scanner) to scan the webpages of the SWaT Touch Panel and discovered one potential vulnerability of “WriteAuth=Deny” option. They forced this option to UNRESTRICTED 38 become “WriteAuth=Allow”, providing “write” access, and used Touch Panel GUI to shut down SWaT. Figure 34: Screenshot of an Actual Packet Figure 35: Screenshot of an Altered Packet 4.8.2 Control of SWaT SCADA HMI Objective Control of SWaT SCADA HMI Attack Method Exploited the host using Metasploit framework Tools Metasploit Description The attackers identified the SCADA HMI IP address through their enumeration and exploited the Windows 7 vulnerability, EternalBlue. With the meterpreter session, they exfiltrated files from the workstation and changed the Administrator password. The attackers re-gained access to the SCADA using Windows RDP and the new password and was able to control SWaT using SCADA GUI. 4.8.3 Control of motorised valve (MV) Objective Control of Motorised Valve (refer to Figure 48) Attack Method Direct control of MV101 through SCADA HMI Tools Not applicable Description With the access of SCADA HMI, attacker changed the operational mode of the motorised valve MV101 to “Manual” and set it to “Close.” UNRESTRICTED 39 Figure 36: Screenshot of SCADA HMI 4.9 Team DiffEY Hillman; Ernst and Young (Singapore) 4.9.1 Malfunction of PLC 1 Objective Disrupt the raw water process in PLC 1 Attack Method Downloaded the malfunction code to the PLC 1 using RSLogix 5000 Tools VNC viewer and RSLogix 5000 Description After gaining access to the SCADA workstation using VNC, the attackers executed RSLogix500 proprietary software of Allen Bradley and made changes to the structured text of the PLC 3 codes. They downloaded the malfunction codes from Engineering workstation (EWS) to PLC 1 and caused pump P101 to close and motorised valve MV101 to open. This attack caused an overflow on the raw water tank T101. UNRESTRICTED 40 Figure 37: Screenshot of an attacker’s script UNRESTRICTED 41 4.10 Team Crackers (Singapore) 4.10.1 Control of the soft-PLC Objective Control of soft-PLC Attack Method Direct control over soft-PLC through http protocol Tools Not applicable Description The attackers identified the soft-PLC from their enumeration and was able to log in using default password and http protocol. With access to the soft-PLC, the attackers stopped the special water process setup. 5. Description of Defence Teams 5.1 iTrust Anomaly Detection Mechanisms (ADMs) 5.1.1 Distributed Attack Detection (DAD) Background Distributed Attack Detection (DAD) is an attack detection system developed in-house by a team of researchers in iTrust. DAD is a product in development with its patent filed. Through the course of its development, DAD was iteratively improved through extensive experimentation in SWaT. Technology Description DAD can be considered as a host-based intrusion detection system (HIDS). Specifically, it collects data on the various sensor measurements of processes such as water pH, water level and flow indicator of the plant, for analysis and process anomaly detection. By using measurements from 52 sensors in SWaT, it can detect single-stage multipoint and multi-stage multi-point cyber-attacks in a distributed control system. DAD is novel because it uses “security by design” for many basic and advanced attacker models. Based on the laws of physics, it directly verifies the interactions among process variables of the plant within the distributed PLCs to check for abnormal behaviour. Process variables are time-dependent and interrelated within the entire plant process. Hence, their values are constrained by the relationship they have with the other process variables, as governed by the fundamental laws of physics and/or chemistry. The relationships among UNRESTRICTED 42 these constrained variables lead to process invariants and forms the backbone of DAD’s rulebased algorithms. The invariants are embedded in the PLCs as well as special hardware devices known as intelligent checkers (ICs) with wired interfaces to sensors and actuators. The invariants are checked constantly to ensure the underlying processes are behaving as intended. Violation of an invariant is indicative of divergence of the process from its internal behaviour Figure 53 below shows an instance of the DAD’s interface for which an alarm for invariant P1_SD5 was triggered as it was detected as being violated. In this example, the physical rule that is violated is part of the encoded control logic in SWaT, whereby the Raw Water pumps P101 and P102 should be turned on when the Ultrafiltration Feed Water Tank Level (LIT301) downstream is low. Figure 38: DAD Alarm Screenshot 5.1.2 HybMonitor Background HybMonitor is a detection method based on a novel modelling framework. It uses the model of the system under analysis to predict future behaviours. It can detect behaviours that diverge from the expected. Technology Description UNRESTRICTED 43 HybMonitor tool is a black-box modelling approach to detect cyber-attacks in Cyber-Physical systems. It relies on two different tools: HybModeller and HybMonitor. HybModeller uses historical data (data from historian) and creates a model of the normal behaviour of the system. The second component (HybMonitor) uses system’s models and predicts ‘normal’ behaviour of the system under test. It reads the actual state of the system, identifies the operational mode and predicts sensor readings. HybMonitor can predict state transitions in a controller based on prior knowledge. 5.1.3 AI Crit Background AICrit’s intelligence integrates the design knowledge and machine learning algorithms into one versatile solution for automated process monitoring and threat detection in the operational Industrial Control Systems (ICS). Technology Description AICrit for anomaly detection in ICS is a unified framework for real-time process monitoring with a goal to preserve the control behaviour integrity of the ICS. It precisely learns the normal spatio-temporal relationship among the set of highly correlated components through the application of machine learning algorithms (data-centric approach) and with a considerable amount of design knowledge (design-centric approach). The process involved in the design of the unsupervised detector presented here is of two-folds. One is modelling the normal behaviour of continuous-valued state variables (sensors) through the temporal dependencies to forecast their behaviour with minimal error. Second is modelling the higher-order and nonlinear correlation among the discrete and continuous type state variables (cross-correlation among the sensors and actuators) during the normal plant operation. By combining these two, the functional dependencies of the sensors and actuators are monitored continuously, which increases the confidence in discovering and reporting a wide range of anomalies during the discrepancies in the expected and actual behaviour of ICS. 5.1.4 AEGIS Background Automatic Extensible Generic Invariant-based Security (AEGIS) is an attack detection tool that intends to augment the usability of DAD by automating the process of invariant creation. It UNRESTRICTED 44 comprises an algorithm designed to be generic and universal for various types of CPS, offering the option of plant-specific customisation for users. Technology Description The first step in the automation using AEGIS’ algorithm hinges on the idea of reading the connections between the components of the plant from its CAD (Computer-aided Design) file or P&ID (Piping and Instrumentation Diagram). Based on encoded physics principles, the algorithm then automatically generates the rules that the associated sensor-actuator sets must follow for the proper operation of the system. These rules, called invariants, are created using similar logic as followed by DAD. When the tool is in operation, it keeps checking the incoming sensor and actuator readings to determine whether the actual system behaviour is in accordance with its expected performance. The violation of the invariants could be a sign of the presence of process anomalies, which could be occurring due to attacks. The tool is modular in its architecture and allows plant operators to tune the generalised design parameters and device-specific constants to tailor the detector for their particular systems. 5.1.5 Attester Background The attestation tool is a mechanism, which specifically addresses the problem of attesting the integrity of the PLC code. The attestation techniques typically can be categorized into three types-software-based attestations, hardware-based attestation, and physical attestation. Since SWaT does not provide the hardware for hardware-based attestation, and access to the firmware, a practical remote attestation solution is used where mechanism only requires all sensor readings, actuator states, and variables concerning PLC state as input. Technology Description Firstly, the faithful offline copies of its PLC programs are written in python. This code will generate the corresponding actuator commands for the given sensor readings, actuator UNRESTRICTED 45 states, and variables. Based on the inputs from the real system, Attester tool can predict the state of the actuators. Then, the prediction states and the state in the future are checked and will raise alarm(s) if these two values are not consistent. 5.2 Commercial Products Five commercial vendors, referred to as External Blue Teams (EBTs) 1, 2, 3, 4 and 5 participated in CISS as Blue Teams. Their identities are not revealed in this report. 6. Evaluation of Defence Mechanisms The defence mechanisms were evaluated based on the total OT anomalies detected on the SWaT system at a particular Red Team session. IT anomalies were not considered as part of the evaluation. During the event, Blue Teams sent alarms live to the Alert logger when their defence mechanisms detected an anomaly. These alarms were then evaluated for True positive (TP) implying that the alarm is correct, False Positive (FP) when there is an alarm but no anomaly and False Negative (FN) for unable to detect an anomaly. Each detector was scored accordingly to the red team sessions. The nomenclature for each red team session is DATE|SLOT. For example, Aug3AM would represent a session on the morning of the 3rd of August. The 5 iTrust detectors were evaluated using the Aug3AM and Aug6AM session. These sessions were carried out by iTrust red team and contained numerous OT anomalies and attacks. 6.1 OT anomalies For Aug3AM there were a total of 26 Anomalies; for Aug6AM there were 6. These anomalies are listed in Table 2 below. Table 2: Anomalies occurred on Aug3AM No. 1 2, 11, 17 3 4 Anomaly Anomaly in raw water inlet value and raw water outlet flow meter Anomaly in ultra-filtration stage Anomaly in NaHSo3 dosing pump Anomaly in raw water motorised valve Explanation Value of FIT101 was changed from 0 to 1.5 and MV101 from 1 to 2 Values of stage 3 was changed Value of P403 changed from 1 to 2; P401 and P501 started together; UV401 was OFF Value of MV101 was changed from 1->0>2->0->1->0->2->0->1->0-2>0->1. UNRESTRICTED 46 5 Anomaly in speed of variable speed pump Anomaly in ultraviolet dechlorinator Anomaly in UF feed water level meter Anomaly in HCl concentration 6 7 8 9 10 12 13, 26 14 15, 21 16 18 19 20 22, 25 23 24 Value of VSD pump was changed Value of FIT401 was changed to 0.49 Value of LIT301 was changed to 780 Anomaly in RO permeate pressure Anomaly in chemical dosing pH meter Anomaly in RO feed ORP meter Anomaly in de-chlorination stage Anomaly in ultra- filtration Anomaly in reverse osmosis stage Anomaly in UF backwash valve Anomaly in pre-treatment stage Anomaly in pre-treatment stage Anomaly in dechlorination stage and valves of ultra- filtration stage Anomaly in raw water level meter Anomaly in RO feed water level meter Anomaly in RO feed water level meter and UF feed water level meter Value of P203 and P204 are changed to turn ON Value of PIT503 was changed Value of AIT202 value was changed Value of AIT402 was changed Values of stage 4 was changed Value of LIT301 was changed; P101 was ON but LIT301 was not increasing. Values of stage 5 was changed Value of FIT301 behaving abnormally All value of stage 2 pumps are 2 Value of stage 2 pumps are reversed Error in Stage 3 Valves; Values of stage 4 was changed Value of LIT101 was changed to 608 Value of LIT301 was incorrect LIT301 and LIT401 sensors are swapped Table 3: Anomalies occurred in Aug6AM No. 1, 2 3 Anomaly Anomaly in ultra-filtration stage Anomaly in raw water stage 4 Anomaly in level meter 5 6 Anomaly in UF feed water level meter Anomaly in RO feed water level meter and UF feed water level meter UNRESTRICTED 47 Explanation Values of stage 3 changed P101/P102 is not running when LIT301 is low Value of LIT101, LIT301, LIT401 was changed Value of LIT301 was changed Value of LIT301 & LIT401 was changed 7. Summary of Results 7.1 iTrust ADMs Table 4 shows the anomalies detected by each iTrust detector. A cell marked “X” indicates that the anomaly was detected. Tables 5 and 6 detail the performances of iTrust ADMs (anomalies detected, number of alarms generated, and the number of true positives (TP), false positives (FP) and false negatives (FN)), in numbers and percentages, respectively. The rate of TP and FP are in relation to total alarms generated and the rate of FN is in relation to the total number of anomalies. Table 4: Detection of anomalies by iTrust ADMs Anomaly S/N* DAD 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 X X X 1 X X X AEGIS AICrit Aug3AM X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X Aug6AM X UNRESTRICTED 48 Attester X X X X x X X X X X X X X HybMon X X X X X X X X X X X X X X X X 2 3 4 5 6 X X X X X X X X X X X X X *Anomaly S/N: please refer to Table 2 X X X X X X Table 5: Performance of iTrust ADMs, number Session Detector Aug 3AM Aug 6AM Total # Anomalies Total # Alarms TP FP FN Total # Anomalies Total # Alarms TP FP FN AEGIS 26 7450 958 6483 12 6 998 137 861 0 AICrit 26 15812 1998 13814 12 6 1990 38 1952 0 DAD 26 761 761 0 9 6 130 130 0 2 HybMon 26 2513 0 2513 25 6 563 23 540 2 Attester 26 168 83 85 7 6 1821 131 1690 4 Table 6: Performance of iTrust ADM, % Session Detector Aug 3AM Aug 6AM TP FP FN TP FP FN AEGIS 12.86% 87.02% 46.15% 13.73% 86.27% 0.00 % AICrit 12.64% 87.36% 46.15% 1.91% 98.09% 0.00 % DAD 100.00% 0.00% 34.62% 100.00% 0.00% 33.33% HybMon 0.00% 100.00% 96.15% 4.09% 95.91% 33.33% Attester 49.40% 50.60% 7.19% 92.81% 66.67% 26.92% UNRESTRICTED 49 7.2 EBTs ADMs Table 7 shows the anomalies detected by each EBTs’ detector. A cell marked “X” indicates that the anomaly was detected. Tables 8 and 9 detail the performances of EBTs’ ADMs (anomalies detected, number of alarms generated, and the number of true positives (TP), false positives (FP) and false negatives (FN)), in numbers and percentages, respectively. The rate of TP and FP are in relation to total alarms generated and the rate of FN is in relation to the total number of anomalies. Table 7: Detection of anomalies by EBTs Anomaly S/N* 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 1 2 3 4 EBT01 EBT02 EBT03 AUG3AM X X X 1 X X X X X X X X X X X X X X X X X X X X X X Aug3AM X X X X UNRESTRICTED 50 EBT04 EBT05 X X X X X X X X X X X X X X X X X X X X X X X X X 5 6 X *Anomaly S/N: please refer to Table 2 Table 8: Performance of EBTs ADMs, number Session Aug 3AM Detector Aug 6AM Total Anomaly Total Alarms Total OT Alarms TP FP FN Total Anomaly Total Alarms Total OT Alarms TP FP FN EBT01 26 0 0 0 0 26 6 0 0 0 0 6 EBT02 26 1506 529 193 336 5 6 616 16 16 0 1 EBT03 26 3773 3655 720 2935 16 6 57 53 9 44 2 EBT04 26 98 96 76 18 16 6 16 10 3 7 3 EBT05 26 17 17 10 7 23 6 2 2 2 0 4 Table 9: Performance of EBTs ADMs, % Session Detector Aug 3AM Aug 6AM TP FP FN TP FP FN EBT01 0.00% 0.00% 100.00% 0.00% 0.00% 100.00% EBT02 36.48% 63.52% 19.23% 100.00% 0.00% 16.67% EBT03 19.70% 80.30% 61.54% 16.98% 83.02% 33.33% EBT04 79.17% 18.75% 61.54% 30.00% 70.00% 50.00% EBT05 58.82% 41.18% 88.46% 100.00% 0.00% 66.67% UNRESTRICTED 51 7.3 Outcomes 7.3.1 Aug3AM session Across all iTrust ADMs, Attester detected the most number of anomalies (19 out of 26) followed by DAD (17 out of 26.) However, it must be noted that DAD has a FP rate of 0% compared to Attester’s FP rate (50.6%.) Hybmon failed to detect any anomalies resulting in all alarms raised as FP. AICrit and AEGIS raised huge number of alarms (7,450 and 15,812 respectively); however, only about 12.5% of the alarms for (each of the detector) turned out to be true positives. Out of the total 26 anomalies discovered, AICrit and AEGIS detected 14 anomalies during this session. Across all EBTs ADMs, EBT02 detected the most number of anomalies at 21 out of 26, followed by EBT03 and EBT04 (both with 10 out of 26.) Between EBT03 and EBT04, EBT04 fared better as it had a higher TP rate and a lower FP rate. 7.3.2 Aug6AM session Across all iTrust ADMs, DAD performed the best as it had the highest percentage of TP at 100.00% with no FP. However, DAD failed to detect 2 of the 6 anomalies. AICrit and AEGIS detected all 6 anomalies but reported a significant number of false positive. HybMon managed to detect 4 out of 6 anomalies and Attester detected 2 out of 6 anomalies. Across all EBTs, both EBT02 and EBT05 had a TP rate of 100%. However, EBT05 has a higher FN rate compared to EBT02. EBT02 has the most anomalies detected (5 out of 6), followed by EBT03 (4 out of 6) and EBT04 (3 out of 6.) 7.4 Improved iTrust ADMs iTrust blue teams were given the opportunity to update their ADMs to improve their algorithm after the event. The improved ADMs can then be used to re-evaluated against the event’s dataset. The evaluations were done by the developer. Below shows the updated evaluation for AICrit. Table 10: Updated evaluation for improved AICrit Session Detector AICrit Aug 3AM Aug 6AM Total # Anomalies Total # Alarms TP FP FN Total # Anomalies Total # Alarms TP FP FN 26 2118 1998 108 12 6 52 38 14 0 UNRESTRICTED 52 8. Conclusion This year, CISS was held online and invited more participants than in the past from various countries from different backgrounds. A total of thirteen Red Teams and six Blue Teams (five commercial products and an iTrust Blue Team featuring five ADMs) took part in this event. The Red Teams had a unique opportunity to attack a realistic process plant to cause process anomalies. The attacks allowed us to understand composite Tactics, Techniques and Procedures (TTPs) that can be used for enhanced Operation Security (OpSec). The attacks were scored based on target selection, mode of entry, attack target, attack success and detection. The Blue Teams showcased their ability to detect such sophisticated attacks and by using CISS as a platform to validate and assess the effectiveness of their technologies. Blue teams sent live alarms to the alert logging system. These logs were then analysed by internal iTrust team after the event and scored based on detection of process anomalies in terms of TP, FP and FN. Importantly, CISS has developed capabilities for defending critical infrastructure under emergency such as cyber-attacks which is crucial for safeguarding our interests. 9. Acknowledgements iTrust sincerely thanks the numerous members of red and blue teams who found time to participate in the first ever international on-line cyber-security exercise focused on exclusively on physical critical infrastructure. Thanks also to the judges who found time to judge this gruelling event. 10. Nomenclature Alert Logger: Automates the process of logging and sending time-stamped alerts by blue teams to iTrust Attack Launcher: Optional platform for red teams to select and launch attacks Attack Logger: Communicate attack intentions and steps to White Team and judges, and log attacks as they occur PEPPR: Collection of tools (PlantPlayer (PP), PlantViz (PV) and PlantIO (PI)) that allows playback of historical data to enable blue teams to test their own detection systems PEPPR-PP: Tool to playback past historical data UNRESTRICTED 53 PEPPR-PV: Visualisation tool for live, prediction, and anomaly data from detectors. PEPPR-PI: A suite of tools that allows detectors to save, publish and playback live, the predicted plant state and alerts. The data which is saved or published can be used by other tools on the same network.