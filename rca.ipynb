{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77dc7b1",
   "metadata": {},
   "source": [
    "# Llama-3.1-8B (128,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7362755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mskim2/llm_rca/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mskim2/llm_rca/myenv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:898: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/mskim2/llm_rca/myenv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.74s/it]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import sqlite3\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "with open(\"token.txt\", \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", use_auth_token=token)\n",
    "llm_pipeline = pipeline(\"text-generation\", \n",
    "                    model=model, \n",
    "                    tokenizer=tokenizer, \n",
    "                    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "                    device_map=\"auto\",\n",
    "                    return_full_text=False,\n",
    "                    temperature=0.1,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2790269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# import sqlite3\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.llms import HuggingFacePipeline\n",
    "# from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./saved_model\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"./saved_model\")\n",
    "\n",
    "# llm_pipeline = pipeline(\"text-generation\", \n",
    "#                     model=model, \n",
    "#                     tokenizer=tokenizer, \n",
    "#                     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#                     device_map=\"auto\",\n",
    "#                     return_full_text=False,\n",
    "#                     temperature=0.1,\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e75f7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GNN 결과 로드\n",
    "test_result = pd.read_csv(\"/home/mskim2/GDN/csv/swat/test_result.csv\")\n",
    "attention = pd.read_csv(\"/home/mskim2/GDN/csv/swat/attention_result.csv\")\n",
    "anomaly_score = pd.read_csv(\"/home/mskim2/GDN/csv/swat/anomaly_score.csv\")\n",
    "raw_df = pd.read_csv(\"/home/mskim2/GDN/data/swat/test.csv\")\n",
    "\n",
    "feature_file = open(f'/home/mskim2/GDN/data/swat/list.txt', 'r')\n",
    "feature_list = []\n",
    "for ft in feature_file:\n",
    "    feature_list.append(ft.strip())\n",
    "\n",
    "attack_point = pd.read_csv(\"/home/mskim2/GDN/attack_point.csv\")\n",
    "attack_point = attack_point.iloc[5:, -1].tolist()\n",
    "test_result['attack_point'] = attack_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f3b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. true positive 시점 필터링\n",
    "tp_df = test_result[(test_result[\"ground truth label\"] == 1.0) & (test_result[\"model prediction\"] == 1.0)& (pd.notna(test_result[\"attack_point\"]))]\n",
    "tp_df = tp_df.drop(tp_df.index[68])\n",
    "\n",
    "# 4-1. DB 연결 (SQLite / CSV 예시)\n",
    "conn = sqlite3.connect(\"sensor_data.db\")\n",
    "def get_raw_sensor_data(sensor: str, time_idx: int, window: int = 10) -> str:\n",
    "    query = f\"\"\"\n",
    "        SELECT timestamp, value\n",
    "        FROM raw_data\n",
    "        WHERE sensor_id = '{sensor}'\n",
    "        AND time_index BETWEEN {time_idx - window} AND {time_idx + window}\n",
    "        ORDER BY time_index\n",
    "    \"\"\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    return result.to_string(index=False)\n",
    "\n",
    "def get_sensor_data_block(raw_df: pd.DataFrame, sensor: list, time_idx: int, window: int = 10) -> str:\n",
    "    start = max(0, time_idx - window)\n",
    "    end = min(len(raw_df), time_idx + window + 1)\n",
    "    block = raw_df.loc[start:end, sensor]\n",
    "    lines = [f\"{val}\" for idx, val in block.items()]\n",
    "    return \", \".join(lines)\n",
    "\n",
    "def get_attention_data_block(df, sensor, time_idx, window):\n",
    "    topk = 15\n",
    "    node_num = 51\n",
    "    block = df.loc[(time_idx)*node_num*topk:(time_idx+1)*node_num*topk, :].squeeze()\n",
    "    sensor_graph = {}\n",
    "    for _, row in block.iterrows():\n",
    "        source = row['source']\n",
    "        target = row['target']\n",
    "        attn = row['attention']\n",
    "\n",
    "        if source not in sensor_graph:\n",
    "            sensor_graph[source] = {}\n",
    "        \n",
    "        sensor_graph[source][target] = attn\n",
    "\n",
    "    return sensor_graph\n",
    "\n",
    "# 5. 도메인 매뉴얼 불러오기\n",
    "with open(\"./manual.txt\", \"r\") as f:\n",
    "    manual_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd6741f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Index:  1538\n",
      "Top 3 Sensors:  ['FIT401', 'MV301', 'FIT501']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause: FIT-401 ---\n",
      "\n",
      "--- Root Cause Analysis for time 1538 ---\n",
      "{\n",
      "  \"root_causes\": [\n",
      "    {\"cause\": \"Possible malfunction of the UV dechlorination process (UV401) due to an unexpected drop in its operational status.\", \"evidence\": [\"UV401\"], \"confidence\": 0.8},\n",
      "    {\"cause\": \"Possible issue with the reverse osmosis system (P501) due to an unexpected drop in its operational status.\", \"evidence\": [\"P501\"], \"confidence\": 0.7},\n",
      "    {\"cause\": \"Possible malfunction of the FIT401 sensor due to an unexpected drop in its reading.\", \"evidence\": [\"FIT401\"], \"confidence\": 0.6}\n",
      "  ],\n",
      "  \"supporting_detail\": \"The anomaly is likely caused by a malfunction in one of the critical components of the water treatment system. The UV dechlorination process (UV401) and the reverse osmosis system (P501) are both critical components that play a crucial role in the water treatment process. The unexpected drop in their operational status suggests that there may be a malfunction in these components. Additionally, the FIT401 sensor is also showing an unexpected drop in its reading, which could be a contributing factor to the anomaly. Further investigation is required to determine the root cause of the anomaly and to take corrective action.\"\n",
      "}\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@ ['UV-401', 'P-501', 'FIT-401'] FIT-401 @@@@@@@@@@@@@@@@@@@@@@\n",
      "Time Index:  11614\n",
      "Top 3 Sensors:  ['AIT504', 'FIT501', 'FIT401']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause: AIT-504 ---\n",
      "\n",
      "--- Root Cause Analysis for time 11614 ---\n",
      "{\n",
      "  \"root_causes\": [\n",
      "    {\"cause\": \"High conductivity in the water treatment process\", \"evidence\": [\"AIT504\"], \"confidence\": 0.9},\n",
      "    {\"cause\": \"Abnormal flow rate in the ultrafiltration stage\", \"evidence\": [\"FIT401\"], \"confidence\": 0.8},\n",
      "    {\"cause\": \"Unusual pressure reading after the reverse osmosis membrane\", \"evidence\": [\"PIT503\"], \"confidence\": 0.7}\n",
      "  ],\n",
      "  \"supporting_detail\": \"The high conductivity reading from AIT504 sensor suggests a potential issue with the water treatment process. The abnormal flow rate in the ultrafiltration stage, as indicated by FIT401 sensor, may be related to the high conductivity reading. The unusual pressure reading after the reverse osmosis membrane, as indicated by PIT503 sensor, may also be related to the issue. The attention weights suggest a strong correlation between AIT504 and FIT401 sensors, indicating that the high conductivity reading may be causing the abnormal flow rate. The attention weights also suggest a moderate correlation between AIT504 and PIT503 sensors, indicating that the high conductivity reading may be related to the unusual pressure reading.\"\n",
      "}\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@ ['AIT-504', 'FIT-401', 'PIT-503'] AIT-504 @@@@@@@@@@@@@@@@@@@@@@\n",
      "Time Index:  13291\n",
      "Top 3 Sensors:  ['FIT501', 'FIT401', 'MV302']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause: AIT-502,P-501,UV-401 ---\n",
      "\n",
      "--- Root Cause Analysis for time 13291 ---\n",
      "{\n",
      "  \"root_causes\": [\n",
      "    {\"cause\": \"Possible clogging or pump failure in the ultrafiltration stage\", \"evidence\": [\"FIT301\", \"MV302\"], \"confidence\": 0.8},\n",
      "    {\"cause\": \"Possible malfunction of the reverse osmosis membrane\", \"evidence\": [\"PIT503\", \"FIT501\"], \"confidence\": 0.7},\n",
      "    {\"cause\": \"Possible issue with the UV dechlorination process\", \"evidence\": [\"UV401\", \"P501\"], \"confidence\": 0.6}\n",
      "  ],\n",
      "  \"supporting_detail\": \"The anomaly is likely caused by a combination of factors, including clogging or pump failure in the ultrafiltration stage, malfunction of the reverse osmosis membrane, and issue with the UV dechlorination process. The evidence from the sensors and attention weights suggests that these factors are highly correlated and likely to be the root cause of the anomaly.\"\n",
      "}\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@ ['FIT-301', 'PIT-503', 'UV-401'] AIT-502,P-501,UV-401 @@@@@@@@@@@@@@@@@@@@@@\n",
      "Time Index:  23171\n",
      "Top 3 Sensors:  ['P502', 'UV401', 'P206']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause: P-302 ---\n",
      "\n",
      "--- Root Cause Analysis for time 23171 ---\n",
      "{\n",
      "  \"root_causes\": [\n",
      "    {\"cause\": \"UV401 malfunction\", \"evidence\": [\"UV401\"], \"confidence\": 0.8},\n",
      "    {\"cause\": \"P502 malfunction\", \"evidence\": [\"P502\"], \"confidence\": 0.7},\n",
      "    {\"cause\": \"P206 malfunction\", \"evidence\": [\"P206\"], \"confidence\": 0.6}\n",
      "  ],\n",
      "  \"supporting_detail\": \"The anomaly is likely caused by a malfunction in one of the UV401, P502, or P206 sensors. The attention weights show a strong correlation between these sensors and other sensors in the system, indicating that they play a crucial role in the system's operation. The raw sensor data also shows abnormal changes in these sensors, which further supports the likelihood of a malfunction. The confidence levels are based on the strength of the evidence and the correlation between the sensors.\"\n",
      "}\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@ ['UV-401', 'P-502', 'P-206'] P-302 @@@@@@@@@@@@@@@@@@@@@@\n",
      "Time Index:  43654\n",
      "Top 3 Sensors:  ['FIT502', 'P502', 'UV401']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause: FIT-502,P-501 ---\n",
      "\n",
      "--- Root Cause Analysis for time 43654 ---\n",
      "{\n",
      "  \"root_causes\": [\n",
      "    {\"cause\": \"UV Disinfection Unit malfunction\", \"evidence\": [\"UV401\"], \"confidence\": 0.8},\n",
      "    {\"cause\": \"Reverse Osmosis (RO) membrane failure\", \"evidence\": [\"PIT503\"], \"confidence\": 0.7},\n",
      "    {\"cause\": \"Pump P501 malfunction\", \"evidence\": [\"P501\"], \"confidence\": 0.6}\n",
      "  ],\n",
      "  \"supporting_detail\": \"The anomaly is likely caused by a malfunction in the UV disinfection unit (UV401), which is indicated by the sudden drop in its output. This could be due to a failure in the UV lamp or a malfunction in the control system. The attention weights also suggest a strong correlation between UV401 and other sensors in the system, such as PIT503, which measures the pressure after the RO membrane. This suggests that the RO membrane may also be affected by the anomaly. Additionally, the pump P501, which is responsible for pumping water through the RO system, shows a sudden drop in its output, indicating a possible malfunction.\"\n",
      "}\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@ ['UV-401', 'PIT-503', 'P-501'] FIT-502,P-501 @@@@@@@@@@@@@@@@@@@@@@\n",
      "Time Index:  43814\n",
      "Top 3 Sensors:  ['P201', 'FIT501', 'FIT401']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause: AIT-502,FIT-401 ---\n",
      "\n",
      "--- Root Cause Analysis for time 43814 ---\n",
      "{\n",
      "  \"root_causes\": [\n",
      "    {\"cause\": \"Chemical dosing pump P201 malfunction\", \"evidence\": [\"P201\"], \"confidence\": 0.8},\n",
      "    {\"cause\": \"Sensor FIT501 malfunction\", \"evidence\": [\"FIT501\"], \"confidence\": 0.7},\n",
      "    {\"cause\": \"Sensor FIT401 malfunction\", \"evidence\": [\"FIT401\"], \"confidence\": 0.6}\n",
      "  ],\n",
      "  \"supporting_detail\": \"The anomaly is likely caused by a malfunction in the chemical dosing pump P201, as indicated by the sudden change in its output. This is supported by the attention weights, which show a strong correlation between P201 and other sensors in the system. Additionally, the raw sensor data shows a sudden change in the output of sensor FIT501, which is also correlated with P201. The malfunction of P201 is likely the root cause of the anomaly, as it affects the chemical dosing process and can lead to changes in the water quality.\"\n",
      "}\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@ ['P-201', 'FIT-501', 'FIT-401'] AIT-502,FIT-401 @@@@@@@@@@@@@@@@@@@@@@\n",
      "Time Index:  43862\n",
      "Top 3 Sensors:  ['P201', 'FIT501', 'MV301']\n",
      "\n",
      "--- Root Cause: FIT-401 ---\n",
      "\n",
      "--- Root Cause Analysis for time 43862 ---\n",
      "{\n",
      "  \"root_causes\": [\n",
      "    {\"cause\": \"Chemical dosing pump P201 malfunction\", \"evidence\": [\"P201\"], \"confidence\": 0.8},\n",
      "    {\"cause\": \"Faulty conductivity sensor AIT201\", \"evidence\": [\"AIT201\"], \"confidence\": 0.7},\n",
      "    {\"cause\": \"Clogged ultrafiltration stage\", \"evidence\": [\"FIT301\"], \"confidence\": 0.6}\n",
      "  ],\n",
      "  \"supporting_detail\": \"The anomaly is likely caused by a malfunction in the chemical dosing pump P201, as indicated by the high attention weights from P201 to other sensors. Additionally, the conductivity sensor AIT201 shows a significant deviation from its normal range, suggesting a potential fault. The ultrafiltration stage FIT301 also shows an abnormal change in flow rate, which could be indicative of a clog.\"\n",
      "}\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@ ['P-201', 'AIT-201', 'FIT-301'] FIT-401 @@@@@@@@@@@@@@@@@@@@@@\n",
      "5 2\n",
      "Accuracy:  0.7142857142857143\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "root = None\n",
    "\n",
    "# 6. 루트 원인 분석 루프\n",
    "slide_win = 5\n",
    "window = 30\n",
    "prev_value = None\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "for _, row in tp_df.iterrows():\n",
    "    current_value = row['attack_point']\n",
    "    if current_value != prev_value:\n",
    "        time_idx = int(row[\"timestamp\"] + slide_win)\n",
    "        print(\"Time Index: \", time_idx)\n",
    "        sensors_scores = [s.strip() for s in row[[\"1\", \"2\", \"3\"]].tolist()]\n",
    "        sensors = [s.split(\":\")[0] for s in sensors_scores]\n",
    "        print(\"Top 3 Sensors: \", sensors)\n",
    "\n",
    "        output_json = {\n",
    "            \"raw_data\": {},\n",
    "            \"anomaly_scores\": {},\n",
    "            \"attention\": {},\n",
    "        }\n",
    "\n",
    "        for sensor in feature_list:\n",
    "            anomaly = get_sensor_data_block(anomaly_score, sensor, time_idx, window=window)\n",
    "            output_json[\"anomaly_scores\"][sensor] = anomaly\n",
    "\n",
    "        for sensor in feature_list:\n",
    "            raw = get_sensor_data_block(raw_df, sensor, time_idx, window=window)\n",
    "            output_json[\"raw_data\"][sensor] = raw\n",
    "\n",
    "        anomaly = get_attention_data_block(attention, sensor, time_idx, window=window)\n",
    "        output_json[\"attention\"] = anomaly\n",
    "\n",
    "        root = row['attack_point']\n",
    "\n",
    "        messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are an expert in root cause analysis for cyber-physical systems, especially industrial water treatment systems. Your task is to identify plausible root causes of detected anomalies. Use domain knowledge and respond concisely and clearly.\n",
    "\n",
    "        TASK:\n",
    "        1. Read the files provided in subsequent messages:\n",
    "        - Sensor Manual: A textual guide containing descriptions of each sensor and actuator, their intended functionality.\n",
    "        - Raw Sensor Data: A dictionary mapping each sensor name to a string containing comma-separated raw data over a time window (±30 time steps from the detected anomaly).\n",
    "        - Attention Weights: A dictionary where each key is a source sensor name, and its value is another dictionary mapping target sensor names to attention values (floats between 0 and 1). The attention values represents the influence or correlation strength from the source sensor to the target sensor as learned by the Graph Neural Network.\n",
    "        2. Return a JSON object with:\n",
    "        {\n",
    "            \"root_causes\": [\n",
    "            {\"cause\": str, \"evidence\": [sensor_id], \"confidence\": 0-1 float}\n",
    "            ],\n",
    "            \"supporting_detail\": str (<=150 tokens)\n",
    "        }\n",
    "        CONSTRAINTS:\n",
    "        - Use only the given data; do not hallucinate unseen equipment.\n",
    "        - Be concise; no markdown, no additional text outside the JSON.\n",
    "        - Identify the most plausible root cause by considering abnormal changes in raw data or attention weights, as well as the inter-sensor relationships and the system’s operational flow.\n",
    "        \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "        Top 3 Sensors (by anomaly score): {', '.join(sensors)}\n",
    "\n",
    "        Sensor Manual:\n",
    "        {manual_text}\n",
    "\n",
    "        Raw Sensor Data (±{window} points around anomaly):\n",
    "        {output_json['raw_data']}\n",
    "\n",
    "        Attention Weights:\n",
    "        {output_json['attention']}\n",
    "\n",
    "        Please analyze and explain the most likely root cause of the anomaly. Respond only with the required JSON output.\"\"\"\n",
    "        }\n",
    "        ]\n",
    "\n",
    "        response = llm_pipeline(messages, max_new_tokens=512)\n",
    "        print(\"\\n--- Root Cause:\", root, '---')\n",
    "        print(f\"\\n--- Root Cause Analysis for time {time_idx} ---\\n{response[0]['generated_text']}\\n\")\n",
    "        parsed = json.loads(response[0]['generated_text'])\n",
    "        \n",
    "        predicted_root_sensors = []\n",
    "        for i in range(len(parsed['root_causes'])):\n",
    "            predicted_root = parsed['root_causes'][i]['evidence'][0]\n",
    "            predicted_root = re.sub(r\"([A-Za-z]+)(\\d+)\", r\"\\1-\\2\", predicted_root)            \n",
    "            predicted_root_sensors.append(predicted_root)\n",
    "\n",
    "        acc = 1 if any(sensor in root for sensor in predicted_root_sensors) else 0\n",
    "\n",
    "        if acc:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "        print(\"@@@@@@@@@@@@@@@@@@@@@@\", predicted_root_sensors, root, \"@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "\n",
    "    prev_value = current_value\n",
    "\n",
    "print(correct, incorrect)\n",
    "print(\"Accuracy: \", correct / (correct + incorrect))\n",
    "print('------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use anomaly scores in the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c4230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "root = None\n",
    "\n",
    "# 6. 루트 원인 분석 루프\n",
    "slide_win = 5\n",
    "window = 30\n",
    "prev_value = None\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "for _, row in tp_df.iterrows():\n",
    "    current_value = row['attack_point']\n",
    "    if current_value != prev_value:\n",
    "        time_idx = int(row[\"timestamp\"] + slide_win)\n",
    "        sensors_scores = [s.strip() for s in row[[\"1\", \"2\", \"3\"]].tolist()]\n",
    "        sensors = [s.split(\":\")[0] for s in sensors_scores]\n",
    "\n",
    "        output_json = {\n",
    "            \"raw_data\": {},\n",
    "            \"anomaly_scores\": {},\n",
    "            \"attention\": {},\n",
    "        }\n",
    "\n",
    "        for sensor in feature_list:\n",
    "            anomaly = get_sensor_data_block(anomaly_score, sensor, time_idx, window=window)\n",
    "            output_json[\"anomaly_scores\"][sensor] = anomaly\n",
    "\n",
    "        for sensor in feature_list:\n",
    "            raw = get_sensor_data_block(raw_df, sensor, time_idx, window=window)\n",
    "            output_json[\"raw_data\"][sensor] = raw\n",
    "\n",
    "        anomaly = get_attention_data_block(attention, sensor, time_idx, window=window)\n",
    "        output_json[\"attention\"] = anomaly\n",
    "\n",
    "        root = row['attack_point']\n",
    "\n",
    "        messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are an expert in root cause analysis for cyber-physical systems, especially industrial water treatment systems. Your task is to identify plausible root causes of detected anomalies. Use domain knowledge and respond concisely and clearly.\n",
    "\n",
    "        TASK:\n",
    "        1. Read the files provided in subsequent messages:\n",
    "        - Sensor Manual: A textual guide containing descriptions of each sensor and actuator, their intended functionality.\n",
    "        - Raw Sensor Data: A dictionary mapping each sensor name to a string containing comma-separated raw data over a time window (±30 time steps from the detected anomaly).\n",
    "        - Anomaly Scores: A dictionary mapping each sensor name to a string containing comma-separated anomaly scores, which is learned by the Graph Neural Network, over a time window (±30 time steps from the detected anomaly).\n",
    "        - Attention Weights: A dictionary where each key is a source sensor name, and its value is another dictionary mapping target sensor names to attention values (floats between 0 and 1). The attention values represents the influence or correlation strength from the source sensor to the target sensor as learned by the Graph Neural Network.\n",
    "        2. Return a JSON object with:\n",
    "        {\n",
    "            \"root_causes\": [\n",
    "            {\"cause\": str, \"evidence\": [sensor_id], \"confidence\": 0-1 float}\n",
    "            ],\n",
    "            \"supporting_detail\": str (<=150 tokens)\n",
    "        }\n",
    "        CONSTRAINTS:\n",
    "        - Use only the given data; do not hallucinate unseen equipment.\n",
    "        - Be concise; no markdown, no additional text outside the JSON.\n",
    "        \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "        Top 3 Sensors (by anomaly score): {', '.join(sensors)}\n",
    "\n",
    "        Sensor Manual:\n",
    "        {manual_text}\n",
    "\n",
    "        Raw Sensor Data (±{window} points around anomaly):\n",
    "        {output_json['raw_data']}\n",
    "\n",
    "        Anomaly Scores (±{window} points around anomaly):\n",
    "        {output_json['anomaly_scores']}\n",
    "\n",
    "        Attention Weights:\n",
    "        {output_json['attention']}\n",
    "\n",
    "        Please analyze and explain the most likely root cause of the anomaly. Respond only with the required JSON output.\"\"\"\n",
    "        }\n",
    "        ]\n",
    "\n",
    "        response = llm_pipeline(messages, max_new_tokens=512)\n",
    "        print(\"\\n--- Root Cause:\", root, '---')\n",
    "        print(f\"\\n--- Root Cause Analysis for time {time_idx} ---\\n{response[0]['generated_text']}\\n\")\n",
    "        parsed = json.loads(response[0]['generated_text'])\n",
    "        predicted_root = parsed['root_causes'][0]['evidence'][0]\n",
    "\n",
    "        acc = predicted_root in root\n",
    "        if acc:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "        print(\"@@@@\", predicted_root, root, \"@@@@\")\n",
    "\n",
    "    prev_value = current_value\n",
    "\n",
    "\n",
    "print(correct, incorrect)\n",
    "print(\"Accuracy: \", correct / (correct + incorrect))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bdf288",
   "metadata": {},
   "source": [
    "# Falcon-7B (2,048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2cedbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]\n",
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_1267002/908972119.py:17: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=text_gen)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "text_gen = pipeline(\"text-generation\", \n",
    "                    model=model, \n",
    "                    tokenizer=tokenizer, \n",
    "                    max_new_tokens=512,\n",
    "                    return_full_text=False,\n",
    "                    )\n",
    "llm = HuggingFacePipeline(pipeline=text_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb6177e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause Analysis for time 1533 ---\n",
      "\n",
      "- Spoofing sensor values (FIT401, AIT201) via simulation mode or HMI tag manipulation to damage RO membrane.\n",
      "- Disabling UV401 via alarm setpoint manipulation to damage RO membrane.\n",
      "- Exploiting SCADA workstation (e.g., EternalBlue) to alter plant operation logic.\n",
      "- Command injection into network devices (e.g., MOXA access points) to disrupt communication.\n",
      "\n",
      "The most likely root cause of the anomaly at time 1533 is spoofing sensor values. This is due to the fact that the anomaly occurred during a time when the sensor values were being manipulated through simulation mode or HMI tag manipulation. The spoofing could be intentional or unintentional, but it is likely that the root cause is related to the manipulation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. GNN 결과 로드\n",
    "df = pd.read_csv(\"/home/mskim2/GDN/csv/swat/test_result.csv\")\n",
    "\n",
    "# 3. true positive 시점 필터링\n",
    "tp_df = df[(df[\"ground truth label\"] == 1.0) & (df[\"model prediction\"] == 1.0)]\n",
    "\n",
    "# 4-1. DB 연결 (SQLite / CSV 예시)\n",
    "conn = sqlite3.connect(\"sensor_data.db\")\n",
    "def get_raw_sensor_data(sensor: str, time_idx: int, window: int = 10) -> str:\n",
    "    query = f\"\"\"\n",
    "        SELECT timestamp, value\n",
    "        FROM raw_data\n",
    "        WHERE sensor_id = '{sensor}'\n",
    "        AND time_index BETWEEN {time_idx - window} AND {time_idx + window}\n",
    "        ORDER BY time_index\n",
    "    \"\"\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    return result.to_string(index=False)\n",
    "\n",
    "def get_sensor_data_block(sensor: list, time_idx: int, window: int = 10) -> str:\n",
    "    raw_df = pd.read_csv(\"/home/mskim2/GDN/data/swat/test.csv\")\n",
    "    start = max(0, time_idx - window)\n",
    "    end = min(len(raw_df), time_idx + window + 1)\n",
    "    block = raw_df.loc[start:end, sensor]\n",
    "    return block.to_string(index=False)\n",
    "\n",
    "# 5. 도메인 매뉴얼 불러오기\n",
    "with open(\"./manual.txt\", \"r\") as f:\n",
    "    manual_text = f.read()\n",
    "\n",
    "# 6. 루트 원인 분석 루프\n",
    "slide_win = 5\n",
    "for _, row in tp_df.iterrows():\n",
    "    time_idx = int(row[\"timestamp\"]+slide_win)\n",
    "    sensors_scores = [s.strip() for s in row[[\"1\", \"2\", \"3\"]].tolist()]\n",
    "    sensors = [s.split(\":\")[0] for s in sensors_scores]\n",
    "\n",
    "    window=20\n",
    "    sensor_data_blocks = []\n",
    "    for sensor in sensors:\n",
    "        raw = get_sensor_data_block(sensor, time_idx, window=window)\n",
    "        sensor_data_blocks.append(f\"Sensor: {sensor}\\n{raw}\")\n",
    "\n",
    "    sensor_data_str = \"\\n\\n\".join(sensor_data_blocks)\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"You are an expert in root cause analysis for cyber-physical systems, especially industrial water treatment systems. Your task is to identify plausible root causes of detected anomalies. Use domain knowledge and respond concisely and clearly.\"),\n",
    "        (\"human\", f\"\"\"Domain Knowledge:\n",
    "{manual_text}\n",
    "\n",
    "Time Point: {time_idx}\n",
    "Top 3 Sensors (by anomaly score): {', '.join(sensors)}\n",
    "\n",
    "Raw Sensor Data (±{window} points around anomaly):\n",
    "{sensor_data_str}\n",
    "\n",
    "Please analyze this and explain the most likely root cause of the anomaly at time {time_idx}. Respond concisely and clearly in bullet points.\"\"\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt_template | llm\n",
    "    response = chain.invoke({})\n",
    "    print(f\"\\n--- Root Cause Analysis for time {time_idx} ---\\n{response}\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60eaca",
   "metadata": {},
   "source": [
    "# DeepSeek-7B (4,096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9e7313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.57s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c2222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause Analysis for time 1533 ---\n",
      "* FIT401 and FIT501 show significant spikes in values, reaching -30 in some cases, which is highly unusual for sensor values.\n",
      "* FIT502 has more normal values but still shows some unusual fluctuations.\n",
      "* The most likely root cause of these anomalies is a physical failure or malfunction of the sensors themselves, leading to incorrect or inconsistent readings.\n",
      "* It is also possible that there is a communication issue between the sensors and the SCADA system, causing data corruption or delay.\n",
      "* It is important to investigate these anomalies further by physically inspecting the sensors, checking their calibration, and verifying their connection to the system.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. GNN 결과 로드\n",
    "df = pd.read_csv(\"/home/mskim2/GDN/csv/swat/test_result.csv\")\n",
    "\n",
    "# 3. true positive 시점 필터링\n",
    "tp_df = df[(df[\"ground truth label\"] == 1.0) & (df[\"model prediction\"] == 1.0)]\n",
    "\n",
    "# 4-1. DB 연결 (SQLite / CSV 예시)\n",
    "conn = sqlite3.connect(\"sensor_data.db\")\n",
    "def get_raw_sensor_data(sensor: str, time_idx: int, window: int = 10) -> str:\n",
    "    query = f\"\"\"\n",
    "        SELECT timestamp, value\n",
    "        FROM raw_data\n",
    "        WHERE sensor_id = '{sensor}'\n",
    "        AND time_index BETWEEN {time_idx - window} AND {time_idx + window}\n",
    "        ORDER BY time_index\n",
    "    \"\"\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    return result.to_string(index=False)\n",
    "\n",
    "def get_sensor_data_block(sensor: list, time_idx: int, window: int = 10) -> str:\n",
    "    raw_df = pd.read_csv(\"/home/mskim2/GDN/data/swat/test.csv\")\n",
    "    start = max(0, time_idx - window)\n",
    "    end = min(len(raw_df), time_idx + window + 1)\n",
    "    block = raw_df.loc[start:end, sensor]\n",
    "    return block.to_string(index=False)\n",
    "\n",
    "# 5. 도메인 매뉴얼 불러오기\n",
    "with open(\"./manual.txt\", \"r\") as f:\n",
    "    manual_text = f.read()\n",
    "\n",
    "# 6. 루트 원인 분석 루프 (DeepSeek 스타일 프롬프트 적용)\n",
    "slide_win = 5\n",
    "for _, row in tp_df.iterrows():\n",
    "    time_idx = int(row[\"timestamp\"] + slide_win)\n",
    "    sensors_scores = [s.strip() for s in row[[\"1\", \"2\", \"3\"]].tolist()]\n",
    "    sensors = [s.split(\":\")[0] for s in sensors_scores]\n",
    "\n",
    "    window = 30\n",
    "    sensor_data_blocks = []\n",
    "    for sensor in sensors:\n",
    "        raw = get_sensor_data_block(sensor, time_idx, window=window)\n",
    "        sensor_data_blocks.append(f\"Sensor: {sensor}\\n{raw}\")\n",
    "\n",
    "    sensor_data_str = \"\\n\\n\".join(sensor_data_blocks)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"Domain Knowledge:\n",
    "    {manual_text}\n",
    "\n",
    "    Time Point: {time_idx}\n",
    "    Top 3 Sensors (by anomaly score): {', '.join(sensors)}\n",
    "\n",
    "    Raw Sensor Data (±{window} points around anomaly):\n",
    "    {sensor_data_str}\n",
    "\n",
    "    Please analyze the anomaly and explain the most likely root cause at time {time_idx}. Respond concisely and clearly in bullet points.\"\"\"}\n",
    "    ]\n",
    "\n",
    "    # 템플릿 적용\n",
    "    inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs.to(model.device), max_new_tokens=512)\n",
    "\n",
    "    # 응답 디코딩\n",
    "    response = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Root Cause Analysis for time {time_idx} ---\\n{response}\\n\")\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
