{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77dc7b1",
   "metadata": {},
   "source": [
    "# Llama-3.1-8B (128,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7362755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mskim2/llm_rca/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mskim2/llm_rca/myenv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:898: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/mskim2/llm_rca/myenv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.40it/s]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import sqlite3\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "with open(\"token.txt\", \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", use_auth_token=token)\n",
    "llm_pipeline = pipeline(\"text-generation\", \n",
    "                    model=model, \n",
    "                    tokenizer=tokenizer, \n",
    "                    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "                    device_map=\"auto\",\n",
    "                    return_full_text=False,\n",
    "                    temperature=0.1,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e75f7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GNN 결과 로드\n",
    "test_result = pd.read_csv(\"/home/mskim2/GDN/csv/swat/test_result.csv\")\n",
    "attention = pd.read_csv(\"/home/mskim2/GDN/csv/swat/attention_result.csv\")\n",
    "anomaly_score = pd.read_csv(\"/home/mskim2/GDN/csv/swat/anomaly_score.csv\")\n",
    "raw_df = pd.read_csv(\"/home/mskim2/GDN/data/swat/test.csv\")\n",
    "\n",
    "feature_file = open(f'/home/mskim2/GDN/data/swat/list.txt', 'r')\n",
    "feature_list = []\n",
    "for ft in feature_file:\n",
    "    feature_list.append(ft.strip())\n",
    "\n",
    "attack_point = pd.read_csv(\"/home/mskim2/GDN/attack_point.csv\")\n",
    "attack_point = attack_point.iloc[5:, -1].tolist()\n",
    "test_result['attack_point'] = attack_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f3b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. true positive 시점 필터링\n",
    "tp_df = test_result[(test_result[\"ground truth label\"] == 1.0) & (test_result[\"model prediction\"] == 1.0)& (pd.notna(test_result[\"attack_point\"]))]\n",
    "\n",
    "# 4-1. DB 연결 (SQLite / CSV 예시)\n",
    "conn = sqlite3.connect(\"sensor_data.db\")\n",
    "def get_raw_sensor_data(sensor: str, time_idx: int, window: int = 10) -> str:\n",
    "    query = f\"\"\"\n",
    "        SELECT timestamp, value\n",
    "        FROM raw_data\n",
    "        WHERE sensor_id = '{sensor}'\n",
    "        AND time_index BETWEEN {time_idx - window} AND {time_idx + window}\n",
    "        ORDER BY time_index\n",
    "    \"\"\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    return result.to_string(index=False)\n",
    "\n",
    "def get_sensor_data_block(raw_df: pd.DataFrame, sensor: list, time_idx: int, window: int = 10) -> str:\n",
    "    start = max(0, time_idx - window)\n",
    "    end = min(len(raw_df), time_idx + window + 1)\n",
    "    block = raw_df.loc[start:end, sensor]\n",
    "    lines = [f\"{val}\" for idx, val in block.items()]\n",
    "    return \", \".join(lines)\n",
    "\n",
    "def get_attention_data_block(df, sensor, time_idx, window):\n",
    "    topk = 15\n",
    "    node_num = 51\n",
    "    block = df.loc[(time_idx)*node_num*topk:(time_idx+1)*node_num*topk, :].squeeze()\n",
    "    sensor_graph = {}\n",
    "    for _, row in block.iterrows():\n",
    "        source = row['source']\n",
    "        target = row['target']\n",
    "        attn = row['attention']\n",
    "\n",
    "        if source not in sensor_graph:\n",
    "            sensor_graph[source] = {}\n",
    "        \n",
    "        sensor_graph[source][target] = attn\n",
    "\n",
    "    return sensor_graph\n",
    "\n",
    "# 5. 도메인 매뉴얼 불러오기\n",
    "with open(\"./manual.txt\", \"r\") as f:\n",
    "    manual_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd6741f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT-401\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "root = None\n",
    "\n",
    "# 6. 루트 원인 분석 루프\n",
    "slide_win = 5\n",
    "window = 10\n",
    "\n",
    "for _, row in tp_df.iterrows():\n",
    "    time_idx = int(row[\"timestamp\"] + slide_win)\n",
    "    sensors_scores = [s.strip() for s in row[[\"1\", \"2\", \"3\"]].tolist()]\n",
    "    sensors = [s.split(\":\")[0] for s in sensors_scores]\n",
    "\n",
    "    output_json = {\n",
    "        \"raw_data\": {},\n",
    "        \"anomaly_scores\": {},\n",
    "        \"attention\": {},\n",
    "    }\n",
    "\n",
    "    for sensor in feature_list:\n",
    "        anomaly = get_sensor_data_block(anomaly_score, sensor, time_idx, window=window)\n",
    "        output_json[\"anomaly_scores\"][sensor] = anomaly\n",
    "\n",
    "    for sensor in feature_list:\n",
    "        raw = get_sensor_data_block(raw_df, sensor, time_idx, window=window)\n",
    "        output_json[\"raw_data\"][sensor] = raw\n",
    "\n",
    "    anomaly = get_attention_data_block(attention, sensor, time_idx, window=window)\n",
    "    output_json[\"attention\"] = anomaly\n",
    "\n",
    "    root = row['attack_point']\n",
    "    # break로 첫 번째 tp만 일단\n",
    "    break\n",
    "\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06ab53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"You are an expert in root cause analysis for cyber-physical systems, especially industrial water treatment systems. Your task is to identify plausible root causes of detected anomalies. Use domain knowledge and respond concisely and clearly.\n",
    "\n",
    "TASK:\n",
    "1. Read the files provided in subsequent messages:\n",
    "- Sensor Manual: A textual guide containing descriptions of each sensor and actuator, their intended functionality.\n",
    "- Raw Sensor Data: A dictionary mapping each sensor name to a string containing comma-separated raw data over a time window (±30 time steps from the detected anomaly).\n",
    "- Anomaly Scores: A dictionary mapping each sensor name to a string containing comma-separated anomaly scores, which is learned by the Graph Neural Network, over a time window (±30 time steps from the detected anomaly).\n",
    "- Attention Weights: A dictionary where each key is a source sensor name, and its value is another dictionary mapping target sensor names to attention scores (floats between 0 and 1). The attention score represents the influence or correlation strength from the source sensor to the target sensor as learned by the Graph Neural Network.\n",
    "2. Return a JSON object with:\n",
    "   {\n",
    "     \"root_causes\": [\n",
    "       {\"cause\": str, \"evidence\": [sensor_id], \"confidence\": 0-1 float}\n",
    "     ],\n",
    "     \"supporting_detail\": str (<=150 tokens)\n",
    "   }\n",
    "CONSTRAINTS:\n",
    "- Use only the given data; do not hallucinate unseen equipment.\n",
    "- Be concise; no markdown, no additional text outside the JSON.\n",
    "\"\"\"\n",
    "},\n",
    "{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"\"\"\n",
    "Top 3 Sensors (by anomaly score): {', '.join(sensors)}\n",
    "\n",
    "Sensor Manual:\n",
    "{manual_text}\n",
    "\n",
    "Raw Sensor Data (±{window} points around anomaly):\n",
    "{output_json['raw_data']}\n",
    "\n",
    "Anomaly Scores (±{window} points around anomaly):\n",
    "{output_json['anomaly_scores']}\n",
    "\n",
    "Attention Weights:\n",
    "{output_json['attention']}\n",
    "\n",
    "Please analyze and explain the most likely root cause of the anomaly. Respond only with the required JSON output.\"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209301f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Cause: FIT-401\n",
      "\n",
      "--- Root Cause Analysis for time 1538 ---\n",
      "{\n",
      "  \"root_causes\": [\n",
      "    {\"cause\": \"Possible malfunction of FIT401 sensor\", \"evidence\": [\"FIT401\"], \"confidence\": 0.9},\n",
      "    {\"cause\": \"Possible malfunction of P101 actuator\", \"evidence\": [\"P101\"], \"confidence\": 0.8},\n",
      "    {\"cause\": \"Possible malfunction of MV301 actuator\", \"evidence\": [\"MV301\"], \"confidence\": 0.7}\n",
      "  ],\n",
      "  \"supporting_detail\": \"The anomaly scores for FIT401 are significantly higher than other sensors, indicating a possible malfunction. The attention weights also show a strong correlation between FIT401 and other sensors, suggesting a potential issue with the sensor's measurement. The P101 actuator's anomaly score is also high, indicating a possible malfunction. The MV301 actuator's anomaly score is lower, but its attention weights show a strong correlation with other sensors, suggesting a potential issue.\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = llm_pipeline(messages, max_new_tokens=512)\n",
    "print(\"\\n--- Root Cause:\", root, '---')\n",
    "print(f\"\\n--- Root Cause Analysis for time {time_idx} ---\\n{response[0]['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8781f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Cause: FIT-401\n",
      "\n",
      "--- Root Cause Analysis for time 1538 ---\n",
      "Based on the provided sensor data and domain knowledge, the most likely root cause of the anomaly is:\n",
      "\n",
      "* **Sensor FIT401 anomaly**: The sensor data shows a sudden drop in value to -13.93543942 and then to -23.93044192, which is likely due to a **sensor failure or malfunction**. This is because the sensor is measuring flow rate, and a sudden drop in value is not physically possible in this context.\n",
      "* **Sensor MV301 anomaly**: The sensor data shows a constant value of 0.5, which is likely due to a **stuck or faulty sensor**. This is because the motorized valve (MV301) is expected to have varying values based on its position, but the constant value suggests that the sensor is not accurately measuring the valve's position.\n",
      "* **Sensor FIT501 anomaly**: The sensor data shows a sudden drop in value to -6.637492982 and then to -6.714059509, which is likely due to a **sensor failure or malfunction**. This is because the sensor is measuring flow rate, and a sudden drop in value is not physically possible in this context.\n",
      "\n",
      "The common root cause among these sensors is likely a **power or communication issue**, which has caused the sensors to malfunction or fail. This could be due to a variety of factors, such as a power outage, a communication network failure, or a hardware issue with the sensors themselves.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "slide_win = 5\n",
    "for _, row in tp_df.iterrows():\n",
    "    time_idx = int(row[\"timestamp\"]+slide_win)\n",
    "    sensors_scores = [s.strip() for s in row[[\"1\", \"2\", \"3\"]].tolist()]\n",
    "    sensors = [s.split(\":\")[0] for s in sensors_scores]\n",
    "\n",
    "    window=30\n",
    "    sensor_data_blocks = []\n",
    "    for sensor in sensors:\n",
    "        raw = get_sensor_data_block(raw_df, sensor, time_idx, window=window)\n",
    "        sensor_data_blocks.append(f\"Sensor: {sensor}\\n{raw}\")\n",
    "\n",
    "    sensor_data_str = \"\\n\\n\".join(sensor_data_blocks)\n",
    "\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an expert in root cause analysis for cyber-physical systems, especially industrial water treatment systems. Your task is to identify plausible root causes of detected anomalies. Use domain knowledge and respond concisely and clearly.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"Domain Knowledge:\n",
    "{manual_text}\n",
    "\n",
    "Top 3 Sensors (by anomaly score): {', '.join(sensors)}\n",
    "\n",
    "Raw Sensor Data (±{window} points around anomaly):\n",
    "{sensor_data_str}\n",
    "\n",
    "Please analyze and explain the most likely root cause of the anomaly. Respond concisely and clearly in bullet points.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "    response = llm_pipeline(messages, max_new_tokens=512)\n",
    "    print(\"Root Cause:\", root)\n",
    "    print(f\"\\n--- Root Cause Analysis for time {time_idx} ---\\n{response[0]['generated_text']}\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a7eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause Analysis for time 1533 ---\n",
      "Based on the provided data and rules, the most likely root cause of the anomaly at time 1533 is:\n",
      "\n",
      "* **Sensor spoofing or malfunction**: \n",
      "  • FIT401, FIT501, and FIT502 show anomalies at time 1533, with FIT401 and FIT501 having negative values, which is physically impossible.\n",
      "  • The sudden drop in flow rates is not consistent with the expected behavior of the system.\n",
      "  • The rules state that a pump should never be ON when corresponding flow (FIT) is zero, which is likely violated in this case.\n",
      "  • The conductivity (AIT201) and pH (AIT202) sensors do not show any anomalies, which suggests that the issue is likely related to the flow sensors.\n",
      "\n",
      "* **Possible attack vector**: \n",
      "  • The anomaly could be caused by a PLC override or spoofing sensor values via simulation mode or HMI tag manipulation.\n",
      "  • The attacker might have exploited the SCADA workstation or command injection into network devices to disrupt communication and manipulate sensor values.\n",
      "\n",
      "To further investigate, it is recommended to:\n",
      "\n",
      "* Check the system logs for any suspicious activity or anomalies around the time of the incident.\n",
      "* Verify the integrity of the flow sensors and the PLC code.\n",
      "* Review the system's configuration and ensure that all sensors and actuators are operating within their expected ranges.\n",
      "* Consider implementing additional security measures to prevent future attacks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. GNN 결과 로드\n",
    "df = pd.read_csv(\"/home/mskim2/GDN/csv/swat/test_result.csv\")\n",
    "\n",
    "# 3. true positive 시점 필터링\n",
    "tp_df = df[(df[\"ground truth label\"] == 1.0) & (df[\"model prediction\"] == 1.0)]\n",
    "\n",
    "# 4-1. DB 연결 (SQLite / CSV 예시)\n",
    "conn = sqlite3.connect(\"sensor_data.db\")\n",
    "def get_raw_sensor_data(sensor: str, time_idx: int, window: int = 10) -> str:\n",
    "    query = f\"\"\"\n",
    "        SELECT timestamp, value\n",
    "        FROM raw_data\n",
    "        WHERE sensor_id = '{sensor}'\n",
    "        AND time_index BETWEEN {time_idx - window} AND {time_idx + window}\n",
    "        ORDER BY time_index\n",
    "    \"\"\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    return result.to_string(index=False)\n",
    "\n",
    "def get_sensor_data_block(sensor: list, time_idx: int, window: int = 10) -> str:\n",
    "    raw_df = pd.read_csv(\"/home/mskim2/GDN/data/swat/test.csv\")\n",
    "    start = max(0, time_idx - window)\n",
    "    end = min(len(raw_df), time_idx + window + 1)\n",
    "    block = raw_df.loc[start:end, sensor]\n",
    "    return block.to_string(index=False)\n",
    "\n",
    "# 5. 도메인 매뉴얼 불러오기\n",
    "with open(\"./manual.txt\", \"r\") as f:\n",
    "    manual_text = f.read()\n",
    "\n",
    "# 6. 루트 원인 분석 루프\n",
    "slide_win = 5\n",
    "for _, row in tp_df.iterrows():\n",
    "    time_idx = int(row[\"timestamp\"]+slide_win)\n",
    "    sensors_scores = [s.strip() for s in row[[\"1\", \"2\", \"3\"]].tolist()]\n",
    "    sensors = [s.split(\":\")[0] for s in sensors_scores]\n",
    "\n",
    "    window=30\n",
    "    sensor_data_blocks = []\n",
    "    for sensor in sensors:\n",
    "        raw = get_sensor_data_block(sensor, time_idx, window=window)\n",
    "        sensor_data_blocks.append(f\"Sensor: {sensor}\\n{raw}\")\n",
    "\n",
    "    sensor_data_str = \"\\n\\n\".join(sensor_data_blocks)\n",
    "\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an expert in root cause analysis for cyber-physical systems, especially industrial water treatment systems. Your task is to identify plausible root causes of detected anomalies. Use domain knowledge and respond concisely and clearly.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"Domain Knowledge:\n",
    "{manual_text}\n",
    "\n",
    "Time Point: {time_idx}\n",
    "Top 3 Sensors (by anomaly score): {', '.join(sensors)}\n",
    "\n",
    "Raw Sensor Data (±{window} points around anomaly):\n",
    "{sensor_data_str}\n",
    "\n",
    "Please analyze and explain the most likely root cause of the anomaly at time {time_idx}. Respond concisely and clearly in bullet points.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "    response = llm_pipeline(messages, max_new_tokens=512)\n",
    "    print(f\"\\n--- Root Cause Analysis for time {time_idx} ---\\n{response[0]['generated_text']}\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bdf288",
   "metadata": {},
   "source": [
    "# Falcon-7B (2,048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2cedbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]\n",
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_1267002/908972119.py:17: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=text_gen)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "text_gen = pipeline(\"text-generation\", \n",
    "                    model=model, \n",
    "                    tokenizer=tokenizer, \n",
    "                    max_new_tokens=512,\n",
    "                    return_full_text=False,\n",
    "                    )\n",
    "llm = HuggingFacePipeline(pipeline=text_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb6177e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause Analysis for time 1533 ---\n",
      "\n",
      "- Spoofing sensor values (FIT401, AIT201) via simulation mode or HMI tag manipulation to damage RO membrane.\n",
      "- Disabling UV401 via alarm setpoint manipulation to damage RO membrane.\n",
      "- Exploiting SCADA workstation (e.g., EternalBlue) to alter plant operation logic.\n",
      "- Command injection into network devices (e.g., MOXA access points) to disrupt communication.\n",
      "\n",
      "The most likely root cause of the anomaly at time 1533 is spoofing sensor values. This is due to the fact that the anomaly occurred during a time when the sensor values were being manipulated through simulation mode or HMI tag manipulation. The spoofing could be intentional or unintentional, but it is likely that the root cause is related to the manipulation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. GNN 결과 로드\n",
    "df = pd.read_csv(\"/home/mskim2/GDN/csv/swat/test_result.csv\")\n",
    "\n",
    "# 3. true positive 시점 필터링\n",
    "tp_df = df[(df[\"ground truth label\"] == 1.0) & (df[\"model prediction\"] == 1.0)]\n",
    "\n",
    "# 4-1. DB 연결 (SQLite / CSV 예시)\n",
    "conn = sqlite3.connect(\"sensor_data.db\")\n",
    "def get_raw_sensor_data(sensor: str, time_idx: int, window: int = 10) -> str:\n",
    "    query = f\"\"\"\n",
    "        SELECT timestamp, value\n",
    "        FROM raw_data\n",
    "        WHERE sensor_id = '{sensor}'\n",
    "        AND time_index BETWEEN {time_idx - window} AND {time_idx + window}\n",
    "        ORDER BY time_index\n",
    "    \"\"\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    return result.to_string(index=False)\n",
    "\n",
    "def get_sensor_data_block(sensor: list, time_idx: int, window: int = 10) -> str:\n",
    "    raw_df = pd.read_csv(\"/home/mskim2/GDN/data/swat/test.csv\")\n",
    "    start = max(0, time_idx - window)\n",
    "    end = min(len(raw_df), time_idx + window + 1)\n",
    "    block = raw_df.loc[start:end, sensor]\n",
    "    return block.to_string(index=False)\n",
    "\n",
    "# 5. 도메인 매뉴얼 불러오기\n",
    "with open(\"./manual.txt\", \"r\") as f:\n",
    "    manual_text = f.read()\n",
    "\n",
    "# 6. 루트 원인 분석 루프\n",
    "slide_win = 5\n",
    "for _, row in tp_df.iterrows():\n",
    "    time_idx = int(row[\"timestamp\"]+slide_win)\n",
    "    sensors_scores = [s.strip() for s in row[[\"1\", \"2\", \"3\"]].tolist()]\n",
    "    sensors = [s.split(\":\")[0] for s in sensors_scores]\n",
    "\n",
    "    window=20\n",
    "    sensor_data_blocks = []\n",
    "    for sensor in sensors:\n",
    "        raw = get_sensor_data_block(sensor, time_idx, window=window)\n",
    "        sensor_data_blocks.append(f\"Sensor: {sensor}\\n{raw}\")\n",
    "\n",
    "    sensor_data_str = \"\\n\\n\".join(sensor_data_blocks)\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"You are an expert in root cause analysis for cyber-physical systems, especially industrial water treatment systems. Your task is to identify plausible root causes of detected anomalies. Use domain knowledge and respond concisely and clearly.\"),\n",
    "        (\"human\", f\"\"\"Domain Knowledge:\n",
    "{manual_text}\n",
    "\n",
    "Time Point: {time_idx}\n",
    "Top 3 Sensors (by anomaly score): {', '.join(sensors)}\n",
    "\n",
    "Raw Sensor Data (±{window} points around anomaly):\n",
    "{sensor_data_str}\n",
    "\n",
    "Please analyze this and explain the most likely root cause of the anomaly at time {time_idx}. Respond concisely and clearly in bullet points.\"\"\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt_template | llm\n",
    "    response = chain.invoke({})\n",
    "    print(f\"\\n--- Root Cause Analysis for time {time_idx} ---\\n{response}\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60eaca",
   "metadata": {},
   "source": [
    "# DeepSeek-7B (4,096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9e7313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.57s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c2222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause Analysis for time 1533 ---\n",
      "* FIT401 and FIT501 show significant spikes in values, reaching -30 in some cases, which is highly unusual for sensor values.\n",
      "* FIT502 has more normal values but still shows some unusual fluctuations.\n",
      "* The most likely root cause of these anomalies is a physical failure or malfunction of the sensors themselves, leading to incorrect or inconsistent readings.\n",
      "* It is also possible that there is a communication issue between the sensors and the SCADA system, causing data corruption or delay.\n",
      "* It is important to investigate these anomalies further by physically inspecting the sensors, checking their calibration, and verifying their connection to the system.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. GNN 결과 로드\n",
    "df = pd.read_csv(\"/home/mskim2/GDN/csv/swat/test_result.csv\")\n",
    "\n",
    "# 3. true positive 시점 필터링\n",
    "tp_df = df[(df[\"ground truth label\"] == 1.0) & (df[\"model prediction\"] == 1.0)]\n",
    "\n",
    "# 4-1. DB 연결 (SQLite / CSV 예시)\n",
    "conn = sqlite3.connect(\"sensor_data.db\")\n",
    "def get_raw_sensor_data(sensor: str, time_idx: int, window: int = 10) -> str:\n",
    "    query = f\"\"\"\n",
    "        SELECT timestamp, value\n",
    "        FROM raw_data\n",
    "        WHERE sensor_id = '{sensor}'\n",
    "        AND time_index BETWEEN {time_idx - window} AND {time_idx + window}\n",
    "        ORDER BY time_index\n",
    "    \"\"\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    return result.to_string(index=False)\n",
    "\n",
    "def get_sensor_data_block(sensor: list, time_idx: int, window: int = 10) -> str:\n",
    "    raw_df = pd.read_csv(\"/home/mskim2/GDN/data/swat/test.csv\")\n",
    "    start = max(0, time_idx - window)\n",
    "    end = min(len(raw_df), time_idx + window + 1)\n",
    "    block = raw_df.loc[start:end, sensor]\n",
    "    return block.to_string(index=False)\n",
    "\n",
    "# 5. 도메인 매뉴얼 불러오기\n",
    "with open(\"./manual.txt\", \"r\") as f:\n",
    "    manual_text = f.read()\n",
    "\n",
    "# 6. 루트 원인 분석 루프 (DeepSeek 스타일 프롬프트 적용)\n",
    "slide_win = 5\n",
    "for _, row in tp_df.iterrows():\n",
    "    time_idx = int(row[\"timestamp\"] + slide_win)\n",
    "    sensors_scores = [s.strip() for s in row[[\"1\", \"2\", \"3\"]].tolist()]\n",
    "    sensors = [s.split(\":\")[0] for s in sensors_scores]\n",
    "\n",
    "    window = 30\n",
    "    sensor_data_blocks = []\n",
    "    for sensor in sensors:\n",
    "        raw = get_sensor_data_block(sensor, time_idx, window=window)\n",
    "        sensor_data_blocks.append(f\"Sensor: {sensor}\\n{raw}\")\n",
    "\n",
    "    sensor_data_str = \"\\n\\n\".join(sensor_data_blocks)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"Domain Knowledge:\n",
    "    {manual_text}\n",
    "\n",
    "    Time Point: {time_idx}\n",
    "    Top 3 Sensors (by anomaly score): {', '.join(sensors)}\n",
    "\n",
    "    Raw Sensor Data (±{window} points around anomaly):\n",
    "    {sensor_data_str}\n",
    "\n",
    "    Please analyze the anomaly and explain the most likely root cause at time {time_idx}. Respond concisely and clearly in bullet points.\"\"\"}\n",
    "    ]\n",
    "\n",
    "    # 템플릿 적용\n",
    "    inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs.to(model.device), max_new_tokens=512)\n",
    "\n",
    "    # 응답 디코딩\n",
    "    response = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Root Cause Analysis for time {time_idx} ---\\n{response}\\n\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7312429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeecc32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45dd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e376c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
