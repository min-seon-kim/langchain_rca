{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77dc7b1",
   "metadata": {},
   "source": [
    "# Llama-3.1-8B (128,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7362755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mskim2/llm_rca/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mskim2/llm_rca/myenv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:898: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/mskim2/llm_rca/myenv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import sqlite3\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "with open(\"token.txt\", \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", use_auth_token=token)\n",
    "llm_pipeline = pipeline(\"text-generation\", \n",
    "                    model=model, \n",
    "                    tokenizer=tokenizer, \n",
    "                    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "                    device_map=\"auto\",\n",
    "                    return_full_text=False,\n",
    "                    temperature=0.1,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0acd4f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause Analysis for time 1533 ---\n",
      "Based on the provided data and rules, the most likely root cause of the anomaly at time 1533 is:\n",
      "\n",
      "* **Sensor spoofing or malfunction**: \n",
      "  • FIT401, FIT501, and FIT502 show anomalies at time 1533, with FIT401 and FIT501 having negative values, which is physically impossible.\n",
      "  • The sudden drop in flow rates is not consistent with the expected behavior of the system.\n",
      "  • The rules state that a pump should never be ON when corresponding flow (FIT) is zero, which is likely violated in this case.\n",
      "  • The conductivity (AIT201) and pH (AIT202) sensors do not show any anomalies, which suggests that the issue is likely related to the flow sensors.\n",
      "\n",
      "* **Possible attack vector**: \n",
      "  • The anomaly could be caused by a PLC override or spoofing sensor values via simulation mode or HMI tag manipulation.\n",
      "  • The attacker might have exploited the SCADA workstation or command injection into network devices to disrupt communication and manipulate sensor values.\n",
      "\n",
      "To further investigate, it is recommended to:\n",
      "\n",
      "* Check the system logs for any suspicious activity or anomalies around the time of the incident.\n",
      "* Verify the integrity of the flow sensors and the PLC code.\n",
      "* Review the system's configuration and ensure that all sensors and actuators are operating within their expected ranges.\n",
      "* Consider implementing additional security measures to prevent future attacks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. GNN 결과 로드\n",
    "df = pd.read_csv(\"/home/mskim2/GDN/csv/swat/test_result.csv\")\n",
    "\n",
    "# 3. true positive 시점 필터링\n",
    "tp_df = df[(df[\"ground truth label\"] == 1.0) & (df[\"model prediction\"] == 1.0)]\n",
    "\n",
    "# 4-1. DB 연결 (SQLite / CSV 예시)\n",
    "conn = sqlite3.connect(\"sensor_data.db\")\n",
    "def get_raw_sensor_data(sensor: str, time_idx: int, window: int = 10) -> str:\n",
    "    query = f\"\"\"\n",
    "        SELECT timestamp, value\n",
    "        FROM raw_data\n",
    "        WHERE sensor_id = '{sensor}'\n",
    "        AND time_index BETWEEN {time_idx - window} AND {time_idx + window}\n",
    "        ORDER BY time_index\n",
    "    \"\"\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    return result.to_string(index=False)\n",
    "\n",
    "def get_sensor_data_block(sensor: list, time_idx: int, window: int = 10) -> str:\n",
    "    raw_df = pd.read_csv(\"/home/mskim2/GDN/data/swat/test.csv\")\n",
    "    start = max(0, time_idx - window)\n",
    "    end = min(len(raw_df), time_idx + window + 1)\n",
    "    block = raw_df.loc[start:end, sensor]\n",
    "    return block.to_string(index=False)\n",
    "\n",
    "# 5. 도메인 매뉴얼 불러오기\n",
    "with open(\"./manual.txt\", \"r\") as f:\n",
    "    manual_text = f.read()\n",
    "\n",
    "# 6. 루트 원인 분석 루프\n",
    "slide_win = 5\n",
    "for _, row in tp_df.iterrows():\n",
    "    time_idx = int(row[\"timestamp\"]+slide_win)\n",
    "    sensors_scores = [s.strip() for s in row[[\"1\", \"2\", \"3\"]].tolist()]\n",
    "    sensors = [s.split(\":\")[0] for s in sensors_scores]\n",
    "\n",
    "    window=30\n",
    "    sensor_data_blocks = []\n",
    "    for sensor in sensors:\n",
    "        raw = get_sensor_data_block(sensor, time_idx, window=window)\n",
    "        sensor_data_blocks.append(f\"Sensor: {sensor}\\n{raw}\")\n",
    "\n",
    "    sensor_data_str = \"\\n\\n\".join(sensor_data_blocks)\n",
    "\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an expert in root cause analysis for cyber-physical systems, especially industrial water treatment systems. Your task is to identify plausible root causes of detected anomalies. Use domain knowledge and respond concisely and clearly.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"Domain Knowledge:\n",
    "{manual_text}\n",
    "\n",
    "Time Point: {time_idx}\n",
    "Top 3 Sensors (by anomaly score): {', '.join(sensors)}\n",
    "\n",
    "Raw Sensor Data (±{window} points around anomaly):\n",
    "{sensor_data_str}\n",
    "\n",
    "Please analyze and explain the most likely root cause of the anomaly at time {time_idx}. Respond concisely and clearly in bullet points.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "    response = llm_pipeline(messages, max_new_tokens=512)\n",
    "    print(f\"\\n--- Root Cause Analysis for time {time_idx} ---\\n{response[0]['generated_text']}\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bdf288",
   "metadata": {},
   "source": [
    "# Falcon-7B (2,048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2cedbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]\n",
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_1267002/908972119.py:17: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=text_gen)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "text_gen = pipeline(\"text-generation\", \n",
    "                    model=model, \n",
    "                    tokenizer=tokenizer, \n",
    "                    max_new_tokens=512,\n",
    "                    return_full_text=False,\n",
    "                    )\n",
    "llm = HuggingFacePipeline(pipeline=text_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb6177e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause Analysis for time 1533 ---\n",
      "\n",
      "- Spoofing sensor values (FIT401, AIT201) via simulation mode or HMI tag manipulation to damage RO membrane.\n",
      "- Disabling UV401 via alarm setpoint manipulation to damage RO membrane.\n",
      "- Exploiting SCADA workstation (e.g., EternalBlue) to alter plant operation logic.\n",
      "- Command injection into network devices (e.g., MOXA access points) to disrupt communication.\n",
      "\n",
      "The most likely root cause of the anomaly at time 1533 is spoofing sensor values. This is due to the fact that the anomaly occurred during a time when the sensor values were being manipulated through simulation mode or HMI tag manipulation. The spoofing could be intentional or unintentional, but it is likely that the root cause is related to the manipulation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. GNN 결과 로드\n",
    "df = pd.read_csv(\"/home/mskim2/GDN/csv/swat/test_result.csv\")\n",
    "\n",
    "# 3. true positive 시점 필터링\n",
    "tp_df = df[(df[\"ground truth label\"] == 1.0) & (df[\"model prediction\"] == 1.0)]\n",
    "\n",
    "# 4-1. DB 연결 (SQLite / CSV 예시)\n",
    "conn = sqlite3.connect(\"sensor_data.db\")\n",
    "def get_raw_sensor_data(sensor: str, time_idx: int, window: int = 10) -> str:\n",
    "    query = f\"\"\"\n",
    "        SELECT timestamp, value\n",
    "        FROM raw_data\n",
    "        WHERE sensor_id = '{sensor}'\n",
    "        AND time_index BETWEEN {time_idx - window} AND {time_idx + window}\n",
    "        ORDER BY time_index\n",
    "    \"\"\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    return result.to_string(index=False)\n",
    "\n",
    "def get_sensor_data_block(sensor: list, time_idx: int, window: int = 10) -> str:\n",
    "    raw_df = pd.read_csv(\"/home/mskim2/GDN/data/swat/test.csv\")\n",
    "    start = max(0, time_idx - window)\n",
    "    end = min(len(raw_df), time_idx + window + 1)\n",
    "    block = raw_df.loc[start:end, sensor]\n",
    "    return block.to_string(index=False)\n",
    "\n",
    "# 5. 도메인 매뉴얼 불러오기\n",
    "with open(\"./manual.txt\", \"r\") as f:\n",
    "    manual_text = f.read()\n",
    "\n",
    "# 6. 루트 원인 분석 루프\n",
    "slide_win = 5\n",
    "for _, row in tp_df.iterrows():\n",
    "    time_idx = int(row[\"timestamp\"]+slide_win)\n",
    "    sensors_scores = [s.strip() for s in row[[\"1\", \"2\", \"3\"]].tolist()]\n",
    "    sensors = [s.split(\":\")[0] for s in sensors_scores]\n",
    "\n",
    "    window=20\n",
    "    sensor_data_blocks = []\n",
    "    for sensor in sensors:\n",
    "        raw = get_sensor_data_block(sensor, time_idx, window=window)\n",
    "        sensor_data_blocks.append(f\"Sensor: {sensor}\\n{raw}\")\n",
    "\n",
    "    sensor_data_str = \"\\n\\n\".join(sensor_data_blocks)\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"You are an expert in root cause analysis for cyber-physical systems, especially industrial water treatment systems. Your task is to identify plausible root causes of detected anomalies. Use domain knowledge and respond concisely and clearly.\"),\n",
    "        (\"human\", f\"\"\"Domain Knowledge:\n",
    "{manual_text}\n",
    "\n",
    "Time Point: {time_idx}\n",
    "Top 3 Sensors (by anomaly score): {', '.join(sensors)}\n",
    "\n",
    "Raw Sensor Data (±{window} points around anomaly):\n",
    "{sensor_data_str}\n",
    "\n",
    "Please analyze this and explain the most likely root cause of the anomaly at time {time_idx}. Respond concisely and clearly in bullet points.\"\"\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt_template | llm\n",
    "    response = chain.invoke({})\n",
    "    print(f\"\\n--- Root Cause Analysis for time {time_idx} ---\\n{response}\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60eaca",
   "metadata": {},
   "source": [
    "# DeepSeek-7B (4,096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9e7313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.57s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c2222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Root Cause Analysis for time 1533 ---\n",
      "* FIT401 and FIT501 show significant spikes in values, reaching -30 in some cases, which is highly unusual for sensor values.\n",
      "* FIT502 has more normal values but still shows some unusual fluctuations.\n",
      "* The most likely root cause of these anomalies is a physical failure or malfunction of the sensors themselves, leading to incorrect or inconsistent readings.\n",
      "* It is also possible that there is a communication issue between the sensors and the SCADA system, causing data corruption or delay.\n",
      "* It is important to investigate these anomalies further by physically inspecting the sensors, checking their calibration, and verifying their connection to the system.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. GNN 결과 로드\n",
    "df = pd.read_csv(\"/home/mskim2/GDN/csv/swat/test_result.csv\")\n",
    "\n",
    "# 3. true positive 시점 필터링\n",
    "tp_df = df[(df[\"ground truth label\"] == 1.0) & (df[\"model prediction\"] == 1.0)]\n",
    "\n",
    "# 4-1. DB 연결 (SQLite / CSV 예시)\n",
    "conn = sqlite3.connect(\"sensor_data.db\")\n",
    "def get_raw_sensor_data(sensor: str, time_idx: int, window: int = 10) -> str:\n",
    "    query = f\"\"\"\n",
    "        SELECT timestamp, value\n",
    "        FROM raw_data\n",
    "        WHERE sensor_id = '{sensor}'\n",
    "        AND time_index BETWEEN {time_idx - window} AND {time_idx + window}\n",
    "        ORDER BY time_index\n",
    "    \"\"\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    return result.to_string(index=False)\n",
    "\n",
    "def get_sensor_data_block(sensor: list, time_idx: int, window: int = 10) -> str:\n",
    "    raw_df = pd.read_csv(\"/home/mskim2/GDN/data/swat/test.csv\")\n",
    "    start = max(0, time_idx - window)\n",
    "    end = min(len(raw_df), time_idx + window + 1)\n",
    "    block = raw_df.loc[start:end, sensor]\n",
    "    return block.to_string(index=False)\n",
    "\n",
    "# 5. 도메인 매뉴얼 불러오기\n",
    "with open(\"./manual.txt\", \"r\") as f:\n",
    "    manual_text = f.read()\n",
    "\n",
    "# 6. 루트 원인 분석 루프 (DeepSeek 스타일 프롬프트 적용)\n",
    "slide_win = 5\n",
    "for _, row in tp_df.iterrows():\n",
    "    time_idx = int(row[\"timestamp\"] + slide_win)\n",
    "    sensors_scores = [s.strip() for s in row[[\"1\", \"2\", \"3\"]].tolist()]\n",
    "    sensors = [s.split(\":\")[0] for s in sensors_scores]\n",
    "\n",
    "    window = 30\n",
    "    sensor_data_blocks = []\n",
    "    for sensor in sensors:\n",
    "        raw = get_sensor_data_block(sensor, time_idx, window=window)\n",
    "        sensor_data_blocks.append(f\"Sensor: {sensor}\\n{raw}\")\n",
    "\n",
    "    sensor_data_str = \"\\n\\n\".join(sensor_data_blocks)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"Domain Knowledge:\n",
    "    {manual_text}\n",
    "\n",
    "    Time Point: {time_idx}\n",
    "    Top 3 Sensors (by anomaly score): {', '.join(sensors)}\n",
    "\n",
    "    Raw Sensor Data (±{window} points around anomaly):\n",
    "    {sensor_data_str}\n",
    "\n",
    "    Please analyze the anomaly and explain the most likely root cause at time {time_idx}. Respond concisely and clearly in bullet points.\"\"\"}\n",
    "    ]\n",
    "\n",
    "    # 템플릿 적용\n",
    "    inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs.to(model.device), max_new_tokens=512)\n",
    "\n",
    "    # 응답 디코딩\n",
    "    response = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Root Cause Analysis for time {time_idx} ---\\n{response}\\n\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7312429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeecc32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45dd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e376c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
